<!DOCTYPE html><html lang="en" class="" style="scroll-padding:60px"><head><meta charSet="utf-8"/><meta name="viewport" content="width=device-width,initial-scale=1"/><title>Context for this coding &amp; writing sample - Coding Sample</title><meta property="og:title" content="Context for this coding &amp; writing sample - Coding Sample"/><meta name="generator" content="mystmd"/><meta name="keywords" content=""/><meta name="image" content="/build/b77199e99a54e59b2e3c037c2cc90f21.svg"/><meta property="og:image" content="/build/b77199e99a54e59b2e3c037c2cc90f21.svg"/><link rel="stylesheet" href="/build/_assets/app-HG4THSM4.css"/><link rel="stylesheet" href="/build/_assets/thebe-core-VKVHG5VY.css"/><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/jupyter-matplotlib@0.11.3/css/mpl_widget.css"/><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/4.7.0/css/font-awesome.css"/><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.2/dist/katex.min.css" integrity="sha384-MlJdn/WNKDGXveldHDdyRP1R4CTHr3FeuDNfhsLPYrq2t0UBkUdK2jyTnXPEK1NQ" crossorigin="anonymous"/><link rel="icon" href="/favicon.ico"/><link rel="stylesheet" href="/myst-theme.css"/><script>
  const savedTheme = localStorage.getItem("myst:theme");
  const theme = window.matchMedia("(prefers-color-scheme: light)").matches ? 'light' : 'dark';
  const classes = document.documentElement.classList;
  const hasAnyTheme = classes.contains('light') || classes.contains('dark');
  if (!hasAnyTheme) classes.add(savedTheme ?? theme);
</script></head><body class="m-0 transition-colors duration-500 bg-white dark:bg-stone-900"><div class="fixed top-1 left-1 h-[0px] w-[0px] focus-within:z-40 focus-within:h-auto focus-within:w-auto bg-white overflow-hidden focus-within:p-2 focus-within:ring-1" aria-label="skip to content options"><a href="#skip-to-frontmatter" class="block px-2 py-1 text-black underline">Skip to article frontmatter</a><a href="#skip-to-article" class="block px-2 py-1 text-black underline">Skip to article content</a></div><div class="bg-white/80 backdrop-blur dark:bg-stone-900/80 shadow dark:shadow-stone-700 p-3 md:px-8 sticky w-screen top-0 z-30 h-[60px]"><nav class="flex items-center justify-between flex-nowrap max-w-[1440px] mx-auto"><div class="flex flex-row xl:min-w-[19.5rem] mr-2 sm:mr-7 justify-start items-center shrink-0"><a class="flex items-center ml-3 dark:text-white w-fit md:ml-5 xl:ml-7" href="/"><span class="text-md sm:text-xl tracking-tight sm:mr-5">Made with MyST</span></a></div><div class="flex items-center flex-grow w-auto"><div class="flex-grow hidden text-md lg:block"></div><div class="flex-grow block"></div><button type="button" aria-haspopup="dialog" aria-expanded="false" aria-controls="radix-:R3iop:" data-state="closed" class="flex items-center h-10 aspect-square sm:w-64 text-left text-gray-400 border border-gray-300 dark:border-gray-600 rounded-lg bg-gray-50 dark:bg-gray-700 hover:ring-blue-500 dark:hover:ring-blue-500 hover:border-blue-500 dark:hover:border-blue-500"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="currentColor" aria-hidden="true" data-slot="icon" class="p-2.5 h-10 w-10 aspect-square"><path fill-rule="evenodd" d="M10.5 3.75a6.75 6.75 0 1 0 0 13.5 6.75 6.75 0 0 0 0-13.5ZM2.25 10.5a8.25 8.25 0 1 1 14.59 5.28l4.69 4.69a.75.75 0 1 1-1.06 1.06l-4.69-4.69A8.25 8.25 0 0 1 2.25 10.5Z" clip-rule="evenodd"></path></svg><span class="hidden sm:block grow">Search</span><div aria-hidden="true" class="items-center hidden mx-1 font-mono text-sm text-gray-400 sm:flex gap-x-1"><kbd class="px-2 py-1 border border-gray-300 dark:border-gray-600 rounded-md shadow-[0px_2px_0px_0px_rgba(0,0,0,0.08)] dark:shadow-none hide-mac">CTRL</kbd><kbd class="px-2 py-1 border border-gray-300 dark:border-gray-600 rounded-md shadow-[0px_2px_0px_0px_rgba(0,0,0,0.08)] dark:shadow-none show-mac">⌘</kbd><kbd class="px-2 py-1 border border-gray-300 dark:border-gray-600 rounded-md shadow-[0px_2px_0px_0px_rgba(0,0,0,0.08)] dark:shadow-none ">K</kbd><script>
;(() => {
const script = document.currentScript;
const root = script.parentElement;

const isMac = /mac/i.test(
      window.navigator.userAgentData?.platform ?? window.navigator.userAgent,
    );
root.querySelectorAll(".hide-mac").forEach(node => {node.classList.add(isMac ? "hidden" : "block")});
root.querySelectorAll(".show-mac").forEach(node => {node.classList.add(!isMac ? "hidden" : "block")});
})()</script></div></button><button class="theme rounded-full aspect-square border border-stone-700 dark:border-white hover:bg-neutral-100 border-solid overflow-hidden text-stone-700 dark:text-white hover:text-stone-500 dark:hover:text-neutral-800 w-8 h-8 mx-3" title="Toggle theme between light and dark mode." aria-label="Toggle theme between light and dark mode."><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="currentColor" aria-hidden="true" data-slot="icon" class="h-full w-full p-0.5 hidden dark:block"><path fill-rule="evenodd" d="M9.528 1.718a.75.75 0 0 1 .162.819A8.97 8.97 0 0 0 9 6a9 9 0 0 0 9 9 8.97 8.97 0 0 0 3.463-.69.75.75 0 0 1 .981.98 10.503 10.503 0 0 1-9.694 6.46c-5.799 0-10.5-4.7-10.5-10.5 0-4.368 2.667-8.112 6.46-9.694a.75.75 0 0 1 .818.162Z" clip-rule="evenodd"></path></svg><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" class="h-full w-full p-0.5 dark:hidden"><path stroke-linecap="round" stroke-linejoin="round" d="M12 3v2.25m6.364.386-1.591 1.591M21 12h-2.25m-.386 6.364-1.591-1.591M12 18.75V21m-4.773-4.227-1.591 1.591M5.25 12H3m4.227-4.773L5.636 5.636M15.75 12a3.75 3.75 0 1 1-7.5 0 3.75 3.75 0 0 1 7.5 0Z"></path></svg></button><div class="block sm:hidden"></div><div class="hidden sm:block"></div></div></nav></div><article class="article content article-grid grid-gap"><main class="article-grid subgrid-gap col-screen"><div class="hidden"></div><div id="skip-to-frontmatter" aria-label="article frontmatter" class="mb-8 pt-9"><div class="flex items-center h-6 mb-5 text-sm font-light"><div class="flex-grow"></div><div class="inline-block mr-1"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="currentColor" aria-hidden="true" width="1.25rem" height="1.25rem" class="inline-block"><title>Jupyter Notebook</title><path d="M20.2 1.7c0 .8-.5 1.4-1.3 1.5-.8 0-1.4-.5-1.5-1.3 0-.8.5-1.4 1.3-1.5.8-.1 1.5.5 1.5 1.3zM12 17.9c-3.7 0-7-1.3-8.7-3.3 1.8 4.8 7.1 7.3 11.9 5.5 2.5-.9 4.5-2.9 5.5-5.5-1.7 2-4.9 3.3-8.7 3.3zM12 5.1c3.7 0 7 1.3 8.7 3.3-1.8-4.8-7.1-7.3-11.9-5.5-2.5.9-4.5 2.9-5.5 5.5 1.7-2 5-3.3 8.7-3.3zM6.9 21.8c.1 1-.7 1.8-1.7 1.9-1 .1-1.8-.7-1.9-1.7 0-1 .7-1.8 1.7-1.9 1-.1 1.8.7 1.9 1.7zM3.7 4.6c-.6 0-1-.4-1-1s.4-1 1-1 1 .4 1 1c0 .5-.4 1-1 1z"></path></svg></div><div class="relative flex inline-block mx-1 grow-0" data-headlessui-state=""><button class="relative ml-2 -mr-1" id="headlessui-menu-button-:Rd4fop:" type="button" aria-haspopup="menu" aria-expanded="false" data-headlessui-state=""><span class="sr-only">Downloads</span><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" width="1.25rem" height="1.25rem"><path stroke-linecap="round" stroke-linejoin="round" d="M3 16.5v2.25A2.25 2.25 0 0 0 5.25 21h13.5A2.25 2.25 0 0 0 21 18.75V16.5M16.5 12 12 16.5m0 0L7.5 12m4.5 4.5V3"></path></svg></button></div></div><h1 class="mb-0">Context for this coding &amp; writing sample</h1></div><div class="block my-10 lg:sticky lg:z-10 lg:h-0 lg:pt-0 lg:my-0 lg:ml-10 lg:col-margin-right" style="top:60px"><nav></nav></div><div id="skip-to-article"></div><div id="dZcS9NkH1f" class="relative group/block"><p>I presented this notebook on Tuesday, April 29th to Fernando Perez’s research group at UC-Berkely. I’ve modified it slightly to:</p><ol start="1"><li>Add context that I had previously noted verbally</li><li>Reduce the computational complexity of the example so that it can run on a single binder instance</li><li>Created a repository so that software dependencies can be built automatically, and the data is present.</li></ol><p>This notebook can be run for free from any web browser be clicking the following binder link: <a target="_blank" rel="noreferrer" href="https://mybinder.org/v2/gh/espg/coding-sample/HEAD?urlpath=%2Fdoc%2Ftree%2FGaussianProcesses.ipynb" class=""><img id="VmQkDJybFE" style="margin:0 auto" src="/build/b77199e99a54e59b2e3c037c2cc90f21.svg" alt="Binder" data-canonical-url="https://mybinder.org/badge_logo.svg"/></a></p></div><div id="IxG2Tr8wEq" class="relative group/block"><h2 id="gaussian-processes-prediction" class="relative group"><span class="heading-text">Gaussian Processes Prediction</span><a class="no-underline text-inherit hover:text-inherit inline-block w-0 px-0 translate-x-[10px] font-normal select-none transition-opacity opacity-0 focus:opacity-100 group-hover:opacity-70" href="#gaussian-processes-prediction" title="Link to this Section" aria-label="Link to this Section">¶</a></h2><p>Principle Component Analysis (PCA) and Empirical Orthogonal functions (EOF) are functionally the same numerical method, with EOFs being the preferred term in Atmospheric communities and PCA being the more general term used in broader statistical discussions. Similarly, Gaussian Processes is the general term used in physics and statistical learning for what the geosciences has traditionally termed ‘kriging’, and which some branches of math refer to as Wiener–Kolmogorov prediction.</p><p>Gaussian Processes (GP) are perhaps best thought of as a collection of enhancements to the traditional kriging system. They are functionally equivalent to kriging (<cite class="" data-state="closed"><a href="https://doi.org/10.1007/978-94-011-5014-9_23" target="_blank" rel="noreferrer" class="hover-link">Williams (1998)</a></cite>), and differ only in implantation details and slightly in philosophy; although the philosophical differences are in general extensions to ideas explicitly espoused by many kriging giants. <strong>The GP philosophy treats interpolation as model selection from an infinite number of functions (<cite class="" data-state="closed"><a href="https://doi.org/10.7551/mitpress/3206.001.0001" target="_blank" rel="noreferrer" class="hover-link">Rasmussen &amp; Williams (2005)</a></cite>)</strong>.</p><picture class=""><source srcSet="/build/5b8ae75218c2b71222b94cc7a0abdc35.webp" type="image/webp"/><img id="IhcbhHl742" style="margin:0 auto" src="/build/5b8ae75218c2b71222b94cc7a0abdc35.png" alt="gp.png" data-canonical-url="https://upload.wikimedia.org/wikipedia/commons/7/7f/Gaussian_Process_Regression.png"/></picture><p>This characterization certainly fits with <cite class="" data-state="closed"><a href="https://doi.org/10.2307/1425829" target="_blank" rel="noreferrer" class="hover-link">Matheron’s</a></cite> discussion of random fields, and is a close match to <cite class="" data-state="closed"><a href="https://doi.org/10.1007/bf02067214" target="_blank" rel="noreferrer" class="hover-link">Journal’s</a></cite> description of projection into various solution spaces. These functions are not required to be linear, as the figure below demonstrates:</p><picture class=""><source srcSet="/build/af20bbeeb575a136bc4a46923a3b5451.webp" type="image/webp"/><img id="JmcDGugKw5" style="margin:0 auto" src="/build/af20bbeeb575a136bc4a46923a3b5451.gif" alt="animation.gif" data-canonical-url="https://upload.wikimedia.org/wikipedia/commons/d/da/Gaussianprocess.gif"/></picture><p><em>As number of predictions ‘P’ grows to be large above, the mean of all ‘P’ approaches the best estimate, with the variance of predictions indicating confidence (std. dev. of predictions)</em></p><p><strong>The primary object of interest in kriging is the variogram</strong>, which is the main method by which practitioners fit a covariance function. <strong>In contrast, the primary object of interest in GPs is the kernel, which is directly equivalent to covariances.</strong> The kernel formulation has direct computational savings, enabling solving of high dimensional kernel functions in low dimensional space via the kernel trick (i.e., computing only the inner products) (<cite class="" data-state="closed"><a href="https://doi.org/10.5555/944790.944815" target="_blank" rel="noreferrer" class="hover-link">Genton (2002)</a></cite>); the kernel formulation also admits easy translation to Fourier based methods when interpolating regular spaces (<cite class="" data-state="closed"><a href="https://doi.org/10.48550/ARXIV.1302.4245" target="_blank" rel="noreferrer" class="hover-link">Wilson &amp; Adams (2013)</a></cite>). Kernel architecture is flexible, as valid kernels can be added or multiplied to form new synthesis kernels (<cite class="" data-state="closed"><a href="https://doi.org/10.1080/01621459.1999.10473885" target="_blank" rel="noreferrer" class="hover-link">Cressie &amp; Huang (1999)</a></cite>). For instance, non-stationary kernels can be combined with stationary kernels and white noise kernels, such that large spatial trends, local correlation and structure, and intrinsic random noise and error can be modeled and specified as discrete submodules and functions-- <a target="_blank" rel="noreferrer" href="https://towardsdatascience.com/gaussian-process-kernels-96bafb4dd63e/" class="">see here for a practical example using Mauna Loa data</a> in scikit-learn. Kernels can also be bounded for more efficient computation—for instance, circular and spherical kernels give rise to sparse gram matrices that can be reordered and solved by efficient sparse solvers; the Matérn kernel (<cite class="" data-state="closed"><a href="https://doi.org/10.1007/978-1-4615-7892-5" target="_blank" rel="noreferrer" class="hover-link">Matérn, 1960</a></cite>) can be modified to do the same. Separable non-stationary kernels can be written as a Kronecker tensor product (<cite class="" data-state="closed"><a href="https://doi.org/10.5555/944790.944815" target="_blank" rel="noreferrer" class="hover-link">Genton (2002)</a></cite>), and solved in circulant matrixes by efficient Fourier methods (<cite class="" data-state="closed"><a href="https://doi.org/10.48550/ARXIV.1503.01057" target="_blank" rel="noreferrer" class="hover-link">Wilson &amp; Nickisch (2015)</a></cite>).</p><p>Although Gaussian Processes is the more general statistical term for covariance methods of prediction, the practice and term of kriging predates Gaussian Processes. Thus, to explain the history and theory of Gaussian Processes, we’ll start with kriging first.</p></div><div id="pP3uq29nGv" class="relative group/block"><h3 id="what-is-kriging-informally" class="relative group"><span class="heading-text">What is kriging (informally)?</span><a class="no-underline text-inherit hover:text-inherit inline-block w-0 px-0 translate-x-[10px] font-normal select-none transition-opacity opacity-0 focus:opacity-100 group-hover:opacity-70" href="#what-is-kriging-informally" title="Link to this Section" aria-label="Link to this Section">¶</a></h3><p>Generally speaking, most people use kriging as an interpolator. Classic interpolators can be split into ‘<em>estimators</em>’ and ‘<em>predictors</em>’; this distinction (in line with <cite class="" data-state="closed"><a href="https://doi.org/10.1007/bf00889887" target="_blank" rel="noreferrer" class="hover-link">Cressie, 1990</a></cite>) mainly applies to highlight that ‘<em>estimators</em>’ provide an estimate of the surface, while ‘<em>predictors</em>’ assign a prediction that is accompanied by measures of confidence (probability, confidence interval).</p><picture class=""><source srcSet="/build/03d1076e4e32f4695734b1167c5c65c6.webp" type="image/webp"/><img id="ACtPvxnC48" style="margin:0 auto" src="/build/03d1076e4e32f4695734b1167c5c65c6.jpeg" alt="image.jpg" data-canonical-url="https://github.com/YuePanEdward/PPE_Kriging/blob/main/figures/result_dense_dataset.jpg?raw=true"/></picture><p><em>Estimators including nearest neighbor, bilinear interpolation, and cubic spline (bottom), as compared with kriging predictions using three different kernels (top)</em></p><p>Traditional ‘<em>estimators</em>’ are of the fairly boring type that most are fairly familiar with— canonical examples are bilinear interpolation, Inverse Distance Weighting (IDW), cubic convolution, etc. Other non-traditional examples of ‘estimators’ include things like nearest and natural neighbor interpolation, which are appropriate for specific domain cases when you want to preserve original data values. If your <strong>goal</strong> is <strong>just</strong> interpolation <strong>and you have sufficient data</strong>, using an estimator is perfectly fine-- and fast! However, if your data is <strong>sparse</strong>, kriging starts to become more appealing:</p><picture class=""><source srcSet="/build/bdb989a18e2c78b76f49ebabc3b22a39.webp" type="image/webp"/><img id="WXPAo6CO42" style="margin:0 auto" src="/build/bdb989a18e2c78b76f49ebabc3b22a39.jpeg" alt="image.jpg" data-canonical-url="https://github.com/YuePanEdward/PPE_Kriging/blob/main/figures/result_sparse_dataset.jpg?raw=true"/></picture><p>This sparse estimation capability is why kriging was originally developed. Kriging is named after Danie G. Krige, who’s 1951 master’s thesis developed and described what we call ‘Ordinary Kriging’. Danie Krige was a prospector looking for gold in South Africa, an application that had sparse input measurements, and expensive sampling. Krige’s method was coined ‘kriging’ by the early 1960’s by French mathematician Georges Matheron, who formalized and expanded the method.</p><p>Of course, the other case where kriging is appealing is when you need to use the method as a <em>predictor</em>.</p></div><div id="WBn9jCR2hq" class="relative group/block"><h3 id="covariance-gold-and-the-variogram-model" class="relative group"><span class="heading-text">Covariance, Gold, and the variogram model</span><a class="no-underline text-inherit hover:text-inherit inline-block w-0 px-0 translate-x-[10px] font-normal select-none transition-opacity opacity-0 focus:opacity-100 group-hover:opacity-70" href="#covariance-gold-and-the-variogram-model" title="Link to this Section" aria-label="Link to this Section">¶</a></h3><picture class=""><source srcSet="/build/2ffed4862480bba556962ff294be9d78.webp" type="image/webp"/><img id="LIPhCTHJUo" style="margin:0 auto" src="/build/2ffed4862480bba556962ff294be9d78.gif" alt="image.gif" data-canonical-url="https://vsp.pnnl.gov/help/image/Variogram.gif"/></picture><p>Traditional kriging defines a <strong>model of covariance</strong> by fitting a function to the empirical ‘variogram’, which plots the variance between observations as a function of distance between those observations. The variogram ‘sill’ refers to variance between uncorrelated samples, and the ‘range’ is the lag-distance at which this paired observation decorrelation occurs. The ‘nugget’ refers to the intrinsic variance (i.e., the observational uncertainty) at distance zero-- that is, the variance of a single point observation with itself. The term ‘nugget’ is literally referring to ‘gold nugget’ in the context of prospecting; i.e., finding a ‘nugget’ of gold which has been displaced from the source gold deposit... just because a ‘nugget’ is present at a location, does not guarantee that you are coincident with the deposit <em>that generated that observation</em>; however, the expectation is that the nugget is close!</p><picture class=""><source srcSet="/build/ff8c410b251590af858bbaf80f9b6717.webp" type="image/webp"/><img id="pSudsWPz0s" style="margin:0 auto" src="/build/ff8c410b251590af858bbaf80f9b6717.png" alt="image.png" data-canonical-url="https://scikit-learn.org/stable/_images/sphx_glr_plot_gpr_noisy_targets_003.png"/></picture><p>Mathematically, specifying a ‘nugget’ value (or <code>alpha</code> in GP terminology) is effectively adding a constant to the diagonal of the covariance matrix such that each observation has some level of variance with itself. Doing this allows flexibility for the mean of the predictions to <em>not</em> intersect all of the observation points-- if covariance is set to zero along the diagonal, then any estimation will be a ‘rubber sheeting’ that ensures the output surface prediction passes through the original data points. Of course, we can also specify covariance <em>per observation</em> rather than as a constant along the diagonal, and selectively <em>down weight</em> low confidence observations.</p></div><div id="ihU90aclTc" class="relative group/block"><h3 id="what-i-use-gaussian-processes-for" class="relative group"><span class="heading-text">What I use Gaussian Processes for</span><a class="no-underline text-inherit hover:text-inherit inline-block w-0 px-0 translate-x-[10px] font-normal select-none transition-opacity opacity-0 focus:opacity-100 group-hover:opacity-70" href="#what-i-use-gaussian-processes-for" title="Link to this Section" aria-label="Link to this Section">¶</a></h3></div><div id="BQEiBJZXnE" class="relative group/block"><div class="flex sticky top-[80px] z-10 opacity-70 group-hover/block:opacity-100 group-hover/block:hidden"><div class="absolute top-0 -right-[28px] flex md:flex-col"></div></div><div class="hidden sticky top-[80px] z-10 opacity-70 group-hover/block:opacity-100 group-hover/block:flex"><div class="absolute top-0 -right-[28px] flex md:flex-col"></div></div><div class="relative group not-prose overflow-auto shadow hover:shadow-md dark:shadow-2xl dark:shadow-neutral-900 my-5 text-sm border border-l-4 border-l-blue-400 border-gray-200 dark:border-l-blue-400 dark:border-gray-800"><pre class="block p-3 hljs" style="background-color:unset"><code class="language-python" style="white-space:pre">%matplotlib inline</code></pre><button title="Copy to Clipboard" class="inline-flex items-center opacity-0 group-hover:opacity-100 hover:opacity-100 focus:opacity-100 active:opacity-100 cursor-pointer ml-2 transition-color duration-200 ease-in-out text-blue-400 hover:text-blue-500 absolute right-1 top-1" aria-pressed="false" aria-label="Copy code to clipboard"><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" width="24" height="24"><path stroke-linecap="round" stroke-linejoin="round" d="M15.75 17.25v3.375c0 .621-.504 1.125-1.125 1.125h-9.75a1.125 1.125 0 0 1-1.125-1.125V7.875c0-.621.504-1.125 1.125-1.125H6.75a9.06 9.06 0 0 1 1.5.124m7.5 10.376h3.375c.621 0 1.125-.504 1.125-1.125V11.25c0-4.46-3.243-8.161-7.5-8.876a9.06 9.06 0 0 0-1.5-.124H9.375c-.621 0-1.125.504-1.125 1.125v3.5m7.5 10.375H9.375a1.125 1.125 0 0 1-1.125-1.125v-9.25m12 6.625v-1.875a3.375 3.375 0 0 0-3.375-3.375h-1.5a1.125 1.125 0 0 1-1.125-1.125v-1.5a3.375 3.375 0 0 0-3.375-3.375H9.75"></path></svg></button></div><div data-mdast-node-id="ICRFtme3r_yimzT5-UzZF" class="max-w-full overflow-y-visible overflow-x-auto m-0 group not-prose relative text-left"></div></div><div id="akpDx99NAa" class="relative group/block"><div class="flex sticky top-[80px] z-10 opacity-70 group-hover/block:opacity-100 group-hover/block:hidden"><div class="absolute top-0 -right-[28px] flex md:flex-col"></div></div><div class="hidden sticky top-[80px] z-10 opacity-70 group-hover/block:opacity-100 group-hover/block:flex"><div class="absolute top-0 -right-[28px] flex md:flex-col"></div></div><div class="relative group not-prose overflow-auto shadow hover:shadow-md dark:shadow-2xl dark:shadow-neutral-900 my-5 text-sm border border-l-4 border-l-blue-400 border-gray-200 dark:border-l-blue-400 dark:border-gray-800"><pre class="block p-3 hljs" style="background-color:unset"><code class="language-python" style="white-space:pre">import matplotlib.pyplot as plt
import matplotlib as mpl
import pandas as pd
import numpy as np
from tqdm.notebook import tqdm
from osgeo import osr
import pyproj
from sklearn.gaussian_process import GaussianProcessRegressor
from sklearn.gaussian_process.kernels import Matern, WhiteKernel, RBF</code></pre><button title="Copy to Clipboard" class="inline-flex items-center opacity-0 group-hover:opacity-100 hover:opacity-100 focus:opacity-100 active:opacity-100 cursor-pointer ml-2 transition-color duration-200 ease-in-out text-blue-400 hover:text-blue-500 absolute right-1 top-1" aria-pressed="false" aria-label="Copy code to clipboard"><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" width="24" height="24"><path stroke-linecap="round" stroke-linejoin="round" d="M15.75 17.25v3.375c0 .621-.504 1.125-1.125 1.125h-9.75a1.125 1.125 0 0 1-1.125-1.125V7.875c0-.621.504-1.125 1.125-1.125H6.75a9.06 9.06 0 0 1 1.5.124m7.5 10.376h3.375c.621 0 1.125-.504 1.125-1.125V11.25c0-4.46-3.243-8.161-7.5-8.876a9.06 9.06 0 0 0-1.5-.124H9.375c-.621 0-1.125.504-1.125 1.125v3.5m7.5 10.375H9.375a1.125 1.125 0 0 1-1.125-1.125v-9.25m12 6.625v-1.875a3.375 3.375 0 0 0-3.375-3.375h-1.5a1.125 1.125 0 0 1-1.125-1.125v-1.5a3.375 3.375 0 0 0-3.375-3.375H9.75"></path></svg></button></div><div data-mdast-node-id="SHU3pfnBQ0m1kzhMaHJMU" class="max-w-full overflow-y-visible overflow-x-auto m-0 group not-prose relative text-left"></div></div><div id="ntFT3sem7p" class="relative group/block"><div class="flex sticky top-[80px] z-10 opacity-70 group-hover/block:opacity-100 group-hover/block:hidden"><div class="absolute top-0 -right-[28px] flex md:flex-col"></div></div><div class="hidden sticky top-[80px] z-10 opacity-70 group-hover/block:opacity-100 group-hover/block:flex"><div class="absolute top-0 -right-[28px] flex md:flex-col"></div></div><div class="relative group not-prose overflow-auto shadow hover:shadow-md dark:shadow-2xl dark:shadow-neutral-900 my-5 text-sm border border-l-4 border-l-blue-400 border-gray-200 dark:border-l-blue-400 dark:border-gray-800"><pre class="block p-3 hljs" style="background-color:unset"><code class="language-python" style="white-space:pre">rng = np.random.default_rng() # numpy sampling API
#np.random.seed(1234)
#np.random.seed(55)
np.random.seed(123)</code></pre><button title="Copy to Clipboard" class="inline-flex items-center opacity-0 group-hover:opacity-100 hover:opacity-100 focus:opacity-100 active:opacity-100 cursor-pointer ml-2 transition-color duration-200 ease-in-out text-blue-400 hover:text-blue-500 absolute right-1 top-1" aria-pressed="false" aria-label="Copy code to clipboard"><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" width="24" height="24"><path stroke-linecap="round" stroke-linejoin="round" d="M15.75 17.25v3.375c0 .621-.504 1.125-1.125 1.125h-9.75a1.125 1.125 0 0 1-1.125-1.125V7.875c0-.621.504-1.125 1.125-1.125H6.75a9.06 9.06 0 0 1 1.5.124m7.5 10.376h3.375c.621 0 1.125-.504 1.125-1.125V11.25c0-4.46-3.243-8.161-7.5-8.876a9.06 9.06 0 0 0-1.5-.124H9.375c-.621 0-1.125.504-1.125 1.125v3.5m7.5 10.375H9.375a1.125 1.125 0 0 1-1.125-1.125v-9.25m12 6.625v-1.875a3.375 3.375 0 0 0-3.375-3.375h-1.5a1.125 1.125 0 0 1-1.125-1.125v-1.5a3.375 3.375 0 0 0-3.375-3.375H9.75"></path></svg></button></div><div data-mdast-node-id="TPzZZ_3mcMCEOo7O8Ts9X" class="max-w-full overflow-y-visible overflow-x-auto m-0 group not-prose relative text-left"></div></div><div id="ozm1Uc6m60" class="relative group/block"><div class="flex sticky top-[80px] z-10 opacity-70 group-hover/block:opacity-100 group-hover/block:hidden"><div class="absolute top-0 -right-[28px] flex md:flex-col"></div></div><div class="hidden sticky top-[80px] z-10 opacity-70 group-hover/block:opacity-100 group-hover/block:flex"><div class="absolute top-0 -right-[28px] flex md:flex-col"></div></div><div class="relative group not-prose overflow-auto shadow hover:shadow-md dark:shadow-2xl dark:shadow-neutral-900 my-5 text-sm border border-l-4 border-l-blue-400 border-gray-200 dark:border-l-blue-400 dark:border-gray-800"><pre class="block p-3 hljs" style="background-color:unset"><code class="language-python" style="white-space:pre">data = pd.HDFStore(&quot;./Z62SU06&quot; + &quot;.h5&quot;, &#x27;r&#x27;) # ICESat data
coordlist = data[&#x27;coords&#x27;] # Needed for distance calculations / plotting
df_indices = data[&#x27;indices&#x27;] # UUID to link to observations to slope retrievals
df_corr = data[&#x27;corr&#x27;] # Filter and weight data

gslope = np.load(&#x27;./General_slopes.npy&#x27;) # Sub ICESat footprint slope retrievals
mean_slope = np.zeros(len(coordlist))
std_slope = np.zeros(len(coordlist))

# Merge and aggregate slope
for i in tqdm(range(len(coordlist))):
    sweights = np.array(df_corr.iloc[i].values)
    weightidx = np.isfinite(sweights)
    sweights = np.abs(sweights[weightidx])
    sidx = df_indices.iloc[i].values[weightidx]
    sidx = np.array(sidx, dtype=int)
    mean_slope[i] = np.average(gslope[sidx], weights=sweights)
    std_slope[i] = np.std(gslope[sidx])</code></pre><button title="Copy to Clipboard" class="inline-flex items-center opacity-0 group-hover:opacity-100 hover:opacity-100 focus:opacity-100 active:opacity-100 cursor-pointer ml-2 transition-color duration-200 ease-in-out text-blue-400 hover:text-blue-500 absolute right-1 top-1" aria-pressed="false" aria-label="Copy code to clipboard"><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" width="24" height="24"><path stroke-linecap="round" stroke-linejoin="round" d="M15.75 17.25v3.375c0 .621-.504 1.125-1.125 1.125h-9.75a1.125 1.125 0 0 1-1.125-1.125V7.875c0-.621.504-1.125 1.125-1.125H6.75a9.06 9.06 0 0 1 1.5.124m7.5 10.376h3.375c.621 0 1.125-.504 1.125-1.125V11.25c0-4.46-3.243-8.161-7.5-8.876a9.06 9.06 0 0 0-1.5-.124H9.375c-.621 0-1.125.504-1.125 1.125v3.5m7.5 10.375H9.375a1.125 1.125 0 0 1-1.125-1.125v-9.25m12 6.625v-1.875a3.375 3.375 0 0 0-3.375-3.375h-1.5a1.125 1.125 0 0 1-1.125-1.125v-1.5a3.375 3.375 0 0 0-3.375-3.375H9.75"></path></svg></button></div><div data-mdast-node-id="Pk0Ci0_hsE4hZga7Fdwsq" class="max-w-full overflow-y-visible overflow-x-auto m-0 group not-prose relative text-left mb-5"><div><div class="p-2.5">Loading...</div></div></div></div><div id="GF3D6gNZYx" class="relative group/block"><p>This example is meant to be larger than a ‘toy’ dataset, but still small enough to interact with and demonstrate. Our input data consist of 23,359 observations (from the summer of 2006), which are within footprint slope retrievals from the first ICESat mission (which flew from 2003 to 2009, although laser power was strongest in the first three years).</p><p>Here’s what the data looks like:</p></div><div id="eKtuoou0FG" class="relative group/block"><div class="flex sticky top-[80px] z-10 opacity-70 group-hover/block:opacity-100 group-hover/block:hidden"><div class="absolute top-0 -right-[28px] flex md:flex-col"></div></div><div class="hidden sticky top-[80px] z-10 opacity-70 group-hover/block:opacity-100 group-hover/block:flex"><div class="absolute top-0 -right-[28px] flex md:flex-col"></div></div><div class="relative group not-prose overflow-auto shadow hover:shadow-md dark:shadow-2xl dark:shadow-neutral-900 my-5 text-sm border border-l-4 border-l-blue-400 border-gray-200 dark:border-l-blue-400 dark:border-gray-800"><pre class="block p-3 hljs" style="background-color:unset"><code class="language-python" style="white-space:pre">fig, ax = plt.subplots()
im = ax.scatter(coordlist.lon, coordlist.lat, c=mean_slope, s=std_slope**2)
im.set_clim(min(mean_slope), max(mean_slope))
fig.colorbar(im, ax=ax, label=&quot;Degrees of slope \n (points scaled by retrieval variance)&quot;)
plt.show()</code></pre><button title="Copy to Clipboard" class="inline-flex items-center opacity-0 group-hover:opacity-100 hover:opacity-100 focus:opacity-100 active:opacity-100 cursor-pointer ml-2 transition-color duration-200 ease-in-out text-blue-400 hover:text-blue-500 absolute right-1 top-1" aria-pressed="false" aria-label="Copy code to clipboard"><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" width="24" height="24"><path stroke-linecap="round" stroke-linejoin="round" d="M15.75 17.25v3.375c0 .621-.504 1.125-1.125 1.125h-9.75a1.125 1.125 0 0 1-1.125-1.125V7.875c0-.621.504-1.125 1.125-1.125H6.75a9.06 9.06 0 0 1 1.5.124m7.5 10.376h3.375c.621 0 1.125-.504 1.125-1.125V11.25c0-4.46-3.243-8.161-7.5-8.876a9.06 9.06 0 0 0-1.5-.124H9.375c-.621 0-1.125.504-1.125 1.125v3.5m7.5 10.375H9.375a1.125 1.125 0 0 1-1.125-1.125v-9.25m12 6.625v-1.875a3.375 3.375 0 0 0-3.375-3.375h-1.5a1.125 1.125 0 0 1-1.125-1.125v-1.5a3.375 3.375 0 0 0-3.375-3.375H9.75"></path></svg></button></div><div data-mdast-node-id="vBPltrFfKrZarFt28AnXM" class="max-w-full overflow-y-visible overflow-x-auto m-0 group not-prose relative text-left mb-5"><img src="/build/7809e52609e3ddbec2e8e4baee69beb1.png" alt="&lt;Figure size 640x480 with 2 Axes&gt;"/></div></div><div id="AyxRXfSb7d" class="relative group/block"><p>This is an interesting case of geostatistics because the sampling is quite odd-- the along track resolution is dense, but the across track resolution is sparse. Most of the code is actually setting up the <strong>source</strong> and <strong>target</strong> coordinate systems for the model. The input observational data is irregularly spaced and in lat/lon coordinates, but we want our distance measurements to be in euclidean space and output to a grid.</p><p>We also want to ‘clip’ the results to a drainage basin. This is for two reasons-- first, the drainage basin boundries are of zero surface slope and provide a physically meaningful way to bound, divide, and tile the analysis. And second, covariance functions are expensive, so clipping and masking the edges of our area of interest helps things run faster... it also makes the output look good!</p></div><div id="rjGV22FnLQ" class="relative group/block"><div class="flex sticky top-[80px] z-10 opacity-70 group-hover/block:opacity-100 group-hover/block:hidden"><div class="absolute top-0 -right-[28px] flex md:flex-col"></div></div><div class="hidden sticky top-[80px] z-10 opacity-70 group-hover/block:opacity-100 group-hover/block:flex"><div class="absolute top-0 -right-[28px] flex md:flex-col"></div></div><div class="relative group not-prose overflow-auto shadow hover:shadow-md dark:shadow-2xl dark:shadow-neutral-900 my-5 text-sm border border-l-4 border-l-blue-400 border-gray-200 dark:border-l-blue-400 dark:border-gray-800"><pre class="block p-3 hljs" style="background-color:unset"><code class="language-python" style="white-space:pre"># Projection object
ds = osr.SpatialReference()
ds.ImportFromEPSG(3411) # polar projection
ds.ExportToProj4()
p2 = pyproj.Proj(ds.ExportToProj4())

# Observations to meters from lat / lon
X, Y = p2(np.array(coordlist.lon),
          np.array(coordlist.lat))
# To vector form sklearn
coords_m = np.ones((len(coordlist),2))
coords_m[:,0] = X
coords_m[:,1] = Y

# Drainage basin boundries
zwally = pd.read_csv(&#x27;./GrnDrainageSystems_Ekholm.txt&#x27;,
                     sep=r&quot;\s+&quot;, names=[&#x27;basin&#x27;, &#x27;lat&#x27;,&#x27;long&#x27;])
basin = &#x27;6.2&#x27;
LL = zip(zwally[zwally.basin == float(basin)].long,
         zwally[zwally.basin == float(basin)].lat)
LL = list(LL)
# Convert basin boundries to meters from lat / lon
pX, pY = p2(np.array(LL)[:,0],
            np.array(LL)[:,1])
# Polygon object for masking
Z = mpl.path.Path(list(zip(pX, pY)))

# Setting up kriging grid
x1, y1 = np.meshgrid(np.r_[round(min(pX), -2) - 2500:round(max(pX), -2) + 2500:5000],
                     np.r_[round(min(pY), -2) - 2500:round(max(pY), -2) + 2500:5000])
kcoords = np.vstack([x1.ravel(),y1.ravel()]).T

# Masking kriging grid
Zidx = Z.contains_points(kcoords[:])
target_c = kcoords[Zidx] # Target coordinates
x1.shape, len(target_c)</code></pre><button title="Copy to Clipboard" class="inline-flex items-center opacity-0 group-hover:opacity-100 hover:opacity-100 focus:opacity-100 active:opacity-100 cursor-pointer ml-2 transition-color duration-200 ease-in-out text-blue-400 hover:text-blue-500 absolute right-1 top-1" aria-pressed="false" aria-label="Copy code to clipboard"><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" width="24" height="24"><path stroke-linecap="round" stroke-linejoin="round" d="M15.75 17.25v3.375c0 .621-.504 1.125-1.125 1.125h-9.75a1.125 1.125 0 0 1-1.125-1.125V7.875c0-.621.504-1.125 1.125-1.125H6.75a9.06 9.06 0 0 1 1.5.124m7.5 10.376h3.375c.621 0 1.125-.504 1.125-1.125V11.25c0-4.46-3.243-8.161-7.5-8.876a9.06 9.06 0 0 0-1.5-.124H9.375c-.621 0-1.125.504-1.125 1.125v3.5m7.5 10.375H9.375a1.125 1.125 0 0 1-1.125-1.125v-9.25m12 6.625v-1.875a3.375 3.375 0 0 0-3.375-3.375h-1.5a1.125 1.125 0 0 1-1.125-1.125v-1.5a3.375 3.375 0 0 0-3.375-3.375H9.75"></path></svg></button></div><div data-mdast-node-id="N8MjkmYRO8ZjlwnplQN7N" class="max-w-full overflow-y-visible overflow-x-auto m-0 group not-prose relative text-left mb-5"><div class="font-mono text-sm whitespace-pre-wrap"><code><span>((108, 110), 5600)</span></code></div></div></div><div id="rXQUZcVHE5" class="relative group/block"><p>At this point, we’ve setup a 2-km grid to predict on that’s 267 by 273 (a little over 500km per side), which after masking has 34,984 target coordinate locations to predict at. The actual Gaussian Process model specification is fairly short:</p></div><div id="RVLVmJFMLQ" class="relative group/block"><div class="flex sticky top-[80px] z-10 opacity-70 group-hover/block:opacity-100 group-hover/block:hidden"><div class="absolute top-0 -right-[28px] flex md:flex-col"></div></div><div class="hidden sticky top-[80px] z-10 opacity-70 group-hover/block:opacity-100 group-hover/block:flex"><div class="absolute top-0 -right-[28px] flex md:flex-col"></div></div><div class="relative group not-prose overflow-auto shadow hover:shadow-md dark:shadow-2xl dark:shadow-neutral-900 my-5 text-sm border border-l-4 border-l-blue-400 border-gray-200 dark:border-l-blue-400 dark:border-gray-800"><pre class="block p-3 hljs" style="background-color:unset"><code class="language-python" style="white-space:pre">ind = np.array(range(0,len(coordlist)), dtype=int)
idxs = np.random.choice(ind, size=4000)</code></pre><button title="Copy to Clipboard" class="inline-flex items-center opacity-0 group-hover:opacity-100 hover:opacity-100 focus:opacity-100 active:opacity-100 cursor-pointer ml-2 transition-color duration-200 ease-in-out text-blue-400 hover:text-blue-500 absolute right-1 top-1" aria-pressed="false" aria-label="Copy code to clipboard"><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" width="24" height="24"><path stroke-linecap="round" stroke-linejoin="round" d="M15.75 17.25v3.375c0 .621-.504 1.125-1.125 1.125h-9.75a1.125 1.125 0 0 1-1.125-1.125V7.875c0-.621.504-1.125 1.125-1.125H6.75a9.06 9.06 0 0 1 1.5.124m7.5 10.376h3.375c.621 0 1.125-.504 1.125-1.125V11.25c0-4.46-3.243-8.161-7.5-8.876a9.06 9.06 0 0 0-1.5-.124H9.375c-.621 0-1.125.504-1.125 1.125v3.5m7.5 10.375H9.375a1.125 1.125 0 0 1-1.125-1.125v-9.25m12 6.625v-1.875a3.375 3.375 0 0 0-3.375-3.375h-1.5a1.125 1.125 0 0 1-1.125-1.125v-1.5a3.375 3.375 0 0 0-3.375-3.375H9.75"></path></svg></button></div><div data-mdast-node-id="74PMpFVsOKrXjKewT-p9x" class="max-w-full overflow-y-visible overflow-x-auto m-0 group not-prose relative text-left"></div></div><div id="TDffK0upLo" class="relative group/block"><div class="flex sticky top-[80px] z-10 opacity-70 group-hover/block:opacity-100 group-hover/block:hidden"><div class="absolute top-0 -right-[28px] flex md:flex-col"></div></div><div class="hidden sticky top-[80px] z-10 opacity-70 group-hover/block:opacity-100 group-hover/block:flex"><div class="absolute top-0 -right-[28px] flex md:flex-col"></div></div><div class="relative group not-prose overflow-auto shadow hover:shadow-md dark:shadow-2xl dark:shadow-neutral-900 my-5 text-sm border border-l-4 border-l-blue-400 border-gray-200 dark:border-l-blue-400 dark:border-gray-800"><pre class="block p-3 hljs" style="background-color:unset"><code class="language-python" style="white-space:pre">%%time
noise = WhiteKernel(noise_level=.5)
rbf = 3 * RBF(length_scale=[80000,80000])
kern = 2.0 * Matern(length_scale=[80000,80000], length_scale_bounds=(1e3, 1e6),
                        nu=0.5)
gp1 = GaussianProcessRegressor(kernel=rbf+kern+noise, alpha=std_slope[idxs]**2, optimizer=None).fit(coords_m[idxs], mean_slope[idxs])</code></pre><button title="Copy to Clipboard" class="inline-flex items-center opacity-0 group-hover:opacity-100 hover:opacity-100 focus:opacity-100 active:opacity-100 cursor-pointer ml-2 transition-color duration-200 ease-in-out text-blue-400 hover:text-blue-500 absolute right-1 top-1" aria-pressed="false" aria-label="Copy code to clipboard"><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" width="24" height="24"><path stroke-linecap="round" stroke-linejoin="round" d="M15.75 17.25v3.375c0 .621-.504 1.125-1.125 1.125h-9.75a1.125 1.125 0 0 1-1.125-1.125V7.875c0-.621.504-1.125 1.125-1.125H6.75a9.06 9.06 0 0 1 1.5.124m7.5 10.376h3.375c.621 0 1.125-.504 1.125-1.125V11.25c0-4.46-3.243-8.161-7.5-8.876a9.06 9.06 0 0 0-1.5-.124H9.375c-.621 0-1.125.504-1.125 1.125v3.5m7.5 10.375H9.375a1.125 1.125 0 0 1-1.125-1.125v-9.25m12 6.625v-1.875a3.375 3.375 0 0 0-3.375-3.375h-1.5a1.125 1.125 0 0 1-1.125-1.125v-1.5a3.375 3.375 0 0 0-3.375-3.375H9.75"></path></svg></button></div><div data-mdast-node-id="yPbObijNp_rhKwJBzItjC" class="max-w-full overflow-y-visible overflow-x-auto m-0 group not-prose relative text-left mb-5"><div><pre class="text-sm font-thin font-system"><code><span>CPU times: user 7.48 s, sys: 984 ms, total: 8.46 s
Wall time: 1.29 s
</span></code></pre></div></div></div><div id="aExPEF75JT" class="relative group/block"><p>We are specifying a <code>Matern</code> kernel to calculate and estimate our covarience, which is defined by the single parameter <code>nu</code>; this parameter controls how smooth the fuctions are within our prior distribution of possible surface functions. It is set at 0.5 (i.e., ‘1 / 2’, equivelent the absolute exponential kernel) to allow rough, non-differentiable candidate functions; a <code>nu=1.5</code> (3 / 2) will select from functions that are once differentiable, <code>nu=2.5</code> (5 / 2) will select from functions that are twice differentiable, and <code>nu=inf</code> will converge to the infinately differentiable RBF kernel.</p><p>The <code>length_scale</code> parameter would typically be optimized during model fit based on the spatial structure of the data... however, because our input data is heavily unbalanced (i.e., dense in the along track direction, sparse in the across track), hyper-parameter optimization sets a length scale that is too short, so it is fixed at 80km, with similar settings applied for the <code>length_scale_bounds</code>.</p><p>After model specification, at <code>fit</code> time we provide the coordinates, and slope values, along with an <code>alpha</code> that is set to varience of slope retrieval (i.e., estimates of varience per observation).</p><p>Doubling the number of observations (by adding a second summer of orbits) pushes the model fit time from under two minutes to about a half hour (although some of this is due to the higher memory footprint and pressure causing the OS to begin swapping to disk).</p><p>We can get the mean surface estimate and target-to-target covariances with the following:</p></div><div id="oNw6UDC98g" class="relative group/block"><div class="flex sticky top-[80px] z-10 opacity-70 group-hover/block:opacity-100 group-hover/block:hidden"><div class="absolute top-0 -right-[28px] flex md:flex-col"></div></div><div class="hidden sticky top-[80px] z-10 opacity-70 group-hover/block:opacity-100 group-hover/block:flex"><div class="absolute top-0 -right-[28px] flex md:flex-col"></div></div><div class="relative group not-prose overflow-auto shadow hover:shadow-md dark:shadow-2xl dark:shadow-neutral-900 my-5 text-sm border border-l-4 border-l-blue-400 border-gray-200 dark:border-l-blue-400 dark:border-gray-800"><pre class="block p-3 hljs" style="background-color:unset"><code class="language-python" style="white-space:pre">%%time
y_mean, y_cov = gp1.predict(target_c, return_cov=True)</code></pre><button title="Copy to Clipboard" class="inline-flex items-center opacity-0 group-hover:opacity-100 hover:opacity-100 focus:opacity-100 active:opacity-100 cursor-pointer ml-2 transition-color duration-200 ease-in-out text-blue-400 hover:text-blue-500 absolute right-1 top-1" aria-pressed="false" aria-label="Copy code to clipboard"><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" width="24" height="24"><path stroke-linecap="round" stroke-linejoin="round" d="M15.75 17.25v3.375c0 .621-.504 1.125-1.125 1.125h-9.75a1.125 1.125 0 0 1-1.125-1.125V7.875c0-.621.504-1.125 1.125-1.125H6.75a9.06 9.06 0 0 1 1.5.124m7.5 10.376h3.375c.621 0 1.125-.504 1.125-1.125V11.25c0-4.46-3.243-8.161-7.5-8.876a9.06 9.06 0 0 0-1.5-.124H9.375c-.621 0-1.125.504-1.125 1.125v3.5m7.5 10.375H9.375a1.125 1.125 0 0 1-1.125-1.125v-9.25m12 6.625v-1.875a3.375 3.375 0 0 0-3.375-3.375h-1.5a1.125 1.125 0 0 1-1.125-1.125v-1.5a3.375 3.375 0 0 0-3.375-3.375H9.75"></path></svg></button></div><div data-mdast-node-id="BY6R9rBIRK9fzO42ibqbM" class="max-w-full overflow-y-visible overflow-x-auto m-0 group not-prose relative text-left mb-5"><div><pre class="text-sm font-thin font-system"><code><span>CPU times: user 12.5 s, sys: 1.79 s, total: 14.3 s
Wall time: 2.09 s
</span></code></pre></div></div></div><div id="J14v7pOdED" class="relative group/block"><p>The mean predictions need to be reshaped before plotting:</p></div><div id="BJdlDUYnSv" class="relative group/block"><div class="flex sticky top-[80px] z-10 opacity-70 group-hover/block:opacity-100 group-hover/block:hidden"><div class="absolute top-0 -right-[28px] flex md:flex-col"></div></div><div class="hidden sticky top-[80px] z-10 opacity-70 group-hover/block:opacity-100 group-hover/block:flex"><div class="absolute top-0 -right-[28px] flex md:flex-col"></div></div><div class="relative group not-prose overflow-auto shadow hover:shadow-md dark:shadow-2xl dark:shadow-neutral-900 my-5 text-sm border border-l-4 border-l-blue-400 border-gray-200 dark:border-l-blue-400 dark:border-gray-800"><pre class="block p-3 hljs" style="background-color:unset"><code class="language-python" style="white-space:pre"># slope
results1 = np.ones(len(kcoords)) *np.nan
results1[Zidx] =  y_mean
show_res1 = results1.reshape((x1.shape))
plt.imshow(np.flipud(show_res1), vmin=0, vmax=10)
plt.colorbar()
plt.show()</code></pre><button title="Copy to Clipboard" class="inline-flex items-center opacity-0 group-hover:opacity-100 hover:opacity-100 focus:opacity-100 active:opacity-100 cursor-pointer ml-2 transition-color duration-200 ease-in-out text-blue-400 hover:text-blue-500 absolute right-1 top-1" aria-pressed="false" aria-label="Copy code to clipboard"><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" width="24" height="24"><path stroke-linecap="round" stroke-linejoin="round" d="M15.75 17.25v3.375c0 .621-.504 1.125-1.125 1.125h-9.75a1.125 1.125 0 0 1-1.125-1.125V7.875c0-.621.504-1.125 1.125-1.125H6.75a9.06 9.06 0 0 1 1.5.124m7.5 10.376h3.375c.621 0 1.125-.504 1.125-1.125V11.25c0-4.46-3.243-8.161-7.5-8.876a9.06 9.06 0 0 0-1.5-.124H9.375c-.621 0-1.125.504-1.125 1.125v3.5m7.5 10.375H9.375a1.125 1.125 0 0 1-1.125-1.125v-9.25m12 6.625v-1.875a3.375 3.375 0 0 0-3.375-3.375h-1.5a1.125 1.125 0 0 1-1.125-1.125v-1.5a3.375 3.375 0 0 0-3.375-3.375H9.75"></path></svg></button></div><div data-mdast-node-id="2hLPICBkJY4pQ_tJgrvbs" class="max-w-full overflow-y-visible overflow-x-auto m-0 group not-prose relative text-left mb-5"><img src="/build/e4355c71dd40f2cba42c72ffa8a053c5.png" alt="&lt;Figure size 640x480 with 2 Axes&gt;"/></div></div><div id="rjctTY6jpy" class="relative group/block"><h3 id="what-is-kriging-formally" class="relative group"><span class="heading-text">What is kriging (formally)?</span><a class="no-underline text-inherit hover:text-inherit inline-block w-0 px-0 translate-x-[10px] font-normal select-none transition-opacity opacity-0 focus:opacity-100 group-hover:opacity-70" href="#what-is-kriging-formally" title="Link to this Section" aria-label="Link to this Section">¶</a></h3><p>Mathematically, kriging is the Best Unbiased Linear <strong>Predictor</strong> (<cite class="" data-state="closed"><a href="https://doi.org/10.1007/bf02067214" target="_blank" rel="noreferrer" class="hover-link">Journel (1977)</a></cite> ; <cite class="" data-state="closed"><a href="https://doi.org/10.1007/bf00889887" target="_blank" rel="noreferrer" class="hover-link">Cressie (1990)</a></cite> ; <cite class="" data-state="closed"><a href="https://doi.org/10.1080/00401706.1993.10485354" target="_blank" rel="noreferrer" class="hover-link">Handcock &amp; Stein (1993)</a></cite>), and provides the Best Linear Unbiased Prediction, or BLUP; this means that kriging prediction is a linear combination of weighted observations at point p that minimizes prediction variance. Note that this is different (but related) to the Best Linear Unbiased <strong>Estimation</strong>, or BLUE... although when using kriging to <em>estimate</em> a quantity, the results will be equivilent to the BLUE, which is why kriging is often conceptually understood as equivalent to spatially weighted generalized least squares regression. There are of course various flavors of kriging (simple, ordinary, universal, etc.) (see <cite class="" data-state="closed"><a href="https://doi.org/10.1007/bf02067214" target="_blank" rel="noreferrer" class="hover-link">Journel</a></cite>), but below is mathematical formulation for simple kriging (other flavors are similar):</p><p>Given N observations (s1…sn), and CovF(distance) covariance function, calculate D distances of N observations; note the convention of using <span><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>t</mi></mrow><annotation encoding="application/x-tex">t</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6151em;"></span><span class="mord mathnormal">t</span></span></span></span></span> for <em>target</em> and <span><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>s</mi></mrow><annotation encoding="application/x-tex">s</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.4306em;"></span><span class="mord mathnormal">s</span></span></span></span></span> for <em>source</em>:</p><div id="G4vKIYjzza" class="flex my-5 group"><div class="flex-grow overflow-x-auto overflow-y-hidden"><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><mi>D</mi><mo stretchy="false">(</mo><msub><mi>s</mi><mn>1</mn></msub><mi mathvariant="normal">.</mi><mi mathvariant="normal">.</mi><mi mathvariant="normal">.</mi><msub><mi>s</mi><mi>n</mi></msub><mo separator="true">,</mo><msub><mi>s</mi><mn>1</mn></msub><mi mathvariant="normal">.</mi><mi mathvariant="normal">.</mi><mi mathvariant="normal">.</mi><msub><mi>s</mi><mi>n</mi></msub><mo stretchy="false">)</mo><mo>=</mo><msub><mi>D</mi><mrow><mi>o</mi><mi>b</mi><mi>s</mi></mrow></msub></mrow><annotation encoding="application/x-tex">D(s_1 ... s_n, s_1 ... s_n) = D_{obs}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal" style="margin-right:0.02778em;">D</span><span class="mopen">(</span><span class="mord"><span class="mord mathnormal">s</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3011em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mord">...</span><span class="mord"><span class="mord mathnormal">s</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.1514em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">n</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord"><span class="mord mathnormal">s</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3011em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mord">...</span><span class="mord"><span class="mord mathnormal">s</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.1514em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">n</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:0.8333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.02778em;">D</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3361em;"><span style="top:-2.55em;margin-left:-0.0278em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">o</span><span class="mord mathnormal mtight">b</span><span class="mord mathnormal mtight">s</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span></span></div><div class="relative self-center flex-none pl-2 m-0 text-right select-none"><a class="no-underline text-inherit hover:text-inherit text-inherit hover:text-inherit select-none hover:underline" href="#G4vKIYjzza" title="Link to this Equation" aria-label="Link to this Equation">(<!-- -->1<!-- -->)</a></div></div><div id="YGVK1dxu8i" class="flex my-5 group"><div class="flex-grow overflow-x-auto overflow-y-hidden"><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><msub><mi>C</mi><mrow><mi>o</mi><mi>b</mi><mi>s</mi></mrow></msub><mo>=</mo><msub><mi>f</mi><mrow><mi>c</mi><mi>o</mi><mi>v</mi></mrow></msub><mo stretchy="false">(</mo><msub><mi>D</mi><mrow><mi>o</mi><mi>b</mi><mi>s</mi></mrow></msub><mo stretchy="false">)</mo><mspace width="1em"/><mtext>or</mtext><mspace width="1em"/><mi>C</mi><mo stretchy="false">(</mo><msub><mi mathvariant="bold">x</mi><mi>n</mi></msub><mo separator="true">,</mo><msub><mi mathvariant="bold">x</mi><mi>m</mi></msub><mo stretchy="false">)</mo><mo>=</mo><mi>k</mi><mo stretchy="false">(</mo><msub><mi mathvariant="bold">x</mi><mi>n</mi></msub><mo separator="true">,</mo><msub><mi mathvariant="bold">x</mi><mi>m</mi></msub><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">C_{obs} = f_{cov}(D_{obs}) \quad \textrm{or} \quad C(\mathbf{x}_n, \mathbf{x}_m) = k(\mathbf{x}_n, \mathbf{x}_m)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.07153em;">C</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3361em;"><span style="top:-2.55em;margin-left:-0.0715em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">o</span><span class="mord mathnormal mtight">b</span><span class="mord mathnormal mtight">s</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.10764em;">f</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.1514em;"><span style="top:-2.55em;margin-left:-0.1076em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">co</span><span class="mord mathnormal mtight" style="margin-right:0.03588em;">v</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mopen">(</span><span class="mord"><span class="mord mathnormal" style="margin-right:0.02778em;">D</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3361em;"><span style="top:-2.55em;margin-left:-0.0278em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">o</span><span class="mord mathnormal mtight">b</span><span class="mord mathnormal mtight">s</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mclose">)</span><span class="mspace" style="margin-right:1em;"></span><span class="mord text"><span class="mord textrm">or</span></span><span class="mspace" style="margin-right:1em;"></span><span class="mord mathnormal" style="margin-right:0.07153em;">C</span><span class="mopen">(</span><span class="mord"><span class="mord mathbf">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.1514em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">n</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord"><span class="mord mathbf">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.1514em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">m</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal" style="margin-right:0.03148em;">k</span><span class="mopen">(</span><span class="mord"><span class="mord mathbf">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.1514em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">n</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord"><span class="mord mathbf">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.1514em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">m</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mclose">)</span></span></span></span></span></div><div class="relative self-center flex-none pl-2 m-0 text-right select-none"><a class="no-underline text-inherit hover:text-inherit text-inherit hover:text-inherit select-none hover:underline" href="#YGVK1dxu8i" title="Link to this Equation" aria-label="Link to this Equation">(<!-- -->2<!-- -->)</a></div></div><div class="relative group not-prose overflow-auto shadow hover:shadow-md dark:shadow-2xl dark:shadow-neutral-900 my-5 text-sm bg-stone-200/10"><pre class="block p-3 hljs" style="background-color:unset"><code class="language-text" style="white-space:pre">Dist(s1…sn, s1…sn) = Dobs  		# square distance matrix
Cobs = CovF(Dobs)                       # observation covarience, i.e., source-to-source cov</code></pre><button title="Copy to Clipboard" class="inline-flex items-center opacity-0 group-hover:opacity-100 hover:opacity-100 focus:opacity-100 active:opacity-100 cursor-pointer ml-2 transition-color duration-200 ease-in-out text-blue-400 hover:text-blue-500 absolute right-1 top-1" aria-pressed="false" aria-label="Copy code to clipboard"><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" width="24" height="24"><path stroke-linecap="round" stroke-linejoin="round" d="M15.75 17.25v3.375c0 .621-.504 1.125-1.125 1.125h-9.75a1.125 1.125 0 0 1-1.125-1.125V7.875c0-.621.504-1.125 1.125-1.125H6.75a9.06 9.06 0 0 1 1.5.124m7.5 10.376h3.375c.621 0 1.125-.504 1.125-1.125V11.25c0-4.46-3.243-8.161-7.5-8.876a9.06 9.06 0 0 0-1.5-.124H9.375c-.621 0-1.125.504-1.125 1.125v3.5m7.5 10.375H9.375a1.125 1.125 0 0 1-1.125-1.125v-9.25m12 6.625v-1.875a3.375 3.375 0 0 0-3.375-3.375h-1.5a1.125 1.125 0 0 1-1.125-1.125v-1.5a3.375 3.375 0 0 0-3.375-3.375H9.75"></path></svg></button></div><p><strong>This is what is happening here:</strong></p><div class="relative group not-prose overflow-auto shadow hover:shadow-md dark:shadow-2xl dark:shadow-neutral-900 my-5 text-sm bg-stone-200/10"><pre class="block p-3 hljs" style="background-color:unset"><code class="language-python" style="white-space:pre">kern = 1.0 * Matern(length_scale=[80000,80000], length_scale_bounds=(1e3, 1e6),
                        nu=0.5)
gp1 = GaussianProcessRegressor(kernel=kern, alpha=std_slope**2, optimizer=None).fit(coords_m, mean_slope)</code></pre><button title="Copy to Clipboard" class="inline-flex items-center opacity-0 group-hover:opacity-100 hover:opacity-100 focus:opacity-100 active:opacity-100 cursor-pointer ml-2 transition-color duration-200 ease-in-out text-blue-400 hover:text-blue-500 absolute right-1 top-1" aria-pressed="false" aria-label="Copy code to clipboard"><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" width="24" height="24"><path stroke-linecap="round" stroke-linejoin="round" d="M15.75 17.25v3.375c0 .621-.504 1.125-1.125 1.125h-9.75a1.125 1.125 0 0 1-1.125-1.125V7.875c0-.621.504-1.125 1.125-1.125H6.75a9.06 9.06 0 0 1 1.5.124m7.5 10.376h3.375c.621 0 1.125-.504 1.125-1.125V11.25c0-4.46-3.243-8.161-7.5-8.876a9.06 9.06 0 0 0-1.5-.124H9.375c-.621 0-1.125.504-1.125 1.125v3.5m7.5 10.375H9.375a1.125 1.125 0 0 1-1.125-1.125v-9.25m12 6.625v-1.875a3.375 3.375 0 0 0-3.375-3.375h-1.5a1.125 1.125 0 0 1-1.125-1.125v-1.5a3.375 3.375 0 0 0-3.375-3.375H9.75"></path></svg></button></div><p><strong>We are selecting a covariance function (the Matern kernel), and then fitting that fuction to our observations on the basis of distance in order to estimate source-to-source cov</strong></p><p>Define p1…pn prediction nodes; calculate distances and Cpred (covariance of predictions):</p><div id="ExtWbIJ2Yf" class="flex my-5 group"><div class="flex-grow overflow-x-auto overflow-y-hidden"><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><mi>D</mi><mo stretchy="false">(</mo><msub><mi>t</mi><mn>1</mn></msub><mi mathvariant="normal">.</mi><mi mathvariant="normal">.</mi><mi mathvariant="normal">.</mi><msub><mi>t</mi><mi>n</mi></msub><mo separator="true">,</mo><msub><mi>t</mi><mn>1</mn></msub><mi mathvariant="normal">.</mi><mi mathvariant="normal">.</mi><mi mathvariant="normal">.</mi><msub><mi>t</mi><mi>n</mi></msub><mo stretchy="false">)</mo><mo>=</mo><msub><mi>D</mi><mrow><mi>p</mi><mi>r</mi><mi>e</mi><mi>d</mi></mrow></msub></mrow><annotation encoding="application/x-tex">D(t_1 ... t_n, t_1 ... t_n) = D_{pred}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal" style="margin-right:0.02778em;">D</span><span class="mopen">(</span><span class="mord"><span class="mord mathnormal">t</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3011em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mord">...</span><span class="mord"><span class="mord mathnormal">t</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.1514em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">n</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord"><span class="mord mathnormal">t</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3011em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mord">...</span><span class="mord"><span class="mord mathnormal">t</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.1514em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">n</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:0.9694em;vertical-align:-0.2861em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.02778em;">D</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3361em;"><span style="top:-2.55em;margin-left:-0.0278em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">p</span><span class="mord mathnormal mtight">re</span><span class="mord mathnormal mtight">d</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2861em;"><span></span></span></span></span></span></span></span></span></span></span></div><div class="relative self-center flex-none pl-2 m-0 text-right select-none"><a class="no-underline text-inherit hover:text-inherit text-inherit hover:text-inherit select-none hover:underline" href="#ExtWbIJ2Yf" title="Link to this Equation" aria-label="Link to this Equation">(<!-- -->3<!-- -->)</a></div></div><div id="B9t2dSfEPL" class="flex my-5 group"><div class="flex-grow overflow-x-auto overflow-y-hidden"><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><msub><mi>C</mi><mrow><mi>p</mi><mi>r</mi><mi>e</mi><mi>d</mi></mrow></msub><mo>=</mo><msub><mi>f</mi><mrow><mi>c</mi><mi>o</mi><mi>v</mi></mrow></msub><mo stretchy="false">(</mo><msub><mi>D</mi><mrow><mi>p</mi><mi>r</mi><mi>e</mi><mi>d</mi></mrow></msub><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">C_{pred} = f_{cov}(D_{pred})</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.9694em;vertical-align:-0.2861em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.07153em;">C</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3361em;"><span style="top:-2.55em;margin-left:-0.0715em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">p</span><span class="mord mathnormal mtight">re</span><span class="mord mathnormal mtight">d</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2861em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:1.0361em;vertical-align:-0.2861em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.10764em;">f</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.1514em;"><span style="top:-2.55em;margin-left:-0.1076em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">co</span><span class="mord mathnormal mtight" style="margin-right:0.03588em;">v</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mopen">(</span><span class="mord"><span class="mord mathnormal" style="margin-right:0.02778em;">D</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3361em;"><span style="top:-2.55em;margin-left:-0.0278em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">p</span><span class="mord mathnormal mtight">re</span><span class="mord mathnormal mtight">d</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2861em;"><span></span></span></span></span></span></span><span class="mclose">)</span></span></span></span></span></div><div class="relative self-center flex-none pl-2 m-0 text-right select-none"><a class="no-underline text-inherit hover:text-inherit text-inherit hover:text-inherit select-none hover:underline" href="#B9t2dSfEPL" title="Link to this Equation" aria-label="Link to this Equation">(<!-- -->4<!-- -->)</a></div></div><div class="relative group not-prose overflow-auto shadow hover:shadow-md dark:shadow-2xl dark:shadow-neutral-900 my-5 text-sm bg-stone-200/10"><pre class="block p-3 hljs" style="background-color:unset"><code class="language-text" style="white-space:pre">Dist(t1…tn, t1…tn) = Dpred  		# square distance matrix
Cpred = CovF(Dpred)                     # target covarience, i.e., target-to-target cov</code></pre><button title="Copy to Clipboard" class="inline-flex items-center opacity-0 group-hover:opacity-100 hover:opacity-100 focus:opacity-100 active:opacity-100 cursor-pointer ml-2 transition-color duration-200 ease-in-out text-blue-400 hover:text-blue-500 absolute right-1 top-1" aria-pressed="false" aria-label="Copy code to clipboard"><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" width="24" height="24"><path stroke-linecap="round" stroke-linejoin="round" d="M15.75 17.25v3.375c0 .621-.504 1.125-1.125 1.125h-9.75a1.125 1.125 0 0 1-1.125-1.125V7.875c0-.621.504-1.125 1.125-1.125H6.75a9.06 9.06 0 0 1 1.5.124m7.5 10.376h3.375c.621 0 1.125-.504 1.125-1.125V11.25c0-4.46-3.243-8.161-7.5-8.876a9.06 9.06 0 0 0-1.5-.124H9.375c-.621 0-1.125.504-1.125 1.125v3.5m7.5 10.375H9.375a1.125 1.125 0 0 1-1.125-1.125v-9.25m12 6.625v-1.875a3.375 3.375 0 0 0-3.375-3.375h-1.5a1.125 1.125 0 0 1-1.125-1.125v-1.5a3.375 3.375 0 0 0-3.375-3.375H9.75"></path></svg></button></div><p>Note that for above, we don’t actually know p1…pn <em>but we do know the locations</em> of p1…pn, and hence we can calculate their distances, and given that our covariance function is a function of distances, we can <strong>model</strong> the covariance of the predictions p1…pn as a function of distance.</p><p>As mentioned above, kriging is equivalent to spatial least squares regression. Hence, we can retrieve our best estimate at locations p1…pn though least square regression—see below for useful equivalencies:</p><div class="relative group not-prose overflow-auto shadow hover:shadow-md dark:shadow-2xl dark:shadow-neutral-900 my-5 text-sm bg-stone-200/10"><pre class="block p-3 hljs" style="background-color:unset"><code class="language-text" style="white-space:pre">Lstsq( s1…sn, t1…tn) == Lstsq( Cobs, Cobs_pred) == kriging_wieghts</code></pre><button title="Copy to Clipboard" class="inline-flex items-center opacity-0 group-hover:opacity-100 hover:opacity-100 focus:opacity-100 active:opacity-100 cursor-pointer ml-2 transition-color duration-200 ease-in-out text-blue-400 hover:text-blue-500 absolute right-1 top-1" aria-pressed="false" aria-label="Copy code to clipboard"><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" width="24" height="24"><path stroke-linecap="round" stroke-linejoin="round" d="M15.75 17.25v3.375c0 .621-.504 1.125-1.125 1.125h-9.75a1.125 1.125 0 0 1-1.125-1.125V7.875c0-.621.504-1.125 1.125-1.125H6.75a9.06 9.06 0 0 1 1.5.124m7.5 10.376h3.375c.621 0 1.125-.504 1.125-1.125V11.25c0-4.46-3.243-8.161-7.5-8.876a9.06 9.06 0 0 0-1.5-.124H9.375c-.621 0-1.125.504-1.125 1.125v3.5m7.5 10.375H9.375a1.125 1.125 0 0 1-1.125-1.125v-9.25m12 6.625v-1.875a3.375 3.375 0 0 0-3.375-3.375h-1.5a1.125 1.125 0 0 1-1.125-1.125v-1.5a3.375 3.375 0 0 0-3.375-3.375H9.75"></path></svg></button></div><p>…where <code>Cobs_pred</code> is the covariance between our observations and predictions, i.e., our target-to-source <code>cov</code>. Of course, we don’t know our predictions yet; all we have are our observations, and our observation covariances. However, we have defined a covariance function, <em><strong>based</strong></em> on our observation covariances, that provides covariance as a function of distance; hence above we defined our prediction to prediction covariance.</p><p><strong>The kriging weights are used to weight a combination of our observations at each prediction location-- with the weights being determined by distance and the covariance structure. Our ‘mean’ prediction and target-to-target cov (and the steps above and below to retrieve them), happen at this call:</strong></p><div class="relative group not-prose overflow-auto shadow hover:shadow-md dark:shadow-2xl dark:shadow-neutral-900 my-5 text-sm bg-stone-200/10"><pre class="block p-3 hljs" style="background-color:unset"><code class="language-python" style="white-space:pre">y_mean, y_cov = gp1.predict(target_c, return_cov=True)</code></pre><button title="Copy to Clipboard" class="inline-flex items-center opacity-0 group-hover:opacity-100 hover:opacity-100 focus:opacity-100 active:opacity-100 cursor-pointer ml-2 transition-color duration-200 ease-in-out text-blue-400 hover:text-blue-500 absolute right-1 top-1" aria-pressed="false" aria-label="Copy code to clipboard"><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" width="24" height="24"><path stroke-linecap="round" stroke-linejoin="round" d="M15.75 17.25v3.375c0 .621-.504 1.125-1.125 1.125h-9.75a1.125 1.125 0 0 1-1.125-1.125V7.875c0-.621.504-1.125 1.125-1.125H6.75a9.06 9.06 0 0 1 1.5.124m7.5 10.376h3.375c.621 0 1.125-.504 1.125-1.125V11.25c0-4.46-3.243-8.161-7.5-8.876a9.06 9.06 0 0 0-1.5-.124H9.375c-.621 0-1.125.504-1.125 1.125v3.5m7.5 10.375H9.375a1.125 1.125 0 0 1-1.125-1.125v-9.25m12 6.625v-1.875a3.375 3.375 0 0 0-3.375-3.375h-1.5a1.125 1.125 0 0 1-1.125-1.125v-1.5a3.375 3.375 0 0 0-3.375-3.375H9.75"></path></svg></button></div><p><strong>(Note, this call is also implicitly calculating the source to target covariance!)</strong></p><p>Using the same assumption that covariance can be specified as a function of distance, we can get an estimate of covariance between our observations and prediction locations:</p><div class="relative group not-prose overflow-auto shadow hover:shadow-md dark:shadow-2xl dark:shadow-neutral-900 my-5 text-sm bg-stone-200/10"><pre class="block p-3 hljs" style="background-color:unset"><code class="language-text" style="white-space:pre">Cobs_pred = CovF(Dist(s1…sn, t1…tn)</code></pre><button title="Copy to Clipboard" class="inline-flex items-center opacity-0 group-hover:opacity-100 hover:opacity-100 focus:opacity-100 active:opacity-100 cursor-pointer ml-2 transition-color duration-200 ease-in-out text-blue-400 hover:text-blue-500 absolute right-1 top-1" aria-pressed="false" aria-label="Copy code to clipboard"><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" width="24" height="24"><path stroke-linecap="round" stroke-linejoin="round" d="M15.75 17.25v3.375c0 .621-.504 1.125-1.125 1.125h-9.75a1.125 1.125 0 0 1-1.125-1.125V7.875c0-.621.504-1.125 1.125-1.125H6.75a9.06 9.06 0 0 1 1.5.124m7.5 10.376h3.375c.621 0 1.125-.504 1.125-1.125V11.25c0-4.46-3.243-8.161-7.5-8.876a9.06 9.06 0 0 0-1.5-.124H9.375c-.621 0-1.125.504-1.125 1.125v3.5m7.5 10.375H9.375a1.125 1.125 0 0 1-1.125-1.125v-9.25m12 6.625v-1.875a3.375 3.375 0 0 0-3.375-3.375h-1.5a1.125 1.125 0 0 1-1.125-1.125v-1.5a3.375 3.375 0 0 0-3.375-3.375H9.75"></path></svg></button></div><p>…now we obtain the kriging weights by:</p><div class="relative group not-prose overflow-auto shadow hover:shadow-md dark:shadow-2xl dark:shadow-neutral-900 my-5 text-sm bg-stone-200/10"><pre class="block p-3 hljs" style="background-color:unset"><code class="language-text" style="white-space:pre">kriging_wieghts = dot(inv(Cobs), Cobs_pred)</code></pre><button title="Copy to Clipboard" class="inline-flex items-center opacity-0 group-hover:opacity-100 hover:opacity-100 focus:opacity-100 active:opacity-100 cursor-pointer ml-2 transition-color duration-200 ease-in-out text-blue-400 hover:text-blue-500 absolute right-1 top-1" aria-pressed="false" aria-label="Copy code to clipboard"><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" width="24" height="24"><path stroke-linecap="round" stroke-linejoin="round" d="M15.75 17.25v3.375c0 .621-.504 1.125-1.125 1.125h-9.75a1.125 1.125 0 0 1-1.125-1.125V7.875c0-.621.504-1.125 1.125-1.125H6.75a9.06 9.06 0 0 1 1.5.124m7.5 10.376h3.375c.621 0 1.125-.504 1.125-1.125V11.25c0-4.46-3.243-8.161-7.5-8.876a9.06 9.06 0 0 0-1.5-.124H9.375c-.621 0-1.125.504-1.125 1.125v3.5m7.5 10.375H9.375a1.125 1.125 0 0 1-1.125-1.125v-9.25m12 6.625v-1.875a3.375 3.375 0 0 0-3.375-3.375h-1.5a1.125 1.125 0 0 1-1.125-1.125v-1.5a3.375 3.375 0 0 0-3.375-3.375H9.75"></path></svg></button></div><p>Above we see the key computational constraint for kriging; we need to be able to invert an N by N observation covariance matrix.</p><p>Given that the regression/kriging weights are identical for both the observations and their covariances, we now have enough information to make a kriging/Lstsq’s prediction of t1…tn:</p><div class="relative group not-prose overflow-auto shadow hover:shadow-md dark:shadow-2xl dark:shadow-neutral-900 my-5 text-sm bg-stone-200/10"><pre class="block p-3 hljs" style="background-color:unset"><code class="language-text" style="white-space:pre">t1…tn =  dot(kriging_wieghts.T, s1…sn)</code></pre><button title="Copy to Clipboard" class="inline-flex items-center opacity-0 group-hover:opacity-100 hover:opacity-100 focus:opacity-100 active:opacity-100 cursor-pointer ml-2 transition-color duration-200 ease-in-out text-blue-400 hover:text-blue-500 absolute right-1 top-1" aria-pressed="false" aria-label="Copy code to clipboard"><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" width="24" height="24"><path stroke-linecap="round" stroke-linejoin="round" d="M15.75 17.25v3.375c0 .621-.504 1.125-1.125 1.125h-9.75a1.125 1.125 0 0 1-1.125-1.125V7.875c0-.621.504-1.125 1.125-1.125H6.75a9.06 9.06 0 0 1 1.5.124m7.5 10.376h3.375c.621 0 1.125-.504 1.125-1.125V11.25c0-4.46-3.243-8.161-7.5-8.876a9.06 9.06 0 0 0-1.5-.124H9.375c-.621 0-1.125.504-1.125 1.125v3.5m7.5 10.375H9.375a1.125 1.125 0 0 1-1.125-1.125v-9.25m12 6.625v-1.875a3.375 3.375 0 0 0-3.375-3.375h-1.5a1.125 1.125 0 0 1-1.125-1.125v-1.5a3.375 3.375 0 0 0-3.375-3.375H9.75"></path></svg></button></div><p>We can calculate partial correlation/covariance, which is equivalent to the covariance of the residual error from kriging/regression. We get conditional covariance with:</p><div class="relative group not-prose overflow-auto shadow hover:shadow-md dark:shadow-2xl dark:shadow-neutral-900 my-5 text-sm bg-stone-200/10"><pre class="block p-3 hljs" style="background-color:unset"><code class="language-text" style="white-space:pre">Cpred – dot(dot(Cobs_pred.T, inv(Cobs)), Cobs_pred)</code></pre><button title="Copy to Clipboard" class="inline-flex items-center opacity-0 group-hover:opacity-100 hover:opacity-100 focus:opacity-100 active:opacity-100 cursor-pointer ml-2 transition-color duration-200 ease-in-out text-blue-400 hover:text-blue-500 absolute right-1 top-1" aria-pressed="false" aria-label="Copy code to clipboard"><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" width="24" height="24"><path stroke-linecap="round" stroke-linejoin="round" d="M15.75 17.25v3.375c0 .621-.504 1.125-1.125 1.125h-9.75a1.125 1.125 0 0 1-1.125-1.125V7.875c0-.621.504-1.125 1.125-1.125H6.75a9.06 9.06 0 0 1 1.5.124m7.5 10.376h3.375c.621 0 1.125-.504 1.125-1.125V11.25c0-4.46-3.243-8.161-7.5-8.876a9.06 9.06 0 0 0-1.5-.124H9.375c-.621 0-1.125.504-1.125 1.125v3.5m7.5 10.375H9.375a1.125 1.125 0 0 1-1.125-1.125v-9.25m12 6.625v-1.875a3.375 3.375 0 0 0-3.375-3.375h-1.5a1.125 1.125 0 0 1-1.125-1.125v-1.5a3.375 3.375 0 0 0-3.375-3.375H9.75"></path></svg></button></div><p>The above gives the estimation error covariance, and allows for simulation, i.e., <em>prediction</em>. Specifically, we can preform simulation via Cholesky decomposition* using the derived mean target predictions, and the target-to-target covariance:</p><p>(from <a href="https://github.com/scikit-learn/scikit-learn/blob/main/sklearn/gaussian_process/_gpr.py" class="italic" target="_blank" rel="noreferrer" data-state="closed">sklearn gaussian process module</a>):</p><div class="relative group not-prose overflow-auto shadow hover:shadow-md dark:shadow-2xl dark:shadow-neutral-900 my-5 text-sm bg-stone-200/10"><pre class="block p-3 hljs" style="background-color:unset"><code class="language-python" style="white-space:pre">    def sample_y(self, X, n_samples=1, random_state=0):
        &quot;&quot;&quot;Draw samples from Gaussian process and evaluate at X.

        Parameters
        ----------
        X : array-like of shape (n_samples_X, n_features) or list of object
            Query points where the GP is evaluated.

        n_samples : int, default=1
            Number of samples drawn from the Gaussian process per query point.

        random_state : int, RandomState instance or None, default=0
            Determines random number generation to randomly draw samples.
            Pass an int for reproducible results across multiple function
            calls.
            See :term:`Glossary &lt;random_state&gt;`.

        Returns
        -------
        y_samples : ndarray of shape (n_samples_X, n_samples), or \
            (n_samples_X, n_targets, n_samples)
            Values of n_samples samples drawn from Gaussian process and
            evaluated at query points.
        &quot;&quot;&quot;
        rng = check_random_state(random_state)

        y_mean, y_cov = self.predict(X, return_cov=True)
        if y_mean.ndim == 1:
            y_samples = rng.multivariate_normal(y_mean, y_cov, n_samples).T
        else:
            y_samples = [
                rng.multivariate_normal(
                    y_mean[:, target], y_cov[..., target], n_samples
                ).T[:, np.newaxis]
                for target in range(y_mean.shape[1])
            ]
            y_samples = np.hstack(y_samples)
        return y_samples</code></pre><button title="Copy to Clipboard" class="inline-flex items-center opacity-0 group-hover:opacity-100 hover:opacity-100 focus:opacity-100 active:opacity-100 cursor-pointer ml-2 transition-color duration-200 ease-in-out text-blue-400 hover:text-blue-500 absolute right-1 top-1" aria-pressed="false" aria-label="Copy code to clipboard"><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" width="24" height="24"><path stroke-linecap="round" stroke-linejoin="round" d="M15.75 17.25v3.375c0 .621-.504 1.125-1.125 1.125h-9.75a1.125 1.125 0 0 1-1.125-1.125V7.875c0-.621.504-1.125 1.125-1.125H6.75a9.06 9.06 0 0 1 1.5.124m7.5 10.376h3.375c.621 0 1.125-.504 1.125-1.125V11.25c0-4.46-3.243-8.161-7.5-8.876a9.06 9.06 0 0 0-1.5-.124H9.375c-.621 0-1.125.504-1.125 1.125v3.5m7.5 10.375H9.375a1.125 1.125 0 0 1-1.125-1.125v-9.25m12 6.625v-1.875a3.375 3.375 0 0 0-3.375-3.375h-1.5a1.125 1.125 0 0 1-1.125-1.125v-1.5a3.375 3.375 0 0 0-3.375-3.375H9.75"></path></svg></button></div><p>Several things are apparent for the kriging description above, that highlight both the strengths and weakness of the approach. First and foremost, <em>the approach is completely dependent on specification of a proper covariance function</em>. <strong>The covariance function must be invertible; that is it must be positive definite (Genton, 2002)</strong>, and the machine that runs the computation must be capable of inverting a N by N matrix. In practice, the N by N inversion can be relaxed if only the ‘best’ prediction is desired (since it can be derived via lstsq calculation); <em>however, simulation and error estimation requires inversion of an N by N matrix.</em> <strong>In practice, empirical covariance almost always provides a non-invertible (not positive definite) gram matrix (<cite class="" data-state="closed"><a href="https://doi.org/10.1080/00401706.1993.10485354" target="_blank" rel="noreferrer" class="hover-link">Handcock &amp; Stein (1993)</a></cite>); further, a model of covariance is needed to estimate source to target and target to target covariance—so estimation of a covariance function, either via a variogram or by other methods, is always required for geostatistical interpolation and simulation.</strong> The error estimation that kriging gives per prediction is error estimation on the assumption that modeled covariance structure is true! Kriging has been characterized as the Best Unbiased Linear Predictor (BULP)… which it is, for a given covariance function. Swapping covariance functions gives different and competing BLUPs, which then need to be evaluated via inter-model comparison (<cite class="" data-state="closed"><a href="https://doi.org/10.1162/neco.1992.4.3.415" target="_blank" rel="noreferrer" class="hover-link">MacKay (1992)</a></cite>). In short, the kriging error and uncertainty estimation is not the absolute error estimate for the surface, and probability estimation of a prediction must be obtained with other models to give realistic confidence bounds.</p><p>*Traditional kriging involves estimation of a variogram, however, the variogram is simply a way of producing a covariance function that produces a positive definite gram matrix of covariances (Genton, 2002). Since we know that our covariance function produces a positive definite gram matrix of covariances, we use cholesky because <a target="_blank" rel="noreferrer" href="https://numpy.org/doc/2.2/reference/random/generated/numpy.random.Generator.multivariate_normal.html#numpy.random.Generator.multivariate_normal" class="">it is faster than SVD or eigen decomposition</a>.</p></div><div id="g9iqpd3OjM" class="relative group/block"><h3 id="why-prediction" class="relative group"><span class="heading-text">Why Prediction?</span><a class="no-underline text-inherit hover:text-inherit inline-block w-0 px-0 translate-x-[10px] font-normal select-none transition-opacity opacity-0 focus:opacity-100 group-hover:opacity-70" href="#why-prediction" title="Link to this Section" aria-label="Link to this Section">¶</a></h3><p>Slope is an important variable for glaciologists, but it also doesn’t vary much on the icesheet-- it goes from about 2 degrees at the edge where it’s ‘steep’, before gradually dropping down to 1 in the interior and eventually 0 at the drainage boundary. However, things change when the surface is crevassed; cracks present a range of surface heights and angles, and generally those retrievals are <strong>not</strong> flat.</p><p>So if we are looking for crevasses, and we know that the ‘background’ slope of the ice sheet is 2 degrees of slope or lower, it would be nice to know when that slope is exceeded. Unfortunately, our mean prediction of surface slope is smoothing the variation in slope retrievals-- if we have a distribution of slope values, the best prediction will trend towards the mean, resulting in surface that suppresses variation we know is present.</p><p>What we can do though, is simulate possible surfaces, and count how often we exceed 2 degrees of slope for a given location:</p></div><div id="yHtB9fXLCi" class="relative group/block"><div class="flex sticky top-[80px] z-10 opacity-70 group-hover/block:opacity-100 group-hover/block:hidden"><div class="absolute top-0 -right-[28px] flex md:flex-col"></div></div><div class="hidden sticky top-[80px] z-10 opacity-70 group-hover/block:opacity-100 group-hover/block:flex"><div class="absolute top-0 -right-[28px] flex md:flex-col"></div></div><div class="relative group not-prose overflow-auto shadow hover:shadow-md dark:shadow-2xl dark:shadow-neutral-900 my-5 text-sm border border-l-4 border-l-blue-400 border-gray-200 dark:border-l-blue-400 dark:border-gray-800"><pre class="block p-3 hljs" style="background-color:unset"><code class="language-python" style="white-space:pre">%%time
realizations = rng.multivariate_normal(y_mean, y_cov, size=100, method=&#x27;cholesky&#x27;)</code></pre><button title="Copy to Clipboard" class="inline-flex items-center opacity-0 group-hover:opacity-100 hover:opacity-100 focus:opacity-100 active:opacity-100 cursor-pointer ml-2 transition-color duration-200 ease-in-out text-blue-400 hover:text-blue-500 absolute right-1 top-1" aria-pressed="false" aria-label="Copy code to clipboard"><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" width="24" height="24"><path stroke-linecap="round" stroke-linejoin="round" d="M15.75 17.25v3.375c0 .621-.504 1.125-1.125 1.125h-9.75a1.125 1.125 0 0 1-1.125-1.125V7.875c0-.621.504-1.125 1.125-1.125H6.75a9.06 9.06 0 0 1 1.5.124m7.5 10.376h3.375c.621 0 1.125-.504 1.125-1.125V11.25c0-4.46-3.243-8.161-7.5-8.876a9.06 9.06 0 0 0-1.5-.124H9.375c-.621 0-1.125.504-1.125 1.125v3.5m7.5 10.375H9.375a1.125 1.125 0 0 1-1.125-1.125v-9.25m12 6.625v-1.875a3.375 3.375 0 0 0-3.375-3.375h-1.5a1.125 1.125 0 0 1-1.125-1.125v-1.5a3.375 3.375 0 0 0-3.375-3.375H9.75"></path></svg></button></div><div data-mdast-node-id="Q0dE4tCUj1r-3NSfi-eXa" class="max-w-full overflow-y-visible overflow-x-auto m-0 group not-prose relative text-left mb-5"><div><pre class="text-sm font-thin font-system"><code><span>CPU times: user 8.21 s, sys: 313 ms, total: 8.52 s
Wall time: 1.12 s
</span></code></pre></div></div></div><div id="wgD4MUWeUf" class="relative group/block"><div class="flex sticky top-[80px] z-10 opacity-70 group-hover/block:opacity-100 group-hover/block:hidden"><div class="absolute top-0 -right-[28px] flex md:flex-col"></div></div><div class="hidden sticky top-[80px] z-10 opacity-70 group-hover/block:opacity-100 group-hover/block:flex"><div class="absolute top-0 -right-[28px] flex md:flex-col"></div></div><div class="relative group not-prose overflow-auto shadow hover:shadow-md dark:shadow-2xl dark:shadow-neutral-900 my-5 text-sm border border-l-4 border-l-blue-400 border-gray-200 dark:border-l-blue-400 dark:border-gray-800"><pre class="block p-3 hljs" style="background-color:unset"><code class="language-python" style="white-space:pre">results1 = np.ones(len(kcoords)) *np.nan
results1[Zidx] =  realizations[5]
show_res1 = results1.reshape((x1.shape))
plt.imshow(np.flipud(show_res1), vmin=2)
plt.colorbar()
plt.show()</code></pre><button title="Copy to Clipboard" class="inline-flex items-center opacity-0 group-hover:opacity-100 hover:opacity-100 focus:opacity-100 active:opacity-100 cursor-pointer ml-2 transition-color duration-200 ease-in-out text-blue-400 hover:text-blue-500 absolute right-1 top-1" aria-pressed="false" aria-label="Copy code to clipboard"><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" width="24" height="24"><path stroke-linecap="round" stroke-linejoin="round" d="M15.75 17.25v3.375c0 .621-.504 1.125-1.125 1.125h-9.75a1.125 1.125 0 0 1-1.125-1.125V7.875c0-.621.504-1.125 1.125-1.125H6.75a9.06 9.06 0 0 1 1.5.124m7.5 10.376h3.375c.621 0 1.125-.504 1.125-1.125V11.25c0-4.46-3.243-8.161-7.5-8.876a9.06 9.06 0 0 0-1.5-.124H9.375c-.621 0-1.125.504-1.125 1.125v3.5m7.5 10.375H9.375a1.125 1.125 0 0 1-1.125-1.125v-9.25m12 6.625v-1.875a3.375 3.375 0 0 0-3.375-3.375h-1.5a1.125 1.125 0 0 1-1.125-1.125v-1.5a3.375 3.375 0 0 0-3.375-3.375H9.75"></path></svg></button></div><div data-mdast-node-id="0a5qZ8XNe_dajSuq9_Oi1" class="max-w-full overflow-y-visible overflow-x-auto m-0 group not-prose relative text-left mb-5"><img src="/build/16054cd9d3452404ea4c0d28a5ebc991.png" alt="&lt;Figure size 640x480 with 2 Axes&gt;"/></div></div><div id="oav8SejSai" class="relative group/block"><div class="flex sticky top-[80px] z-10 opacity-70 group-hover/block:opacity-100 group-hover/block:hidden"><div class="absolute top-0 -right-[28px] flex md:flex-col"></div></div><div class="hidden sticky top-[80px] z-10 opacity-70 group-hover/block:opacity-100 group-hover/block:flex"><div class="absolute top-0 -right-[28px] flex md:flex-col"></div></div><div class="relative group not-prose overflow-auto shadow hover:shadow-md dark:shadow-2xl dark:shadow-neutral-900 my-5 text-sm border border-l-4 border-l-blue-400 border-gray-200 dark:border-l-blue-400 dark:border-gray-800"><pre class="block p-3 hljs" style="background-color:unset"><code class="language-python" style="white-space:pre">results1 = np.ones(len(kcoords)) *np.nan
results1[Zidx] =  realizations[9]
show_res1 = results1.reshape((x1.shape))
plt.imshow(np.flipud(show_res1), vmin=2)
plt.colorbar()
plt.show()</code></pre><button title="Copy to Clipboard" class="inline-flex items-center opacity-0 group-hover:opacity-100 hover:opacity-100 focus:opacity-100 active:opacity-100 cursor-pointer ml-2 transition-color duration-200 ease-in-out text-blue-400 hover:text-blue-500 absolute right-1 top-1" aria-pressed="false" aria-label="Copy code to clipboard"><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" width="24" height="24"><path stroke-linecap="round" stroke-linejoin="round" d="M15.75 17.25v3.375c0 .621-.504 1.125-1.125 1.125h-9.75a1.125 1.125 0 0 1-1.125-1.125V7.875c0-.621.504-1.125 1.125-1.125H6.75a9.06 9.06 0 0 1 1.5.124m7.5 10.376h3.375c.621 0 1.125-.504 1.125-1.125V11.25c0-4.46-3.243-8.161-7.5-8.876a9.06 9.06 0 0 0-1.5-.124H9.375c-.621 0-1.125.504-1.125 1.125v3.5m7.5 10.375H9.375a1.125 1.125 0 0 1-1.125-1.125v-9.25m12 6.625v-1.875a3.375 3.375 0 0 0-3.375-3.375h-1.5a1.125 1.125 0 0 1-1.125-1.125v-1.5a3.375 3.375 0 0 0-3.375-3.375H9.75"></path></svg></button></div><div data-mdast-node-id="6K8j64ofh3Rhr6mSsZF61" class="max-w-full overflow-y-visible overflow-x-auto m-0 group not-prose relative text-left mb-5"><img src="/build/5613a94aefe71a55d1b42b8e85bc75d9.png" alt="&lt;Figure size 640x480 with 2 Axes&gt;"/></div></div><div id="iPkwY8kV6S" class="relative group/block"><div class="flex sticky top-[80px] z-10 opacity-70 group-hover/block:opacity-100 group-hover/block:hidden"><div class="absolute top-0 -right-[28px] flex md:flex-col"></div></div><div class="hidden sticky top-[80px] z-10 opacity-70 group-hover/block:opacity-100 group-hover/block:flex"><div class="absolute top-0 -right-[28px] flex md:flex-col"></div></div><div class="relative group not-prose overflow-auto shadow hover:shadow-md dark:shadow-2xl dark:shadow-neutral-900 my-5 text-sm border border-l-4 border-l-blue-400 border-gray-200 dark:border-l-blue-400 dark:border-gray-800"><pre class="block p-3 hljs" style="background-color:unset"><code class="language-python" style="white-space:pre">occurance = np.zeros(5600, dtype=np.int64)
for i in realizations:
    occurance += i &gt; 3</code></pre><button title="Copy to Clipboard" class="inline-flex items-center opacity-0 group-hover:opacity-100 hover:opacity-100 focus:opacity-100 active:opacity-100 cursor-pointer ml-2 transition-color duration-200 ease-in-out text-blue-400 hover:text-blue-500 absolute right-1 top-1" aria-pressed="false" aria-label="Copy code to clipboard"><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" width="24" height="24"><path stroke-linecap="round" stroke-linejoin="round" d="M15.75 17.25v3.375c0 .621-.504 1.125-1.125 1.125h-9.75a1.125 1.125 0 0 1-1.125-1.125V7.875c0-.621.504-1.125 1.125-1.125H6.75a9.06 9.06 0 0 1 1.5.124m7.5 10.376h3.375c.621 0 1.125-.504 1.125-1.125V11.25c0-4.46-3.243-8.161-7.5-8.876a9.06 9.06 0 0 0-1.5-.124H9.375c-.621 0-1.125.504-1.125 1.125v3.5m7.5 10.375H9.375a1.125 1.125 0 0 1-1.125-1.125v-9.25m12 6.625v-1.875a3.375 3.375 0 0 0-3.375-3.375h-1.5a1.125 1.125 0 0 1-1.125-1.125v-1.5a3.375 3.375 0 0 0-3.375-3.375H9.75"></path></svg></button></div><div data-mdast-node-id="NT3O1UCicG9ovN8s0hMO3" class="max-w-full overflow-y-visible overflow-x-auto m-0 group not-prose relative text-left"></div></div><div id="fVulMGzWbH" class="relative group/block"><div class="flex sticky top-[80px] z-10 opacity-70 group-hover/block:opacity-100 group-hover/block:hidden"><div class="absolute top-0 -right-[28px] flex md:flex-col"></div></div><div class="hidden sticky top-[80px] z-10 opacity-70 group-hover/block:opacity-100 group-hover/block:flex"><div class="absolute top-0 -right-[28px] flex md:flex-col"></div></div><div class="relative group not-prose overflow-auto shadow hover:shadow-md dark:shadow-2xl dark:shadow-neutral-900 my-5 text-sm border border-l-4 border-l-blue-400 border-gray-200 dark:border-l-blue-400 dark:border-gray-800"><pre class="block p-3 hljs" style="background-color:unset"><code class="language-python" style="white-space:pre"></code></pre><button title="Copy to Clipboard" class="inline-flex items-center opacity-0 group-hover:opacity-100 hover:opacity-100 focus:opacity-100 active:opacity-100 cursor-pointer ml-2 transition-color duration-200 ease-in-out text-blue-400 hover:text-blue-500 absolute right-1 top-1" aria-pressed="false" aria-label="Copy code to clipboard"><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" width="24" height="24"><path stroke-linecap="round" stroke-linejoin="round" d="M15.75 17.25v3.375c0 .621-.504 1.125-1.125 1.125h-9.75a1.125 1.125 0 0 1-1.125-1.125V7.875c0-.621.504-1.125 1.125-1.125H6.75a9.06 9.06 0 0 1 1.5.124m7.5 10.376h3.375c.621 0 1.125-.504 1.125-1.125V11.25c0-4.46-3.243-8.161-7.5-8.876a9.06 9.06 0 0 0-1.5-.124H9.375c-.621 0-1.125.504-1.125 1.125v3.5m7.5 10.375H9.375a1.125 1.125 0 0 1-1.125-1.125v-9.25m12 6.625v-1.875a3.375 3.375 0 0 0-3.375-3.375h-1.5a1.125 1.125 0 0 1-1.125-1.125v-1.5a3.375 3.375 0 0 0-3.375-3.375H9.75"></path></svg></button></div><div data-mdast-node-id="UL87g3u8NYv9yNKai7Ywk" class="max-w-full overflow-y-visible overflow-x-auto m-0 group not-prose relative text-left"></div></div><div id="XcIDQWOgTa" class="relative group/block"><div class="flex sticky top-[80px] z-10 opacity-70 group-hover/block:opacity-100 group-hover/block:hidden"><div class="absolute top-0 -right-[28px] flex md:flex-col"></div></div><div class="hidden sticky top-[80px] z-10 opacity-70 group-hover/block:opacity-100 group-hover/block:flex"><div class="absolute top-0 -right-[28px] flex md:flex-col"></div></div><div class="relative group not-prose overflow-auto shadow hover:shadow-md dark:shadow-2xl dark:shadow-neutral-900 my-5 text-sm border border-l-4 border-l-blue-400 border-gray-200 dark:border-l-blue-400 dark:border-gray-800"><pre class="block p-3 hljs" style="background-color:unset"><code class="language-python" style="white-space:pre">results1 = np.ones(len(kcoords)) *np.nan
results1[Zidx] =  occurance
show_res1 = results1.reshape((x1.shape))
plt.imshow(np.flipud(show_res1)) #, norm=mpl.colors.LogNorm())
ticks = np.array([0,20,40,60,80])
yticks = np.array([100,80,60,40,20])
plt.xticks(ticks[1:],(ticks[0:-1]*5))
plt.yticks(yticks,(ticks*5))
plt.colorbar()
plt.show()</code></pre><button title="Copy to Clipboard" class="inline-flex items-center opacity-0 group-hover:opacity-100 hover:opacity-100 focus:opacity-100 active:opacity-100 cursor-pointer ml-2 transition-color duration-200 ease-in-out text-blue-400 hover:text-blue-500 absolute right-1 top-1" aria-pressed="false" aria-label="Copy code to clipboard"><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" width="24" height="24"><path stroke-linecap="round" stroke-linejoin="round" d="M15.75 17.25v3.375c0 .621-.504 1.125-1.125 1.125h-9.75a1.125 1.125 0 0 1-1.125-1.125V7.875c0-.621.504-1.125 1.125-1.125H6.75a9.06 9.06 0 0 1 1.5.124m7.5 10.376h3.375c.621 0 1.125-.504 1.125-1.125V11.25c0-4.46-3.243-8.161-7.5-8.876a9.06 9.06 0 0 0-1.5-.124H9.375c-.621 0-1.125.504-1.125 1.125v3.5m7.5 10.375H9.375a1.125 1.125 0 0 1-1.125-1.125v-9.25m12 6.625v-1.875a3.375 3.375 0 0 0-3.375-3.375h-1.5a1.125 1.125 0 0 1-1.125-1.125v-1.5a3.375 3.375 0 0 0-3.375-3.375H9.75"></path></svg></button></div><div data-mdast-node-id="TwfosROyLIwX0XEtNG6p6" class="max-w-full overflow-y-visible overflow-x-auto m-0 group not-prose relative text-left mb-5"><img src="/build/bd2f9c7b57e429a89e58d05f8c66d1c8.png" alt="&lt;Figure size 640x480 with 2 Axes&gt;"/></div></div><div id="Z2fnGFouBL" class="relative group/block"><h3 id="covarience-kernels" class="relative group"><span class="heading-text">Covarience Kernels</span><a class="no-underline text-inherit hover:text-inherit inline-block w-0 px-0 translate-x-[10px] font-normal select-none transition-opacity opacity-0 focus:opacity-100 group-hover:opacity-70" href="#covarience-kernels" title="Link to this Section" aria-label="Link to this Section">¶</a></h3><p>Observe the following GP kernels (i.e., covarience models), fitted to the same data; note that every model consistently <em>predicts</em> an additional drop <em>beyond the observations</em> between x=4 and x=5; interpolation using most estimators cannot exceed the min/max of the observation space!</p><p><picture class=""><source srcSet="/build/640cbbfcbbe6456d9de17be99a0b8710.webp" type="image/webp"/><img id="LGBEUiKb04" style="margin:0 auto" src="/build/640cbbfcbbe6456d9de17be99a0b8710.png" alt="gp1.png" data-canonical-url="https://scikit-learn.org/stable/_images/sphx_glr_plot_gpr_prior_posterior_001.png"/></picture>
<picture class=""><source srcSet="/build/02c12096c474beb07b01aa952e6d7321.webp" type="image/webp"/><img id="mmD3egw8lA" style="margin:0 auto" src="/build/02c12096c474beb07b01aa952e6d7321.png" alt="gp1.png" data-canonical-url="https://scikit-learn.org/stable/_images/sphx_glr_plot_gpr_prior_posterior_002.png"/></picture></p><p><em>Note that the next kernel is modeling period functions (applicable to basin and range features)</em></p><p><picture class=""><source srcSet="/build/d5647b7711a1f652476f0e28745cc0ab.webp" type="image/webp"/><img id="bI5pScoror" style="margin:0 auto" src="/build/d5647b7711a1f652476f0e28745cc0ab.png" alt="gp1.png" data-canonical-url="https://scikit-learn.org/stable/_images/sphx_glr_plot_gpr_prior_posterior_003.png"/></picture>
<picture class=""><source srcSet="/build/3a9cdfda5457eba4bcbf6bf31a4c9441.webp" type="image/webp"/><img id="HEYuwWm2z8" style="margin:0 auto" src="/build/3a9cdfda5457eba4bcbf6bf31a4c9441.png" alt="gp1.png" data-canonical-url="https://scikit-learn.org/stable/_images/sphx_glr_plot_gpr_prior_posterior_005.png"/></picture></p><p>Note that one major benefit to the GP kernel formulation is that <a target="_blank" rel="noreferrer" href="https://towardsdatascience.com/gaussian-process-kernels-96bafb4dd63e/" class="">kernels can be <em>combined</em></a>. This approach models kernels to account for the non-stationarity of the processes within the kernel formulation, rather than seperating out a</p></div><div></div><section id="references" class="article-grid subgrid-gap col-screen"><div><header class="text-lg font-semibold text-stone-900 dark:text-white group">References<a class="no-underline text-inherit hover:text-inherit ml-2 select-none transition-opacity opacity-0 focus:opacity-100 group-hover:opacity-70" href="#references" title="Link to References" aria-label="Link to References">¶</a></header></div><div class="pl-3 mb-8 text-xs text-stone-500 dark:text-stone-300"><ol><li class="break-words" id="cite-Williams_1998">Williams, C. K. I. (1998). Prediction with Gaussian Processes: From Linear Regression to Linear Prediction and Beyond. In <i>Learning in Graphical Models</i> (pp. 599–621). Springer Netherlands. <a target="_blank" rel="noreferrer" href="https://doi.org/10.1007/978-94-011-5014-9_23">10.1007/978-94-011-5014-9_23</a></li><li class="break-words" id="cite-Rasmussen_2005">Rasmussen, C. E., & Williams, C. K. I. (2005). <i>Gaussian Processes for Machine Learning</i>. The MIT Press. <a target="_blank" rel="noreferrer" href="https://doi.org/10.7551/mitpress/3206.001.0001">10.7551/mitpress/3206.001.0001</a></li><li class="break-words" id="cite-Matheron_1973">Matheron, G. (1973). The intrinsic random functions and their applications. <i>Advances in Applied Probability</i>, <i>5</i>(3), 439–468. <a target="_blank" rel="noreferrer" href="https://doi.org/10.2307/1425829">10.2307/1425829</a></li><li class="break-words" id="cite-Journel_1977">Journel, A. G. (1977). Kriging in terms of projections. <i>Mathematical Geology</i>, <i>9</i>(6), 563–586. <a target="_blank" rel="noreferrer" href="https://doi.org/10.1007/bf02067214">10.1007/bf02067214</a></li><li class="break-words" id="cite-genton">Genton, M. G. (2002). Classes of kernels for machine learning: a statistics perspective. <i>J. Mach. Learn. Res.</i>, <i>2</i>, 299–312. <a target="_blank" rel="noreferrer" href="https://doi.org/10.5555/944790.944815">10.5555/944790.944815</a></li><li class="break-words" id="cite-https://doi.org/10.48550/arxiv.1302.4245">Wilson, A. G., & Adams, R. P. (2013). <i>Gaussian Process Kernels for Pattern Discovery and Extrapolation</i>. <a target="_blank" rel="noreferrer" href="https://doi.org/10.48550/ARXIV.1302.4245">10.48550/ARXIV.1302.4245</a></li><li class="break-words" id="cite-Cressie_1999">Cressie, N., & Huang, H.-C. (1999). Classes of Nonseparable, Spatio-Temporal Stationary Covariance Functions. <i>Journal of the American Statistical Association</i>, <i>94</i>(448), 1330–1339. <a target="_blank" rel="noreferrer" href="https://doi.org/10.1080/01621459.1999.10473885">10.1080/01621459.1999.10473885</a></li><li class="break-words" id="cite-Mat_rn_1986">Matérn, B. (1986). Spatial Variation. In <i>Lecture Notes in Statistics</i>. Springer New York. <a target="_blank" rel="noreferrer" href="https://doi.org/10.1007/978-1-4615-7892-5">10.1007/978-1-4615-7892-5</a></li><li class="break-words" id="cite-https://doi.org/10.48550/arxiv.1503.01057">Wilson, A. G., & Nickisch, H. (2015). <i>Kernel Interpolation for Scalable Structured Gaussian Processes (KISS-GP)</i>. arXiv. <a target="_blank" rel="noreferrer" href="https://doi.org/10.48550/ARXIV.1503.01057">10.48550/ARXIV.1503.01057</a></li><li class="break-words" id="cite-Cressie_1990">Cressie, N. (1990). The origins of kriging. <i>Mathematical Geology</i>, <i>22</i>(3), 239–252. <a target="_blank" rel="noreferrer" href="https://doi.org/10.1007/bf00889887">10.1007/bf00889887</a></li><li class="break-words" id="cite-Handcock_1993">Handcock, M. S., & Stein, M. L. (1993). A Bayesian Analysis of Kriging. <i>Technometrics</i>, <i>35</i>(4), 403–410. <a target="_blank" rel="noreferrer" href="https://doi.org/10.1080/00401706.1993.10485354">10.1080/00401706.1993.10485354</a></li><li class="break-words" id="cite-MacKay_1992">MacKay, D. J. C. (1992). Bayesian Interpolation. <i>Neural Computation</i>, <i>4</i>(3), 415–447. <a target="_blank" rel="noreferrer" href="https://doi.org/10.1162/neco.1992.4.3.415">10.1162/neco.1992.4.3.415</a></li></ol></div></section></main></article><script>((a,d)=>{if(!window.history.state||!window.history.state.key){let h=Math.random().toString(32).slice(2);window.history.replaceState({key:h},"")}try{let f=JSON.parse(sessionStorage.getItem(a)||"{}")[d||window.history.state.key];typeof f=="number"&&window.scrollTo(0,f)}catch(h){console.error(h),sessionStorage.removeItem(a)}})("positions", null)</script><link rel="modulepreload" href="/build/entry.client-UNPC4GT3.js"/><link rel="modulepreload" href="/build/_shared/chunk-OCTKKCIL.js"/><link rel="modulepreload" href="/build/_shared/chunk-UAI5KRM7.js"/><link rel="modulepreload" href="/build/_shared/chunk-2NH4LW52.js"/><link rel="modulepreload" href="/build/_shared/chunk-IZFMW3M4.js"/><link rel="modulepreload" href="/build/_shared/chunk-HBJK6BW3.js"/><link rel="modulepreload" href="/build/_shared/chunk-HYMQ7M2K.js"/><link rel="modulepreload" href="/build/_shared/chunk-OHOXABTA.js"/><link rel="modulepreload" href="/build/_shared/chunk-OCWQY3HK.js"/><link rel="modulepreload" href="/build/_shared/chunk-CPTH56EW.js"/><link rel="modulepreload" href="/build/_shared/chunk-3CVK3PYF.js"/><link rel="modulepreload" href="/build/_shared/chunk-J6FHCSRC.js"/><link rel="modulepreload" href="/build/_shared/chunk-S4SWV34C.js"/><link rel="modulepreload" href="/build/_shared/chunk-GUCIBHGO.js"/><link rel="modulepreload" href="/build/root-QGLRP2PL.js"/><link rel="modulepreload" href="/build/_shared/chunk-CB3BH7WY.js"/><link rel="modulepreload" href="/build/routes/$-7JYT5576.js"/><script>window.__remixContext = {"url":"/gaussianprocesses-copy1","state":{"loaderData":{"root":{"config":{"version":2,"myst":"1.3.26","options":{"hide_toc":true,"hide_footer_links":true},"nav":[],"actions":[],"projects":[{"title":"Coding Sample","thumbnail":"/build/c46244155f82f0a2188b900fb12670c3.svg","exports":[],"bibliography":[],"index":"readme","pages":[{"slug":"gaussianprocesses","title":"Coding \u0026 Writing Sample","description":"","date":"2025-05-07","thumbnail":"/build/b77199e99a54e59b2e3c037c2cc90f21.svg","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":1},{"title":"Tmp","level":1},{"slug":"gaussianprocesses-copy1","title":"Context for this coding \u0026 writing sample","description":"","date":"","thumbnail":"/build/b77199e99a54e59b2e3c037c2cc90f21.svg","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2}]}]},"CONTENT_CDN_PORT":"3101","MODE":"static"},"routes/$":{"config":{"version":2,"myst":"1.3.26","options":{"hide_toc":true,"hide_footer_links":true},"nav":[],"actions":[],"projects":[{"title":"Coding Sample","thumbnail":"/build/c46244155f82f0a2188b900fb12670c3.svg","exports":[],"bibliography":[],"index":"readme","pages":[{"slug":"gaussianprocesses","title":"Coding \u0026 Writing Sample","description":"","date":"2025-05-07","thumbnail":"/build/b77199e99a54e59b2e3c037c2cc90f21.svg","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":1},{"title":"Tmp","level":1},{"slug":"gaussianprocesses-copy1","title":"Context for this coding \u0026 writing sample","description":"","date":"","thumbnail":"/build/b77199e99a54e59b2e3c037c2cc90f21.svg","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2}]}]},"page":{"version":2,"kind":"Notebook","sha256":"53a30412fd66e629c106382baa7d0c0db3e65b1eb251a8a9b0d3d5b98dd59b8c","slug":"gaussianprocesses-copy1","location":"/tmp/GaussianProcesses-Copy1.ipynb","dependencies":[],"frontmatter":{"title":"Context for this coding \u0026 writing sample","content_includes_title":false,"kernelspec":{"name":"python3","display_name":"Python 3 (ipykernel)","language":"python"},"numbering":{"title":{"offset":1}},"thumbnail":"/build/b77199e99a54e59b2e3c037c2cc90f21.svg","exports":[{"format":"ipynb","filename":"GaussianProcesses-Copy1.ipynb","url":"/build/GaussianProcesses-Co-7c0109518ad71989a5d6ace27a9debb8.ipynb"}]},"widgets":{},"mdast":{"type":"root","children":[{"type":"block","kind":"notebook-content","children":[{"type":"paragraph","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"children":[{"type":"text","value":"I presented this notebook on Tuesday, April 29th to Fernando Perez’s research group at UC-Berkely. I’ve modified it slightly to:","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"key":"mz4aFM2HFx"}],"key":"D6H0hZtuwP"},{"type":"list","ordered":true,"start":1,"spread":false,"position":{"start":{"line":5,"column":1},"end":{"line":8,"column":1}},"children":[{"type":"listItem","spread":true,"position":{"start":{"line":5,"column":1},"end":{"line":5,"column":1}},"children":[{"type":"text","value":"Add context that I had previously noted verbally","position":{"start":{"line":5,"column":1},"end":{"line":5,"column":1}},"key":"g8g2DON040"}],"key":"ZyIVBO5hTl"},{"type":"listItem","spread":true,"position":{"start":{"line":6,"column":1},"end":{"line":6,"column":1}},"children":[{"type":"text","value":"Reduce the computational complexity of the example so that it can run on a single binder instance","position":{"start":{"line":6,"column":1},"end":{"line":6,"column":1}},"key":"Y2ue1BoyKN"}],"key":"V61GbQnWYx"},{"type":"listItem","spread":true,"position":{"start":{"line":7,"column":1},"end":{"line":8,"column":1}},"children":[{"type":"text","value":"Created a repository so that software dependencies can be built automatically, and the data is present.","position":{"start":{"line":7,"column":1},"end":{"line":7,"column":1}},"key":"JDYS58ggtO"}],"key":"fnsAX7pjfR"}],"key":"j1IdIm1H5q"},{"type":"paragraph","position":{"start":{"line":9,"column":1},"end":{"line":9,"column":1}},"children":[{"type":"text","value":"This notebook can be run for free from any web browser be clicking the following binder link: ","position":{"start":{"line":9,"column":1},"end":{"line":9,"column":1}},"key":"gkcNVDLCZj"},{"type":"link","url":"https://mybinder.org/v2/gh/espg/coding-sample/HEAD?urlpath=%2Fdoc%2Ftree%2FGaussianProcesses.ipynb","position":{"start":{"line":9,"column":1},"end":{"line":9,"column":1}},"children":[{"type":"image","url":"/build/b77199e99a54e59b2e3c037c2cc90f21.svg","alt":"Binder","position":{"start":{"line":9,"column":1},"end":{"line":9,"column":1}},"key":"VmQkDJybFE","urlSource":"https://mybinder.org/badge_logo.svg"}],"urlSource":"https://mybinder.org/v2/gh/espg/coding-sample/HEAD?urlpath=%2Fdoc%2Ftree%2FGaussianProcesses.ipynb","key":"RFXHjvivjO"}],"key":"Ll9X7VCHNq"}],"key":"dZcS9NkH1f"},{"type":"block","kind":"notebook-content","children":[{"type":"heading","depth":2,"position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"Gaussian Processes Prediction","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"tuOlo1QEzN"}],"identifier":"gaussian-processes-prediction","label":"Gaussian Processes Prediction","html_id":"gaussian-processes-prediction","implicit":true,"key":"ctzUIYPlzJ"},{"type":"paragraph","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"children":[{"type":"text","value":"Principle Component Analysis (PCA) and Empirical Orthogonal functions (EOF) are functionally the same numerical method, with EOFs being the preferred term in Atmospheric communities and PCA being the more general term used in broader statistical discussions. Similarly, Gaussian Processes is the general term used in physics and statistical learning for what the geosciences has traditionally termed ‘kriging’, and which some branches of math refer to as Wiener–Kolmogorov prediction.","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"key":"TmsuV1seMp"}],"key":"SggigGdNjD"},{"type":"paragraph","position":{"start":{"line":5,"column":1},"end":{"line":5,"column":1}},"children":[{"type":"text","value":"Gaussian Processes (GP) are perhaps best thought of as a collection of enhancements to the traditional kriging system. They are functionally equivalent to kriging (","position":{"start":{"line":5,"column":1},"end":{"line":5,"column":1}},"key":"SIV9HIjJRR"},{"type":"cite","url":"https://doi.org/10.1007/978-94-011-5014-9_23","position":{"start":{"line":5,"column":1},"end":{"line":5,"column":1}},"children":[{"type":"text","value":"Williams (1998)","position":{"start":{"line":5,"column":1},"end":{"line":5,"column":1}},"key":"ox1CRda2YZ"}],"kind":"narrative","label":"Williams_1998","identifier":"https://doi.org/10.1007/978-94-011-5014-9_23","enumerator":"1","key":"MvcxXpdvxo"},{"type":"text","value":"), and differ only in implantation details and slightly in philosophy; although the philosophical differences are in general extensions to ideas explicitly espoused by many kriging giants. ","position":{"start":{"line":5,"column":1},"end":{"line":5,"column":1}},"key":"nX5zGnAb4X"},{"type":"strong","position":{"start":{"line":5,"column":1},"end":{"line":5,"column":1}},"children":[{"type":"text","value":"The GP philosophy treats interpolation as model selection from an infinite number of functions (","position":{"start":{"line":5,"column":1},"end":{"line":5,"column":1}},"key":"obRumKEpDr"},{"type":"cite","url":"https://doi.org/10.7551/mitpress/3206.001.0001","position":{"start":{"line":5,"column":1},"end":{"line":5,"column":1}},"children":[{"type":"text","value":"Rasmussen \u0026 Williams (2005)","position":{"start":{"line":5,"column":1},"end":{"line":5,"column":1}},"key":"W40QuIzMXQ"}],"kind":"narrative","label":"Rasmussen_2005","identifier":"https://doi.org/10.7551/mitpress/3206.001.0001","enumerator":"2","key":"B8WE1gT0yX"},{"type":"text","value":")","position":{"start":{"line":5,"column":1},"end":{"line":5,"column":1}},"key":"PJ0xOW4n3e"}],"key":"jgRP4JAAjJ"},{"type":"text","value":".","position":{"start":{"line":5,"column":1},"end":{"line":5,"column":1}},"key":"hkl9d5JZoG"}],"key":"ubE0Mxmxvx"},{"type":"image","url":"/build/5b8ae75218c2b71222b94cc7a0abdc35.png","alt":"gp.png","position":{"start":{"line":7,"column":1},"end":{"line":7,"column":1}},"key":"IhcbhHl742","urlSource":"https://upload.wikimedia.org/wikipedia/commons/7/7f/Gaussian_Process_Regression.png","urlOptimized":"/build/5b8ae75218c2b71222b94cc7a0abdc35.webp"},{"type":"paragraph","position":{"start":{"line":9,"column":1},"end":{"line":9,"column":1}},"children":[{"type":"text","value":"This characterization certainly fits with ","position":{"start":{"line":9,"column":1},"end":{"line":9,"column":1}},"key":"ysOkZ4lpNZ"},{"type":"cite","url":"https://doi.org/10.2307/1425829","position":{"start":{"line":9,"column":1},"end":{"line":9,"column":1}},"children":[{"type":"text","value":"Matheron’s","position":{"start":{"line":9,"column":1},"end":{"line":9,"column":1}},"key":"ipu2MllyfR"}],"kind":"narrative","label":"Matheron_1973","identifier":"https://doi.org/10.2307/1425829","enumerator":"3","key":"kSKs2XIQym"},{"type":"text","value":" discussion of random fields, and is a close match to ","position":{"start":{"line":9,"column":1},"end":{"line":9,"column":1}},"key":"Lii1UzD5PT"},{"type":"cite","url":"https://doi.org/10.1007/bf02067214","position":{"start":{"line":9,"column":1},"end":{"line":9,"column":1}},"children":[{"type":"text","value":"Journal’s","position":{"start":{"line":9,"column":1},"end":{"line":9,"column":1}},"key":"mcKbEHxowA"}],"kind":"narrative","label":"Journel_1977","identifier":"https://doi.org/10.1007/bf02067214","enumerator":"4","key":"tdQWbMu2T8"},{"type":"text","value":" description of projection into various solution spaces. These functions are not required to be linear, as the figure below demonstrates:","position":{"start":{"line":9,"column":1},"end":{"line":9,"column":1}},"key":"AcAPp75pM4"}],"key":"sUzvcvbw5h"},{"type":"image","url":"/build/af20bbeeb575a136bc4a46923a3b5451.gif","alt":"animation.gif","position":{"start":{"line":11,"column":1},"end":{"line":11,"column":1}},"key":"JmcDGugKw5","urlSource":"https://upload.wikimedia.org/wikipedia/commons/d/da/Gaussianprocess.gif","urlOptimized":"/build/af20bbeeb575a136bc4a46923a3b5451.webp"},{"type":"paragraph","position":{"start":{"line":13,"column":1},"end":{"line":13,"column":1}},"children":[{"type":"emphasis","position":{"start":{"line":13,"column":1},"end":{"line":13,"column":1}},"children":[{"type":"text","value":"As number of predictions ‘P’ grows to be large above, the mean of all ‘P’ approaches the best estimate, with the variance of predictions indicating confidence (std. dev. of predictions)","position":{"start":{"line":13,"column":1},"end":{"line":13,"column":1}},"key":"O4Cp1vtnIi"}],"key":"unaBS4x179"}],"key":"MIxebkg2rI"},{"type":"paragraph","position":{"start":{"line":15,"column":1},"end":{"line":15,"column":1}},"children":[{"type":"strong","position":{"start":{"line":15,"column":1},"end":{"line":15,"column":1}},"children":[{"type":"text","value":"The primary object of interest in kriging is the variogram","position":{"start":{"line":15,"column":1},"end":{"line":15,"column":1}},"key":"NdaYmUX6jg"}],"key":"adA3ond8nK"},{"type":"text","value":", which is the main method by which practitioners fit a covariance function. ","position":{"start":{"line":15,"column":1},"end":{"line":15,"column":1}},"key":"Y2loZz3MlP"},{"type":"strong","position":{"start":{"line":15,"column":1},"end":{"line":15,"column":1}},"children":[{"type":"text","value":"In contrast, the primary object of interest in GPs is the kernel, which is directly equivalent to covariances.","position":{"start":{"line":15,"column":1},"end":{"line":15,"column":1}},"key":"Q6TM6VkLpa"}],"key":"NHaB0Sshte"},{"type":"text","value":" The kernel formulation has direct computational savings, enabling solving of high dimensional kernel functions in low dimensional space via the kernel trick (i.e., computing only the inner products) (","position":{"start":{"line":15,"column":1},"end":{"line":15,"column":1}},"key":"VjcVJSy7KW"},{"type":"cite","identifier":"genton","label":"genton","kind":"narrative","position":{"start":{"line":15,"column":455},"end":{"line":15,"column":462}},"children":[{"type":"text","value":"Genton (2002)","key":"XPp0YAVa3L"}],"enumerator":"5","key":"YxPwtvfi7R"},{"type":"text","value":"); the kernel formulation also admits easy translation to Fourier based methods when interpolating regular spaces (","position":{"start":{"line":15,"column":1},"end":{"line":15,"column":1}},"key":"PmfIv9HE5E"},{"type":"cite","url":"https://doi.org/10.48550/arXiv.1302.4245","position":{"start":{"line":15,"column":1},"end":{"line":15,"column":1}},"children":[{"type":"text","value":"Wilson \u0026 Adams (2013)","position":{"start":{"line":15,"column":1},"end":{"line":15,"column":1}},"key":"W49fevm0Ie"}],"kind":"narrative","label":"https://doi.org/10.48550/arxiv.1302.4245","identifier":"https://doi.org/10.48550/arXiv.1302.4245","enumerator":"6","key":"fxxl4nA0iY"},{"type":"text","value":"). Kernel architecture is flexible, as valid kernels can be added or multiplied to form new synthesis kernels (","position":{"start":{"line":15,"column":1},"end":{"line":15,"column":1}},"key":"GoVCoxBh8h"},{"type":"cite","url":"https://doi.org/10.1080/01621459.1999.10473885","position":{"start":{"line":15,"column":1},"end":{"line":15,"column":1}},"children":[{"type":"text","value":"Cressie \u0026 Huang (1999)","position":{"start":{"line":15,"column":1},"end":{"line":15,"column":1}},"key":"ffi8CK1Zqs"}],"kind":"narrative","label":"Cressie_1999","identifier":"https://doi.org/10.1080/01621459.1999.10473885","enumerator":"7","key":"RlMu7zsozB"},{"type":"text","value":"). For instance, non-stationary kernels can be combined with stationary kernels and white noise kernels, such that large spatial trends, local correlation and structure, and intrinsic random noise and error can be modeled and specified as discrete submodules and functions-- ","position":{"start":{"line":15,"column":1},"end":{"line":15,"column":1}},"key":"drc1EFSu0n"},{"type":"link","url":"https://towardsdatascience.com/gaussian-process-kernels-96bafb4dd63e/","position":{"start":{"line":15,"column":1},"end":{"line":15,"column":1}},"children":[{"type":"text","value":"see here for a practical example using Mauna Loa data","position":{"start":{"line":15,"column":1},"end":{"line":15,"column":1}},"key":"DAAVOtGR10"}],"urlSource":"https://towardsdatascience.com/gaussian-process-kernels-96bafb4dd63e/","key":"D7xVvxUtmm"},{"type":"text","value":" in scikit-learn. Kernels can also be bounded for more efficient computation—for instance, circular and spherical kernels give rise to sparse gram matrices that can be reordered and solved by efficient sparse solvers; the Matérn kernel (","position":{"start":{"line":15,"column":1},"end":{"line":15,"column":1}},"key":"NfLsgwRN2z"},{"type":"cite","url":"https://doi.org/10.1007/978-1-4615-7892-5","position":{"start":{"line":15,"column":1},"end":{"line":15,"column":1}},"children":[{"type":"text","value":"Matérn, 1960","position":{"start":{"line":15,"column":1},"end":{"line":15,"column":1}},"key":"G2BMRyCeFk"}],"kind":"narrative","label":"Mat_rn_1986","identifier":"https://doi.org/10.1007/978-1-4615-7892-5","enumerator":"8","key":"Kv2rQFEdXJ"},{"type":"text","value":") can be modified to do the same. Separable non-stationary kernels can be written as a Kronecker tensor product (","position":{"start":{"line":15,"column":1},"end":{"line":15,"column":1}},"key":"IP9jTLLDiI"},{"type":"cite","identifier":"genton","label":"genton","kind":"narrative","position":{"start":{"line":15,"column":1635},"end":{"line":15,"column":1642}},"children":[{"type":"text","value":"Genton (2002)","key":"wwPMf7WXBa"}],"enumerator":"5","key":"I6Ol7cKmHe"},{"type":"text","value":"), and solved in circulant matrixes by efficient Fourier methods (","position":{"start":{"line":15,"column":1},"end":{"line":15,"column":1}},"key":"fqam3hS1RE"},{"type":"cite","url":"https://doi.org/10.48550/arXiv.1503.01057","position":{"start":{"line":15,"column":1},"end":{"line":15,"column":1}},"children":[{"type":"text","value":"Wilson \u0026 Nickisch (2015)","position":{"start":{"line":15,"column":1},"end":{"line":15,"column":1}},"key":"gAhLtceEUP"}],"kind":"narrative","label":"https://doi.org/10.48550/arxiv.1503.01057","identifier":"https://doi.org/10.48550/arXiv.1503.01057","enumerator":"9","key":"eys8ShWcvH"},{"type":"text","value":").","position":{"start":{"line":15,"column":1},"end":{"line":15,"column":1}},"key":"P0mp2QpgDp"}],"key":"oo0pG1vuPD"},{"type":"paragraph","position":{"start":{"line":17,"column":1},"end":{"line":17,"column":1}},"children":[{"type":"text","value":"Although Gaussian Processes is the more general statistical term for covariance methods of prediction, the practice and term of kriging predates Gaussian Processes. Thus, to explain the history and theory of Gaussian Processes, we’ll start with kriging first.","position":{"start":{"line":17,"column":1},"end":{"line":17,"column":1}},"key":"mAUMxWeei9"}],"key":"LO5zKfibZS"}],"key":"IxG2Tr8wEq"},{"type":"block","kind":"notebook-content","children":[{"type":"heading","depth":3,"position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"What is kriging (informally)?","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"jlRTVlLFrs"}],"identifier":"what-is-kriging-informally","label":"What is kriging (informally)?","html_id":"what-is-kriging-informally","implicit":true,"key":"pjq4ewPNrV"},{"type":"paragraph","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"children":[{"type":"text","value":"Generally speaking, most people use kriging as an interpolator. Classic interpolators can be split into ‘","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"key":"TUFeBXHyEc"},{"type":"emphasis","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"children":[{"type":"text","value":"estimators","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"key":"i8C2qUKzen"}],"key":"efkyytlPHQ"},{"type":"text","value":"’ and ‘","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"key":"unggRfg56h"},{"type":"emphasis","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"children":[{"type":"text","value":"predictors","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"key":"vL0mdFw9Po"}],"key":"EaIgLLmVf4"},{"type":"text","value":"’; this distinction (in line with ","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"key":"MDbfDn7gXd"},{"type":"cite","url":"https://doi.org/10.1007/bf00889887","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"children":[{"type":"text","value":"Cressie, 1990","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"key":"iXDXzh4rIt"}],"kind":"narrative","label":"Cressie_1990","identifier":"https://doi.org/10.1007/bf00889887","enumerator":"10","key":"FHkSZkWGph"},{"type":"text","value":") mainly applies to highlight that ‘","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"key":"pWoDfqsmuu"},{"type":"emphasis","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"children":[{"type":"text","value":"estimators","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"key":"j17AuerTn4"}],"key":"pdRjd1NXK4"},{"type":"text","value":"’ provide an estimate of the surface, while ‘","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"key":"brpgrMfkAI"},{"type":"emphasis","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"children":[{"type":"text","value":"predictors","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"key":"b97ifCFRmc"}],"key":"BfcgbHI0GK"},{"type":"text","value":"’ assign a prediction that is accompanied by measures of confidence (probability, confidence interval).","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"key":"hOAis7Sfic"}],"key":"I6xdCrkzF9"},{"type":"image","url":"/build/03d1076e4e32f4695734b1167c5c65c6.jpeg","alt":"image.jpg","position":{"start":{"line":5,"column":1},"end":{"line":5,"column":1}},"key":"ACtPvxnC48","urlSource":"https://github.com/YuePanEdward/PPE_Kriging/blob/main/figures/result_dense_dataset.jpg?raw=true","urlOptimized":"/build/03d1076e4e32f4695734b1167c5c65c6.webp"},{"type":"paragraph","position":{"start":{"line":7,"column":1},"end":{"line":7,"column":1}},"children":[{"type":"emphasis","position":{"start":{"line":7,"column":1},"end":{"line":7,"column":1}},"children":[{"type":"text","value":"Estimators including nearest neighbor, bilinear interpolation, and cubic spline (bottom), as compared with kriging predictions using three different kernels (top)","position":{"start":{"line":7,"column":1},"end":{"line":7,"column":1}},"key":"PkORrdNzwS"}],"key":"KhJuWkbbeg"}],"key":"l0jpwVBPrp"},{"type":"paragraph","position":{"start":{"line":9,"column":1},"end":{"line":9,"column":1}},"children":[{"type":"text","value":"Traditional ‘","position":{"start":{"line":9,"column":1},"end":{"line":9,"column":1}},"key":"GVfbl5Vb3A"},{"type":"emphasis","position":{"start":{"line":9,"column":1},"end":{"line":9,"column":1}},"children":[{"type":"text","value":"estimators","position":{"start":{"line":9,"column":1},"end":{"line":9,"column":1}},"key":"lR20sXFWYD"}],"key":"l6OubFpNmh"},{"type":"text","value":"’ are of the fairly boring type that most are fairly familiar with— canonical examples are bilinear interpolation, Inverse Distance Weighting (IDW), cubic convolution, etc. Other non-traditional examples of ‘estimators’ include things like nearest and natural neighbor interpolation, which are appropriate for specific domain cases when you want to preserve original data values. If your ","position":{"start":{"line":9,"column":1},"end":{"line":9,"column":1}},"key":"KcvB76OquT"},{"type":"strong","position":{"start":{"line":9,"column":1},"end":{"line":9,"column":1}},"children":[{"type":"text","value":"goal","position":{"start":{"line":9,"column":1},"end":{"line":9,"column":1}},"key":"YILudF26Tf"}],"key":"q7YTngpnRN"},{"type":"text","value":" is ","position":{"start":{"line":9,"column":1},"end":{"line":9,"column":1}},"key":"bTaZ50k0b8"},{"type":"strong","position":{"start":{"line":9,"column":1},"end":{"line":9,"column":1}},"children":[{"type":"text","value":"just","position":{"start":{"line":9,"column":1},"end":{"line":9,"column":1}},"key":"vkk0c3GsGr"}],"key":"vzoHjfEp7r"},{"type":"text","value":" interpolation ","position":{"start":{"line":9,"column":1},"end":{"line":9,"column":1}},"key":"gkzXT4BvB5"},{"type":"strong","position":{"start":{"line":9,"column":1},"end":{"line":9,"column":1}},"children":[{"type":"text","value":"and you have sufficient data","position":{"start":{"line":9,"column":1},"end":{"line":9,"column":1}},"key":"EcX8XcOmIR"}],"key":"HVc04c6IyC"},{"type":"text","value":", using an estimator is perfectly fine-- and fast! However, if your data is ","position":{"start":{"line":9,"column":1},"end":{"line":9,"column":1}},"key":"qrMvUhrRMI"},{"type":"strong","position":{"start":{"line":9,"column":1},"end":{"line":9,"column":1}},"children":[{"type":"text","value":"sparse","position":{"start":{"line":9,"column":1},"end":{"line":9,"column":1}},"key":"pNqbSDssab"}],"key":"FNWfTT0ef0"},{"type":"text","value":", kriging starts to become more appealing:","position":{"start":{"line":9,"column":1},"end":{"line":9,"column":1}},"key":"ECXrGJRpj3"}],"key":"rGFIlSKx4F"},{"type":"image","url":"/build/bdb989a18e2c78b76f49ebabc3b22a39.jpeg","alt":"image.jpg","position":{"start":{"line":12,"column":1},"end":{"line":12,"column":1}},"key":"WXPAo6CO42","urlSource":"https://github.com/YuePanEdward/PPE_Kriging/blob/main/figures/result_sparse_dataset.jpg?raw=true","urlOptimized":"/build/bdb989a18e2c78b76f49ebabc3b22a39.webp"},{"type":"paragraph","position":{"start":{"line":14,"column":1},"end":{"line":14,"column":1}},"children":[{"type":"text","value":"This sparse estimation capability is why kriging was originally developed. Kriging is named after Danie G. Krige, who’s 1951 master’s thesis developed and described what we call ‘Ordinary Kriging’. Danie Krige was a prospector looking for gold in South Africa, an application that had sparse input measurements, and expensive sampling. Krige’s method was coined ‘kriging’ by the early 1960’s by French mathematician Georges Matheron, who formalized and expanded the method.","position":{"start":{"line":14,"column":1},"end":{"line":14,"column":1}},"key":"v7zWabYLjC"}],"key":"Ej3QXbWVuV"},{"type":"paragraph","position":{"start":{"line":16,"column":1},"end":{"line":16,"column":1}},"children":[{"type":"text","value":"Of course, the other case where kriging is appealing is when you need to use the method as a ","position":{"start":{"line":16,"column":1},"end":{"line":16,"column":1}},"key":"lDGRVICgmQ"},{"type":"emphasis","position":{"start":{"line":16,"column":1},"end":{"line":16,"column":1}},"children":[{"type":"text","value":"predictor","position":{"start":{"line":16,"column":1},"end":{"line":16,"column":1}},"key":"frTnEgbyAi"}],"key":"D1IQ05OvtJ"},{"type":"text","value":".","position":{"start":{"line":16,"column":1},"end":{"line":16,"column":1}},"key":"U8VtC2HZ68"}],"key":"ySdIjdzPJ8"}],"key":"pP3uq29nGv"},{"type":"block","kind":"notebook-content","children":[{"type":"heading","depth":3,"position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"Covariance, Gold, and the variogram model","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"Gi94sCWDMc"}],"identifier":"covariance-gold-and-the-variogram-model","label":"Covariance, Gold, and the variogram model","html_id":"covariance-gold-and-the-variogram-model","implicit":true,"key":"ziMjdweEKn"},{"type":"image","url":"/build/2ffed4862480bba556962ff294be9d78.gif","alt":"image.gif","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"key":"LIPhCTHJUo","urlSource":"https://vsp.pnnl.gov/help/image/Variogram.gif","urlOptimized":"/build/2ffed4862480bba556962ff294be9d78.webp"},{"type":"paragraph","position":{"start":{"line":5,"column":1},"end":{"line":5,"column":1}},"children":[{"type":"text","value":"Traditional kriging defines a ","position":{"start":{"line":5,"column":1},"end":{"line":5,"column":1}},"key":"zvCsvjHEtW"},{"type":"strong","position":{"start":{"line":5,"column":1},"end":{"line":5,"column":1}},"children":[{"type":"text","value":"model of covariance","position":{"start":{"line":5,"column":1},"end":{"line":5,"column":1}},"key":"x5iqQAIwqD"}],"key":"giiBbqtARB"},{"type":"text","value":" by fitting a function to the empirical ‘variogram’, which plots the variance between observations as a function of distance between those observations. The variogram ‘sill’ refers to variance between uncorrelated samples, and the ‘range’ is the lag-distance at which this paired observation decorrelation occurs. The ‘nugget’ refers to the intrinsic variance (i.e., the observational uncertainty) at distance zero-- that is, the variance of a single point observation with itself. The term ‘nugget’ is literally referring to ‘gold nugget’ in the context of prospecting; i.e., finding a ‘nugget’ of gold which has been displaced from the source gold deposit... just because a ‘nugget’ is present at a location, does not guarantee that you are coincident with the deposit ","position":{"start":{"line":5,"column":1},"end":{"line":5,"column":1}},"key":"AxYGnonOgi"},{"type":"emphasis","position":{"start":{"line":5,"column":1},"end":{"line":5,"column":1}},"children":[{"type":"text","value":"that generated that observation","position":{"start":{"line":5,"column":1},"end":{"line":5,"column":1}},"key":"wdT22AP5Lc"}],"key":"yIc93VX6L2"},{"type":"text","value":"; however, the expectation is that the nugget is close!","position":{"start":{"line":5,"column":1},"end":{"line":5,"column":1}},"key":"lPmYLTtaEp"}],"key":"w7JsyRtzVD"},{"type":"image","url":"/build/ff8c410b251590af858bbaf80f9b6717.png","alt":"image.png","position":{"start":{"line":7,"column":1},"end":{"line":7,"column":1}},"key":"pSudsWPz0s","urlSource":"https://scikit-learn.org/stable/_images/sphx_glr_plot_gpr_noisy_targets_003.png","urlOptimized":"/build/ff8c410b251590af858bbaf80f9b6717.webp"},{"type":"paragraph","position":{"start":{"line":9,"column":1},"end":{"line":9,"column":1}},"children":[{"type":"text","value":"Mathematically, specifying a ‘nugget’ value (or ","position":{"start":{"line":9,"column":1},"end":{"line":9,"column":1}},"key":"XaWLn2RHKJ"},{"type":"inlineCode","value":"alpha","position":{"start":{"line":9,"column":1},"end":{"line":9,"column":1}},"key":"Vyqvwm7oQK"},{"type":"text","value":" in GP terminology) is effectively adding a constant to the diagonal of the covariance matrix such that each observation has some level of variance with itself. Doing this allows flexibility for the mean of the predictions to ","position":{"start":{"line":9,"column":1},"end":{"line":9,"column":1}},"key":"mxdIvy2w0o"},{"type":"emphasis","position":{"start":{"line":9,"column":1},"end":{"line":9,"column":1}},"children":[{"type":"text","value":"not","position":{"start":{"line":9,"column":1},"end":{"line":9,"column":1}},"key":"SaFrThPQer"}],"key":"lswLgVgsQZ"},{"type":"text","value":" intersect all of the observation points-- if covariance is set to zero along the diagonal, then any estimation will be a ‘rubber sheeting’ that ensures the output surface prediction passes through the original data points. Of course, we can also specify covariance ","position":{"start":{"line":9,"column":1},"end":{"line":9,"column":1}},"key":"nZqItcj8j6"},{"type":"emphasis","position":{"start":{"line":9,"column":1},"end":{"line":9,"column":1}},"children":[{"type":"text","value":"per observation","position":{"start":{"line":9,"column":1},"end":{"line":9,"column":1}},"key":"eBgGBODHWw"}],"key":"pchONxwN2D"},{"type":"text","value":" rather than as a constant along the diagonal, and selectively ","position":{"start":{"line":9,"column":1},"end":{"line":9,"column":1}},"key":"XeJ3VxLU1R"},{"type":"emphasis","position":{"start":{"line":9,"column":1},"end":{"line":9,"column":1}},"children":[{"type":"text","value":"down weight","position":{"start":{"line":9,"column":1},"end":{"line":9,"column":1}},"key":"cFehXSGu5c"}],"key":"ta1LUoTuBC"},{"type":"text","value":" low confidence observations.","position":{"start":{"line":9,"column":1},"end":{"line":9,"column":1}},"key":"kQLLpjSC1Z"}],"key":"OztKpdazrF"}],"key":"WBn9jCR2hq"},{"type":"block","kind":"notebook-content","children":[{"type":"heading","depth":3,"position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"What I use Gaussian Processes for","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"r4VvcheBt7"}],"identifier":"what-i-use-gaussian-processes-for","label":"What I use Gaussian Processes for","html_id":"what-i-use-gaussian-processes-for","implicit":true,"key":"mSCqk3qQLC"}],"key":"ihU90aclTc"},{"type":"block","kind":"notebook-code","children":[{"type":"code","lang":"python","executable":true,"value":"%matplotlib inline","key":"yzbHNI5gXY"},{"type":"output","id":"ICRFtme3r_yimzT5-UzZF","data":[],"key":"cY4Fpx61sc"}],"key":"BQEiBJZXnE"},{"type":"block","kind":"notebook-code","children":[{"type":"code","lang":"python","executable":true,"value":"import matplotlib.pyplot as plt\nimport matplotlib as mpl\nimport pandas as pd\nimport numpy as np\nfrom tqdm.notebook import tqdm\nfrom osgeo import osr\nimport pyproj\nfrom sklearn.gaussian_process import GaussianProcessRegressor\nfrom sklearn.gaussian_process.kernels import Matern, WhiteKernel, RBF","key":"rI0STCd1RL"},{"type":"output","id":"SHU3pfnBQ0m1kzhMaHJMU","data":[],"key":"pFhMgC8mOl"}],"key":"akpDx99NAa"},{"type":"block","kind":"notebook-code","children":[{"type":"code","lang":"python","executable":true,"value":"rng = np.random.default_rng() # numpy sampling API\n#np.random.seed(1234)\n#np.random.seed(55)\nnp.random.seed(123)","key":"zAFP9hF3xX"},{"type":"output","id":"TPzZZ_3mcMCEOo7O8Ts9X","data":[],"key":"rsKIH0Ckzo"}],"key":"ntFT3sem7p"},{"type":"block","kind":"notebook-code","children":[{"type":"code","lang":"python","executable":true,"value":"data = pd.HDFStore(\"./Z62SU06\" + \".h5\", 'r') # ICESat data\ncoordlist = data['coords'] # Needed for distance calculations / plotting\ndf_indices = data['indices'] # UUID to link to observations to slope retrievals\ndf_corr = data['corr'] # Filter and weight data\n\ngslope = np.load('./General_slopes.npy') # Sub ICESat footprint slope retrievals\nmean_slope = np.zeros(len(coordlist))\nstd_slope = np.zeros(len(coordlist))\n\n# Merge and aggregate slope\nfor i in tqdm(range(len(coordlist))):\n    sweights = np.array(df_corr.iloc[i].values)\n    weightidx = np.isfinite(sweights)\n    sweights = np.abs(sweights[weightidx])\n    sidx = df_indices.iloc[i].values[weightidx]\n    sidx = np.array(sidx, dtype=int)\n    mean_slope[i] = np.average(gslope[sidx], weights=sweights)\n    std_slope[i] = np.std(gslope[sidx])","key":"MQof38maBE"},{"type":"output","id":"Pk0Ci0_hsE4hZga7Fdwsq","data":[{"output_type":"display_data","metadata":{},"data":{"application/vnd.jupyter.widget-view+json":{"content":"{\"model_id\":\"ae33b6b604ec4c5d830f236df557e5e1\",\"version_major\":2,\"version_minor\":0}","content_type":"application/vnd.jupyter.widget-view+json"},"text/plain":{"content":"  0%|          | 0/23359 [00:00\u003c?, ?it/s]","content_type":"text/plain"}}}],"key":"EzSM5gL8la"}],"key":"ozm1Uc6m60"},{"type":"block","kind":"notebook-content","children":[{"type":"paragraph","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"This example is meant to be larger than a ‘toy’ dataset, but still small enough to interact with and demonstrate. Our input data consist of 23,359 observations (from the summer of 2006), which are within footprint slope retrievals from the first ICESat mission (which flew from 2003 to 2009, although laser power was strongest in the first three years).","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"EI3YygZZ5I"}],"key":"zZkFtye84o"},{"type":"paragraph","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"children":[{"type":"text","value":"Here’s what the data looks like:","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"key":"Mj6mWWi9KP"}],"key":"iyBzmgYiEy"}],"key":"GF3D6gNZYx"},{"type":"block","kind":"notebook-code","children":[{"type":"code","lang":"python","executable":true,"value":"fig, ax = plt.subplots()\nim = ax.scatter(coordlist.lon, coordlist.lat, c=mean_slope, s=std_slope**2)\nim.set_clim(min(mean_slope), max(mean_slope))\nfig.colorbar(im, ax=ax, label=\"Degrees of slope \\n (points scaled by retrieval variance)\")\nplt.show()","key":"ZeZwygLokk"},{"type":"output","id":"vBPltrFfKrZarFt28AnXM","data":[{"output_type":"display_data","metadata":{},"data":{"image/png":{"content_type":"image/png","hash":"7809e52609e3ddbec2e8e4baee69beb1","path":"/build/7809e52609e3ddbec2e8e4baee69beb1.png"},"text/plain":{"content":"\u003cFigure size 640x480 with 2 Axes\u003e","content_type":"text/plain"}}}],"key":"OTEnZzIaP7"}],"key":"eKtuoou0FG"},{"type":"block","kind":"notebook-content","children":[{"type":"paragraph","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"This is an interesting case of geostatistics because the sampling is quite odd-- the along track resolution is dense, but the across track resolution is sparse. Most of the code is actually setting up the ","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"h4AypWeTnU"},{"type":"strong","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"source","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"T4bi6YqMAk"}],"key":"KNI2UHigOh"},{"type":"text","value":" and ","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"YQwIFmL7bZ"},{"type":"strong","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"target","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"dZovGcuYEZ"}],"key":"o8nJXmzt9J"},{"type":"text","value":" coordinate systems for the model. The input observational data is irregularly spaced and in lat/lon coordinates, but we want our distance measurements to be in euclidean space and output to a grid.","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"VgRfSQ88e6"}],"key":"qGofVwE1NU"},{"type":"paragraph","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"children":[{"type":"text","value":"We also want to ‘clip’ the results to a drainage basin. This is for two reasons-- first, the drainage basin boundries are of zero surface slope and provide a physically meaningful way to bound, divide, and tile the analysis. And second, covariance functions are expensive, so clipping and masking the edges of our area of interest helps things run faster... it also makes the output look good!","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"key":"B9lFUvOq3z"}],"key":"ikO72DK0dK"}],"key":"AyxRXfSb7d"},{"type":"block","kind":"notebook-code","children":[{"type":"code","lang":"python","executable":true,"value":"# Projection object\nds = osr.SpatialReference()\nds.ImportFromEPSG(3411) # polar projection\nds.ExportToProj4()\np2 = pyproj.Proj(ds.ExportToProj4())\n\n# Observations to meters from lat / lon\nX, Y = p2(np.array(coordlist.lon),\n          np.array(coordlist.lat))\n# To vector form sklearn\ncoords_m = np.ones((len(coordlist),2))\ncoords_m[:,0] = X\ncoords_m[:,1] = Y\n\n# Drainage basin boundries\nzwally = pd.read_csv('./GrnDrainageSystems_Ekholm.txt',\n                     sep=r\"\\s+\", names=['basin', 'lat','long'])\nbasin = '6.2'\nLL = zip(zwally[zwally.basin == float(basin)].long,\n         zwally[zwally.basin == float(basin)].lat)\nLL = list(LL)\n# Convert basin boundries to meters from lat / lon\npX, pY = p2(np.array(LL)[:,0],\n            np.array(LL)[:,1])\n# Polygon object for masking\nZ = mpl.path.Path(list(zip(pX, pY)))\n\n# Setting up kriging grid\nx1, y1 = np.meshgrid(np.r_[round(min(pX), -2) - 2500:round(max(pX), -2) + 2500:5000],\n                     np.r_[round(min(pY), -2) - 2500:round(max(pY), -2) + 2500:5000])\nkcoords = np.vstack([x1.ravel(),y1.ravel()]).T\n\n# Masking kriging grid\nZidx = Z.contains_points(kcoords[:])\ntarget_c = kcoords[Zidx] # Target coordinates\nx1.shape, len(target_c)","key":"HAVjgYTyCN"},{"type":"output","id":"N8MjkmYRO8ZjlwnplQN7N","data":[{"output_type":"execute_result","execution_count":6,"metadata":{},"data":{"text/plain":{"content":"((108, 110), 5600)","content_type":"text/plain"}}}],"key":"yF8Fazg7Qg"}],"key":"rjGV22FnLQ"},{"type":"block","kind":"notebook-content","children":[{"type":"paragraph","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"At this point, we’ve setup a 2-km grid to predict on that’s 267 by 273 (a little over 500km per side), which after masking has 34,984 target coordinate locations to predict at. The actual Gaussian Process model specification is fairly short:","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"vvif39iBEg"}],"key":"AK3CYxOKNe"}],"key":"rXQUZcVHE5"},{"type":"block","kind":"notebook-code","children":[{"type":"code","lang":"python","executable":true,"value":"ind = np.array(range(0,len(coordlist)), dtype=int)\nidxs = np.random.choice(ind, size=4000)","key":"CFwTcqCfQg"},{"type":"output","id":"74PMpFVsOKrXjKewT-p9x","data":[],"key":"ltlIe2DFBE"}],"key":"RVLVmJFMLQ"},{"type":"block","kind":"notebook-code","children":[{"type":"code","lang":"python","executable":true,"value":"%%time\nnoise = WhiteKernel(noise_level=.5)\nrbf = 3 * RBF(length_scale=[80000,80000])\nkern = 2.0 * Matern(length_scale=[80000,80000], length_scale_bounds=(1e3, 1e6),\n                        nu=0.5)\ngp1 = GaussianProcessRegressor(kernel=rbf+kern+noise, alpha=std_slope[idxs]**2, optimizer=None).fit(coords_m[idxs], mean_slope[idxs])","key":"ZkJuInpYm2"},{"type":"output","id":"yPbObijNp_rhKwJBzItjC","data":[{"name":"stdout","output_type":"stream","text":"CPU times: user 7.48 s, sys: 984 ms, total: 8.46 s\nWall time: 1.29 s\n"}],"key":"GkKK1WXYq9"}],"key":"TDffK0upLo"},{"type":"block","kind":"notebook-content","children":[{"type":"paragraph","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"We are specifying a ","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"pMfjb50JuB"},{"type":"inlineCode","value":"Matern","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"qNMRDdCyTj"},{"type":"text","value":" kernel to calculate and estimate our covarience, which is defined by the single parameter ","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"xFT9IQ7mTC"},{"type":"inlineCode","value":"nu","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"mBYJNiFbAm"},{"type":"text","value":"; this parameter controls how smooth the fuctions are within our prior distribution of possible surface functions. It is set at 0.5 (i.e., ‘1 / 2’, equivelent the absolute exponential kernel) to allow rough, non-differentiable candidate functions; a ","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"qyZCESxmYy"},{"type":"inlineCode","value":"nu=1.5","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"b3pAQGTMg7"},{"type":"text","value":" (3 / 2) will select from functions that are once differentiable, ","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"C7c5seSpmL"},{"type":"inlineCode","value":"nu=2.5","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"kK326bQ6DT"},{"type":"text","value":" (5 / 2) will select from functions that are twice differentiable, and ","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"Hk2IZlKxkt"},{"type":"inlineCode","value":"nu=inf","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"t3bpVH6dk7"},{"type":"text","value":" will converge to the infinately differentiable RBF kernel.","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"ZMtfEcF4Qs"}],"key":"hYhWymzxpZ"},{"type":"paragraph","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"children":[{"type":"text","value":"The ","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"key":"uvuvjN1ygd"},{"type":"inlineCode","value":"length_scale","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"key":"mP8Wbsyxft"},{"type":"text","value":" parameter would typically be optimized during model fit based on the spatial structure of the data... however, because our input data is heavily unbalanced (i.e., dense in the along track direction, sparse in the across track), hyper-parameter optimization sets a length scale that is too short, so it is fixed at 80km, with similar settings applied for the ","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"key":"oFcF4y2zv8"},{"type":"inlineCode","value":"length_scale_bounds","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"key":"w4qUWNP1wc"},{"type":"text","value":".","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"key":"oaHhLQaD3I"}],"key":"BtQh63SzTl"},{"type":"paragraph","position":{"start":{"line":5,"column":1},"end":{"line":5,"column":1}},"children":[{"type":"text","value":"After model specification, at ","position":{"start":{"line":5,"column":1},"end":{"line":5,"column":1}},"key":"LGPqCphJzy"},{"type":"inlineCode","value":"fit","position":{"start":{"line":5,"column":1},"end":{"line":5,"column":1}},"key":"LZG2mz9S5p"},{"type":"text","value":" time we provide the coordinates, and slope values, along with an ","position":{"start":{"line":5,"column":1},"end":{"line":5,"column":1}},"key":"ZpZy6Qjd0d"},{"type":"inlineCode","value":"alpha","position":{"start":{"line":5,"column":1},"end":{"line":5,"column":1}},"key":"m4rL83vAZI"},{"type":"text","value":" that is set to varience of slope retrieval (i.e., estimates of varience per observation).","position":{"start":{"line":5,"column":1},"end":{"line":5,"column":1}},"key":"kSlizAbGQ1"}],"key":"B0S3UNxULf"},{"type":"paragraph","position":{"start":{"line":7,"column":1},"end":{"line":7,"column":1}},"children":[{"type":"text","value":"Doubling the number of observations (by adding a second summer of orbits) pushes the model fit time from under two minutes to about a half hour (although some of this is due to the higher memory footprint and pressure causing the OS to begin swapping to disk).","position":{"start":{"line":7,"column":1},"end":{"line":7,"column":1}},"key":"q8BOvLMBsN"}],"key":"zusXY3fgr4"},{"type":"paragraph","position":{"start":{"line":9,"column":1},"end":{"line":9,"column":1}},"children":[{"type":"text","value":"We can get the mean surface estimate and target-to-target covariances with the following:","position":{"start":{"line":9,"column":1},"end":{"line":9,"column":1}},"key":"gokjwAHWSa"}],"key":"ZP0DPhPSpJ"}],"key":"aExPEF75JT"},{"type":"block","kind":"notebook-code","children":[{"type":"code","lang":"python","executable":true,"value":"%%time\ny_mean, y_cov = gp1.predict(target_c, return_cov=True)","key":"OiqKy1JqT4"},{"type":"output","id":"BY6R9rBIRK9fzO42ibqbM","data":[{"name":"stdout","output_type":"stream","text":"CPU times: user 12.5 s, sys: 1.79 s, total: 14.3 s\nWall time: 2.09 s\n"}],"key":"QyQIDtIFcm"}],"key":"oNw6UDC98g"},{"type":"block","kind":"notebook-content","children":[{"type":"paragraph","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"The mean predictions need to be reshaped before plotting:","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"ts4sCMhaT0"}],"key":"Boo1ipoSBs"}],"key":"J14v7pOdED"},{"type":"block","kind":"notebook-code","children":[{"type":"code","lang":"python","executable":true,"value":"# slope\nresults1 = np.ones(len(kcoords)) *np.nan\nresults1[Zidx] =  y_mean\nshow_res1 = results1.reshape((x1.shape))\nplt.imshow(np.flipud(show_res1), vmin=0, vmax=10)\nplt.colorbar()\nplt.show()","key":"AcVDPWTUMy"},{"type":"output","id":"2hLPICBkJY4pQ_tJgrvbs","data":[{"output_type":"display_data","metadata":{},"data":{"image/png":{"content_type":"image/png","hash":"e4355c71dd40f2cba42c72ffa8a053c5","path":"/build/e4355c71dd40f2cba42c72ffa8a053c5.png"},"text/plain":{"content":"\u003cFigure size 640x480 with 2 Axes\u003e","content_type":"text/plain"}}}],"key":"drWy46Nooh"}],"key":"BJdlDUYnSv"},{"type":"block","kind":"notebook-content","data":{"jp-MarkdownHeadingCollapsed":true},"children":[{"type":"heading","depth":3,"position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"What is kriging (formally)?","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"PJyz1FE0Y4"}],"identifier":"what-is-kriging-formally","label":"What is kriging (formally)?","html_id":"what-is-kriging-formally","implicit":true,"key":"X9hldBgtAI"},{"type":"paragraph","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"children":[{"type":"text","value":"Mathematically, kriging is the Best Unbiased Linear ","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"key":"lTwDgOPrjK"},{"type":"strong","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"children":[{"type":"text","value":"Predictor","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"key":"aIBYv2b3LO"}],"key":"adMtOIr7Wb"},{"type":"text","value":" (","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"key":"ZLnvNCjdCY"},{"type":"cite","identifier":"10.1007/bf02067214","label":"Journel_1977","kind":"narrative","position":{"start":{"line":3,"column":68},"end":{"line":3,"column":87}},"children":[{"type":"text","value":"Journel (1977)","key":"g3MzyIx4Lr"}],"enumerator":"4","key":"AiKRTEfLSe"},{"type":"text","value":" ; ","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"key":"QbXOALaBRc"},{"type":"cite","identifier":"10.1007/bf00889887","label":"Cressie_1990","kind":"narrative","position":{"start":{"line":3,"column":90},"end":{"line":3,"column":109}},"children":[{"type":"text","value":"Cressie (1990)","key":"ZbDMLyDOaA"}],"enumerator":"10","key":"wP6aIhuJJe"},{"type":"text","value":" ; ","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"key":"Cn4NvoW2sa"},{"type":"cite","identifier":"10.1080/00401706.1993.10485354","label":"Handcock_1993","kind":"narrative","position":{"start":{"line":3,"column":112},"end":{"line":3,"column":143}},"children":[{"type":"text","value":"Handcock \u0026 Stein (1993)","key":"Vyp6HvS2Jk"}],"enumerator":"11","key":"uTiuchrT71"},{"type":"text","value":"), and provides the Best Linear Unbiased Prediction, or BLUP; this means that kriging prediction is a linear combination of weighted observations at point p that minimizes prediction variance. Note that this is different (but related) to the Best Linear Unbiased ","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"key":"lBNMeJ07Wk"},{"type":"strong","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"children":[{"type":"text","value":"Estimation","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"key":"Hju35ofc5r"}],"key":"Bto2CP4oV1"},{"type":"text","value":", or BLUE... although when using kriging to ","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"key":"ioZ1qU4dUS"},{"type":"emphasis","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"children":[{"type":"text","value":"estimate","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"key":"Wij8CnP5iJ"}],"key":"FSoGcg1WPJ"},{"type":"text","value":" a quantity, the results will be equivilent to the BLUE, which is why kriging is often conceptually understood as equivalent to spatially weighted generalized least squares regression. There are of course various flavors of kriging (simple, ordinary, universal, etc.) (see ","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"key":"CvwA7QRRcz"},{"type":"cite","url":"10.1007/bf02067214","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"children":[{"type":"text","value":"Journel","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"key":"U4LeWfpfCe"}],"kind":"narrative","label":"Journel_1977","identifier":"10.1007/bf02067214","enumerator":"4","key":"xJXPhUZQAA"},{"type":"text","value":"), but below is mathematical formulation for simple kriging (other flavors are similar):","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"key":"y3ZSuLTT9A"}],"key":"cYHzcTvUtS"},{"type":"paragraph","position":{"start":{"line":5,"column":1},"end":{"line":5,"column":1}},"children":[{"type":"text","value":"Given N observations (s1…sn), and CovF(distance) covariance function, calculate D distances of N observations; note the convention of using ","position":{"start":{"line":5,"column":1},"end":{"line":5,"column":1}},"key":"F40mY6reki"},{"type":"inlineMath","value":"t","position":{"start":{"line":5,"column":1},"end":{"line":5,"column":1}},"html":"\u003cspan class=\"katex\"\u003e\u003cspan class=\"katex-mathml\"\u003e\u003cmath xmlns=\"http://www.w3.org/1998/Math/MathML\"\u003e\u003csemantics\u003e\u003cmrow\u003e\u003cmi\u003et\u003c/mi\u003e\u003c/mrow\u003e\u003cannotation encoding=\"application/x-tex\"\u003et\u003c/annotation\u003e\u003c/semantics\u003e\u003c/math\u003e\u003c/span\u003e\u003cspan class=\"katex-html\" aria-hidden=\"true\"\u003e\u003cspan class=\"base\"\u003e\u003cspan class=\"strut\" style=\"height:0.6151em;\"\u003e\u003c/span\u003e\u003cspan class=\"mord mathnormal\"\u003et\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e","key":"Ry4tdLYdBy"},{"type":"text","value":" for ","position":{"start":{"line":5,"column":1},"end":{"line":5,"column":1}},"key":"FALQpGxuJF"},{"type":"emphasis","position":{"start":{"line":5,"column":1},"end":{"line":5,"column":1}},"children":[{"type":"text","value":"target","position":{"start":{"line":5,"column":1},"end":{"line":5,"column":1}},"key":"mWgbbuouNf"}],"key":"PoDrdzWx3i"},{"type":"text","value":" and ","position":{"start":{"line":5,"column":1},"end":{"line":5,"column":1}},"key":"UiuoWMPhO3"},{"type":"inlineMath","value":"s","position":{"start":{"line":5,"column":1},"end":{"line":5,"column":1}},"html":"\u003cspan class=\"katex\"\u003e\u003cspan class=\"katex-mathml\"\u003e\u003cmath xmlns=\"http://www.w3.org/1998/Math/MathML\"\u003e\u003csemantics\u003e\u003cmrow\u003e\u003cmi\u003es\u003c/mi\u003e\u003c/mrow\u003e\u003cannotation encoding=\"application/x-tex\"\u003es\u003c/annotation\u003e\u003c/semantics\u003e\u003c/math\u003e\u003c/span\u003e\u003cspan class=\"katex-html\" aria-hidden=\"true\"\u003e\u003cspan class=\"base\"\u003e\u003cspan class=\"strut\" style=\"height:0.4306em;\"\u003e\u003c/span\u003e\u003cspan class=\"mord mathnormal\"\u003es\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e","key":"uHGNZugDPe"},{"type":"text","value":" for ","position":{"start":{"line":5,"column":1},"end":{"line":5,"column":1}},"key":"B76AqxQ7pU"},{"type":"emphasis","position":{"start":{"line":5,"column":1},"end":{"line":5,"column":1}},"children":[{"type":"text","value":"source","position":{"start":{"line":5,"column":1},"end":{"line":5,"column":1}},"key":"yMiHL8U0X6"}],"key":"h5FEOwRdyt"},{"type":"text","value":":","position":{"start":{"line":5,"column":1},"end":{"line":5,"column":1}},"key":"O0eeVe9q7a"}],"key":"lRvjtO3hDE"},{"type":"math","value":"D(s_1 ... s_n, s_1 ... s_n) = D_{obs}","position":{"start":{"line":7,"column":1},"end":{"line":7,"column":1}},"html":"\u003cspan class=\"katex-display\"\u003e\u003cspan class=\"katex\"\u003e\u003cspan class=\"katex-mathml\"\u003e\u003cmath xmlns=\"http://www.w3.org/1998/Math/MathML\" display=\"block\"\u003e\u003csemantics\u003e\u003cmrow\u003e\u003cmi\u003eD\u003c/mi\u003e\u003cmo stretchy=\"false\"\u003e(\u003c/mo\u003e\u003cmsub\u003e\u003cmi\u003es\u003c/mi\u003e\u003cmn\u003e1\u003c/mn\u003e\u003c/msub\u003e\u003cmi mathvariant=\"normal\"\u003e.\u003c/mi\u003e\u003cmi mathvariant=\"normal\"\u003e.\u003c/mi\u003e\u003cmi mathvariant=\"normal\"\u003e.\u003c/mi\u003e\u003cmsub\u003e\u003cmi\u003es\u003c/mi\u003e\u003cmi\u003en\u003c/mi\u003e\u003c/msub\u003e\u003cmo separator=\"true\"\u003e,\u003c/mo\u003e\u003cmsub\u003e\u003cmi\u003es\u003c/mi\u003e\u003cmn\u003e1\u003c/mn\u003e\u003c/msub\u003e\u003cmi mathvariant=\"normal\"\u003e.\u003c/mi\u003e\u003cmi mathvariant=\"normal\"\u003e.\u003c/mi\u003e\u003cmi mathvariant=\"normal\"\u003e.\u003c/mi\u003e\u003cmsub\u003e\u003cmi\u003es\u003c/mi\u003e\u003cmi\u003en\u003c/mi\u003e\u003c/msub\u003e\u003cmo stretchy=\"false\"\u003e)\u003c/mo\u003e\u003cmo\u003e=\u003c/mo\u003e\u003cmsub\u003e\u003cmi\u003eD\u003c/mi\u003e\u003cmrow\u003e\u003cmi\u003eo\u003c/mi\u003e\u003cmi\u003eb\u003c/mi\u003e\u003cmi\u003es\u003c/mi\u003e\u003c/mrow\u003e\u003c/msub\u003e\u003c/mrow\u003e\u003cannotation encoding=\"application/x-tex\"\u003eD(s_1 ... s_n, s_1 ... s_n) = D_{obs}\u003c/annotation\u003e\u003c/semantics\u003e\u003c/math\u003e\u003c/span\u003e\u003cspan class=\"katex-html\" aria-hidden=\"true\"\u003e\u003cspan class=\"base\"\u003e\u003cspan class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"\u003e\u003c/span\u003e\u003cspan class=\"mord mathnormal\" style=\"margin-right:0.02778em;\"\u003eD\u003c/span\u003e\u003cspan class=\"mopen\"\u003e(\u003c/span\u003e\u003cspan class=\"mord\"\u003e\u003cspan class=\"mord mathnormal\"\u003es\u003c/span\u003e\u003cspan class=\"msupsub\"\u003e\u003cspan class=\"vlist-t vlist-t2\"\u003e\u003cspan class=\"vlist-r\"\u003e\u003cspan class=\"vlist\" style=\"height:0.3011em;\"\u003e\u003cspan style=\"top:-2.55em;margin-left:0em;margin-right:0.05em;\"\u003e\u003cspan class=\"pstrut\" style=\"height:2.7em;\"\u003e\u003c/span\u003e\u003cspan class=\"sizing reset-size6 size3 mtight\"\u003e\u003cspan class=\"mord mtight\"\u003e1\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"vlist-s\"\u003e​\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"vlist-r\"\u003e\u003cspan class=\"vlist\" style=\"height:0.15em;\"\u003e\u003cspan\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"mord\"\u003e...\u003c/span\u003e\u003cspan class=\"mord\"\u003e\u003cspan class=\"mord mathnormal\"\u003es\u003c/span\u003e\u003cspan class=\"msupsub\"\u003e\u003cspan class=\"vlist-t vlist-t2\"\u003e\u003cspan class=\"vlist-r\"\u003e\u003cspan class=\"vlist\" style=\"height:0.1514em;\"\u003e\u003cspan style=\"top:-2.55em;margin-left:0em;margin-right:0.05em;\"\u003e\u003cspan class=\"pstrut\" style=\"height:2.7em;\"\u003e\u003c/span\u003e\u003cspan class=\"sizing reset-size6 size3 mtight\"\u003e\u003cspan class=\"mord mathnormal mtight\"\u003en\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"vlist-s\"\u003e​\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"vlist-r\"\u003e\u003cspan class=\"vlist\" style=\"height:0.15em;\"\u003e\u003cspan\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"mpunct\"\u003e,\u003c/span\u003e\u003cspan class=\"mspace\" style=\"margin-right:0.1667em;\"\u003e\u003c/span\u003e\u003cspan class=\"mord\"\u003e\u003cspan class=\"mord mathnormal\"\u003es\u003c/span\u003e\u003cspan class=\"msupsub\"\u003e\u003cspan class=\"vlist-t vlist-t2\"\u003e\u003cspan class=\"vlist-r\"\u003e\u003cspan class=\"vlist\" style=\"height:0.3011em;\"\u003e\u003cspan style=\"top:-2.55em;margin-left:0em;margin-right:0.05em;\"\u003e\u003cspan class=\"pstrut\" style=\"height:2.7em;\"\u003e\u003c/span\u003e\u003cspan class=\"sizing reset-size6 size3 mtight\"\u003e\u003cspan class=\"mord mtight\"\u003e1\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"vlist-s\"\u003e​\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"vlist-r\"\u003e\u003cspan class=\"vlist\" style=\"height:0.15em;\"\u003e\u003cspan\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"mord\"\u003e...\u003c/span\u003e\u003cspan class=\"mord\"\u003e\u003cspan class=\"mord mathnormal\"\u003es\u003c/span\u003e\u003cspan class=\"msupsub\"\u003e\u003cspan class=\"vlist-t vlist-t2\"\u003e\u003cspan class=\"vlist-r\"\u003e\u003cspan class=\"vlist\" style=\"height:0.1514em;\"\u003e\u003cspan style=\"top:-2.55em;margin-left:0em;margin-right:0.05em;\"\u003e\u003cspan class=\"pstrut\" style=\"height:2.7em;\"\u003e\u003c/span\u003e\u003cspan class=\"sizing reset-size6 size3 mtight\"\u003e\u003cspan class=\"mord mathnormal mtight\"\u003en\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"vlist-s\"\u003e​\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"vlist-r\"\u003e\u003cspan class=\"vlist\" style=\"height:0.15em;\"\u003e\u003cspan\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"mclose\"\u003e)\u003c/span\u003e\u003cspan class=\"mspace\" style=\"margin-right:0.2778em;\"\u003e\u003c/span\u003e\u003cspan class=\"mrel\"\u003e=\u003c/span\u003e\u003cspan class=\"mspace\" style=\"margin-right:0.2778em;\"\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"base\"\u003e\u003cspan class=\"strut\" style=\"height:0.8333em;vertical-align:-0.15em;\"\u003e\u003c/span\u003e\u003cspan class=\"mord\"\u003e\u003cspan class=\"mord mathnormal\" style=\"margin-right:0.02778em;\"\u003eD\u003c/span\u003e\u003cspan class=\"msupsub\"\u003e\u003cspan class=\"vlist-t vlist-t2\"\u003e\u003cspan class=\"vlist-r\"\u003e\u003cspan class=\"vlist\" style=\"height:0.3361em;\"\u003e\u003cspan style=\"top:-2.55em;margin-left:-0.0278em;margin-right:0.05em;\"\u003e\u003cspan class=\"pstrut\" style=\"height:2.7em;\"\u003e\u003c/span\u003e\u003cspan class=\"sizing reset-size6 size3 mtight\"\u003e\u003cspan class=\"mord mtight\"\u003e\u003cspan class=\"mord mathnormal mtight\"\u003eo\u003c/span\u003e\u003cspan class=\"mord mathnormal mtight\"\u003eb\u003c/span\u003e\u003cspan class=\"mord mathnormal mtight\"\u003es\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"vlist-s\"\u003e​\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"vlist-r\"\u003e\u003cspan class=\"vlist\" style=\"height:0.15em;\"\u003e\u003cspan\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e","enumerator":"1","key":"G4vKIYjzza"},{"type":"math","value":"C_{obs} = f_{cov}(D_{obs}) \\quad \\textrm{or} \\quad C(\\mathbf{x}_n, \\mathbf{x}_m) = k(\\mathbf{x}_n, \\mathbf{x}_m)","position":{"start":{"line":8,"column":1},"end":{"line":8,"column":1}},"html":"\u003cspan class=\"katex-display\"\u003e\u003cspan class=\"katex\"\u003e\u003cspan class=\"katex-mathml\"\u003e\u003cmath xmlns=\"http://www.w3.org/1998/Math/MathML\" display=\"block\"\u003e\u003csemantics\u003e\u003cmrow\u003e\u003cmsub\u003e\u003cmi\u003eC\u003c/mi\u003e\u003cmrow\u003e\u003cmi\u003eo\u003c/mi\u003e\u003cmi\u003eb\u003c/mi\u003e\u003cmi\u003es\u003c/mi\u003e\u003c/mrow\u003e\u003c/msub\u003e\u003cmo\u003e=\u003c/mo\u003e\u003cmsub\u003e\u003cmi\u003ef\u003c/mi\u003e\u003cmrow\u003e\u003cmi\u003ec\u003c/mi\u003e\u003cmi\u003eo\u003c/mi\u003e\u003cmi\u003ev\u003c/mi\u003e\u003c/mrow\u003e\u003c/msub\u003e\u003cmo stretchy=\"false\"\u003e(\u003c/mo\u003e\u003cmsub\u003e\u003cmi\u003eD\u003c/mi\u003e\u003cmrow\u003e\u003cmi\u003eo\u003c/mi\u003e\u003cmi\u003eb\u003c/mi\u003e\u003cmi\u003es\u003c/mi\u003e\u003c/mrow\u003e\u003c/msub\u003e\u003cmo stretchy=\"false\"\u003e)\u003c/mo\u003e\u003cmspace width=\"1em\"/\u003e\u003cmtext\u003eor\u003c/mtext\u003e\u003cmspace width=\"1em\"/\u003e\u003cmi\u003eC\u003c/mi\u003e\u003cmo stretchy=\"false\"\u003e(\u003c/mo\u003e\u003cmsub\u003e\u003cmi mathvariant=\"bold\"\u003ex\u003c/mi\u003e\u003cmi\u003en\u003c/mi\u003e\u003c/msub\u003e\u003cmo separator=\"true\"\u003e,\u003c/mo\u003e\u003cmsub\u003e\u003cmi mathvariant=\"bold\"\u003ex\u003c/mi\u003e\u003cmi\u003em\u003c/mi\u003e\u003c/msub\u003e\u003cmo stretchy=\"false\"\u003e)\u003c/mo\u003e\u003cmo\u003e=\u003c/mo\u003e\u003cmi\u003ek\u003c/mi\u003e\u003cmo stretchy=\"false\"\u003e(\u003c/mo\u003e\u003cmsub\u003e\u003cmi mathvariant=\"bold\"\u003ex\u003c/mi\u003e\u003cmi\u003en\u003c/mi\u003e\u003c/msub\u003e\u003cmo separator=\"true\"\u003e,\u003c/mo\u003e\u003cmsub\u003e\u003cmi mathvariant=\"bold\"\u003ex\u003c/mi\u003e\u003cmi\u003em\u003c/mi\u003e\u003c/msub\u003e\u003cmo stretchy=\"false\"\u003e)\u003c/mo\u003e\u003c/mrow\u003e\u003cannotation encoding=\"application/x-tex\"\u003eC_{obs} = f_{cov}(D_{obs}) \\quad \\textrm{or} \\quad C(\\mathbf{x}_n, \\mathbf{x}_m) = k(\\mathbf{x}_n, \\mathbf{x}_m)\u003c/annotation\u003e\u003c/semantics\u003e\u003c/math\u003e\u003c/span\u003e\u003cspan class=\"katex-html\" aria-hidden=\"true\"\u003e\u003cspan class=\"base\"\u003e\u003cspan class=\"strut\" style=\"height:0.8333em;vertical-align:-0.15em;\"\u003e\u003c/span\u003e\u003cspan class=\"mord\"\u003e\u003cspan class=\"mord mathnormal\" style=\"margin-right:0.07153em;\"\u003eC\u003c/span\u003e\u003cspan class=\"msupsub\"\u003e\u003cspan class=\"vlist-t vlist-t2\"\u003e\u003cspan class=\"vlist-r\"\u003e\u003cspan class=\"vlist\" style=\"height:0.3361em;\"\u003e\u003cspan style=\"top:-2.55em;margin-left:-0.0715em;margin-right:0.05em;\"\u003e\u003cspan class=\"pstrut\" style=\"height:2.7em;\"\u003e\u003c/span\u003e\u003cspan class=\"sizing reset-size6 size3 mtight\"\u003e\u003cspan class=\"mord mtight\"\u003e\u003cspan class=\"mord mathnormal mtight\"\u003eo\u003c/span\u003e\u003cspan class=\"mord mathnormal mtight\"\u003eb\u003c/span\u003e\u003cspan class=\"mord mathnormal mtight\"\u003es\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"vlist-s\"\u003e​\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"vlist-r\"\u003e\u003cspan class=\"vlist\" style=\"height:0.15em;\"\u003e\u003cspan\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"mspace\" style=\"margin-right:0.2778em;\"\u003e\u003c/span\u003e\u003cspan class=\"mrel\"\u003e=\u003c/span\u003e\u003cspan class=\"mspace\" style=\"margin-right:0.2778em;\"\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"base\"\u003e\u003cspan class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"\u003e\u003c/span\u003e\u003cspan class=\"mord\"\u003e\u003cspan class=\"mord mathnormal\" style=\"margin-right:0.10764em;\"\u003ef\u003c/span\u003e\u003cspan class=\"msupsub\"\u003e\u003cspan class=\"vlist-t vlist-t2\"\u003e\u003cspan class=\"vlist-r\"\u003e\u003cspan class=\"vlist\" style=\"height:0.1514em;\"\u003e\u003cspan style=\"top:-2.55em;margin-left:-0.1076em;margin-right:0.05em;\"\u003e\u003cspan class=\"pstrut\" style=\"height:2.7em;\"\u003e\u003c/span\u003e\u003cspan class=\"sizing reset-size6 size3 mtight\"\u003e\u003cspan class=\"mord mtight\"\u003e\u003cspan class=\"mord mathnormal mtight\"\u003eco\u003c/span\u003e\u003cspan class=\"mord mathnormal mtight\" style=\"margin-right:0.03588em;\"\u003ev\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"vlist-s\"\u003e​\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"vlist-r\"\u003e\u003cspan class=\"vlist\" style=\"height:0.15em;\"\u003e\u003cspan\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"mopen\"\u003e(\u003c/span\u003e\u003cspan class=\"mord\"\u003e\u003cspan class=\"mord mathnormal\" style=\"margin-right:0.02778em;\"\u003eD\u003c/span\u003e\u003cspan class=\"msupsub\"\u003e\u003cspan class=\"vlist-t vlist-t2\"\u003e\u003cspan class=\"vlist-r\"\u003e\u003cspan class=\"vlist\" style=\"height:0.3361em;\"\u003e\u003cspan style=\"top:-2.55em;margin-left:-0.0278em;margin-right:0.05em;\"\u003e\u003cspan class=\"pstrut\" style=\"height:2.7em;\"\u003e\u003c/span\u003e\u003cspan class=\"sizing reset-size6 size3 mtight\"\u003e\u003cspan class=\"mord mtight\"\u003e\u003cspan class=\"mord mathnormal mtight\"\u003eo\u003c/span\u003e\u003cspan class=\"mord mathnormal mtight\"\u003eb\u003c/span\u003e\u003cspan class=\"mord mathnormal mtight\"\u003es\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"vlist-s\"\u003e​\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"vlist-r\"\u003e\u003cspan class=\"vlist\" style=\"height:0.15em;\"\u003e\u003cspan\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"mclose\"\u003e)\u003c/span\u003e\u003cspan class=\"mspace\" style=\"margin-right:1em;\"\u003e\u003c/span\u003e\u003cspan class=\"mord text\"\u003e\u003cspan class=\"mord textrm\"\u003eor\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"mspace\" style=\"margin-right:1em;\"\u003e\u003c/span\u003e\u003cspan class=\"mord mathnormal\" style=\"margin-right:0.07153em;\"\u003eC\u003c/span\u003e\u003cspan class=\"mopen\"\u003e(\u003c/span\u003e\u003cspan class=\"mord\"\u003e\u003cspan class=\"mord mathbf\"\u003ex\u003c/span\u003e\u003cspan class=\"msupsub\"\u003e\u003cspan class=\"vlist-t vlist-t2\"\u003e\u003cspan class=\"vlist-r\"\u003e\u003cspan class=\"vlist\" style=\"height:0.1514em;\"\u003e\u003cspan style=\"top:-2.55em;margin-left:0em;margin-right:0.05em;\"\u003e\u003cspan class=\"pstrut\" style=\"height:2.7em;\"\u003e\u003c/span\u003e\u003cspan class=\"sizing reset-size6 size3 mtight\"\u003e\u003cspan class=\"mord mathnormal mtight\"\u003en\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"vlist-s\"\u003e​\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"vlist-r\"\u003e\u003cspan class=\"vlist\" style=\"height:0.15em;\"\u003e\u003cspan\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"mpunct\"\u003e,\u003c/span\u003e\u003cspan class=\"mspace\" style=\"margin-right:0.1667em;\"\u003e\u003c/span\u003e\u003cspan class=\"mord\"\u003e\u003cspan class=\"mord mathbf\"\u003ex\u003c/span\u003e\u003cspan class=\"msupsub\"\u003e\u003cspan class=\"vlist-t vlist-t2\"\u003e\u003cspan class=\"vlist-r\"\u003e\u003cspan class=\"vlist\" style=\"height:0.1514em;\"\u003e\u003cspan style=\"top:-2.55em;margin-left:0em;margin-right:0.05em;\"\u003e\u003cspan class=\"pstrut\" style=\"height:2.7em;\"\u003e\u003c/span\u003e\u003cspan class=\"sizing reset-size6 size3 mtight\"\u003e\u003cspan class=\"mord mathnormal mtight\"\u003em\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"vlist-s\"\u003e​\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"vlist-r\"\u003e\u003cspan class=\"vlist\" style=\"height:0.15em;\"\u003e\u003cspan\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"mclose\"\u003e)\u003c/span\u003e\u003cspan class=\"mspace\" style=\"margin-right:0.2778em;\"\u003e\u003c/span\u003e\u003cspan class=\"mrel\"\u003e=\u003c/span\u003e\u003cspan class=\"mspace\" style=\"margin-right:0.2778em;\"\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"base\"\u003e\u003cspan class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"\u003e\u003c/span\u003e\u003cspan class=\"mord mathnormal\" style=\"margin-right:0.03148em;\"\u003ek\u003c/span\u003e\u003cspan class=\"mopen\"\u003e(\u003c/span\u003e\u003cspan class=\"mord\"\u003e\u003cspan class=\"mord mathbf\"\u003ex\u003c/span\u003e\u003cspan class=\"msupsub\"\u003e\u003cspan class=\"vlist-t vlist-t2\"\u003e\u003cspan class=\"vlist-r\"\u003e\u003cspan class=\"vlist\" style=\"height:0.1514em;\"\u003e\u003cspan style=\"top:-2.55em;margin-left:0em;margin-right:0.05em;\"\u003e\u003cspan class=\"pstrut\" style=\"height:2.7em;\"\u003e\u003c/span\u003e\u003cspan class=\"sizing reset-size6 size3 mtight\"\u003e\u003cspan class=\"mord mathnormal mtight\"\u003en\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"vlist-s\"\u003e​\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"vlist-r\"\u003e\u003cspan class=\"vlist\" style=\"height:0.15em;\"\u003e\u003cspan\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"mpunct\"\u003e,\u003c/span\u003e\u003cspan class=\"mspace\" style=\"margin-right:0.1667em;\"\u003e\u003c/span\u003e\u003cspan class=\"mord\"\u003e\u003cspan class=\"mord mathbf\"\u003ex\u003c/span\u003e\u003cspan class=\"msupsub\"\u003e\u003cspan class=\"vlist-t vlist-t2\"\u003e\u003cspan class=\"vlist-r\"\u003e\u003cspan class=\"vlist\" style=\"height:0.1514em;\"\u003e\u003cspan style=\"top:-2.55em;margin-left:0em;margin-right:0.05em;\"\u003e\u003cspan class=\"pstrut\" style=\"height:2.7em;\"\u003e\u003c/span\u003e\u003cspan class=\"sizing reset-size6 size3 mtight\"\u003e\u003cspan class=\"mord mathnormal mtight\"\u003em\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"vlist-s\"\u003e​\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"vlist-r\"\u003e\u003cspan class=\"vlist\" style=\"height:0.15em;\"\u003e\u003cspan\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"mclose\"\u003e)\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e","enumerator":"2","key":"YGVK1dxu8i"},{"type":"code","lang":"","value":"Dist(s1…sn, s1…sn) = Dobs  \t\t# square distance matrix\nCobs = CovF(Dobs)                       # observation covarience, i.e., source-to-source cov","position":{"start":{"line":10,"column":1},"end":{"line":11,"column":1}},"key":"j9evQoL7sN"},{"type":"paragraph","position":{"start":{"line":13,"column":1},"end":{"line":13,"column":1}},"children":[{"type":"strong","position":{"start":{"line":13,"column":1},"end":{"line":13,"column":1}},"children":[{"type":"text","value":"This is what is happening here:","position":{"start":{"line":13,"column":1},"end":{"line":13,"column":1}},"key":"CB0c1m1svz"}],"key":"OfxaDVKfuE"}],"key":"gU8rM70Jvc"},{"type":"code","lang":"python","value":"kern = 1.0 * Matern(length_scale=[80000,80000], length_scale_bounds=(1e3, 1e6),\n                        nu=0.5)\ngp1 = GaussianProcessRegressor(kernel=kern, alpha=std_slope**2, optimizer=None).fit(coords_m, mean_slope)","position":{"start":{"line":15,"column":1},"end":{"line":19,"column":1}},"key":"birDHtZV4X"},{"type":"paragraph","position":{"start":{"line":21,"column":1},"end":{"line":21,"column":1}},"children":[{"type":"strong","position":{"start":{"line":21,"column":1},"end":{"line":21,"column":1}},"children":[{"type":"text","value":"We are selecting a covariance function (the Matern kernel), and then fitting that fuction to our observations on the basis of distance in order to estimate source-to-source cov","position":{"start":{"line":21,"column":1},"end":{"line":21,"column":1}},"key":"MwykIO3ep5"}],"key":"aThikf4CRi"}],"key":"fbdoms7WZg"},{"type":"paragraph","position":{"start":{"line":23,"column":1},"end":{"line":23,"column":1}},"children":[{"type":"text","value":"Define p1…pn prediction nodes; calculate distances and Cpred (covariance of predictions):","position":{"start":{"line":23,"column":1},"end":{"line":23,"column":1}},"key":"Hd6AQIwTqu"}],"key":"bFyCiVfxRN"},{"type":"math","value":"D(t_1 ... t_n, t_1 ... t_n) = D_{pred}","position":{"start":{"line":25,"column":1},"end":{"line":25,"column":1}},"html":"\u003cspan class=\"katex-display\"\u003e\u003cspan class=\"katex\"\u003e\u003cspan class=\"katex-mathml\"\u003e\u003cmath xmlns=\"http://www.w3.org/1998/Math/MathML\" display=\"block\"\u003e\u003csemantics\u003e\u003cmrow\u003e\u003cmi\u003eD\u003c/mi\u003e\u003cmo stretchy=\"false\"\u003e(\u003c/mo\u003e\u003cmsub\u003e\u003cmi\u003et\u003c/mi\u003e\u003cmn\u003e1\u003c/mn\u003e\u003c/msub\u003e\u003cmi mathvariant=\"normal\"\u003e.\u003c/mi\u003e\u003cmi mathvariant=\"normal\"\u003e.\u003c/mi\u003e\u003cmi mathvariant=\"normal\"\u003e.\u003c/mi\u003e\u003cmsub\u003e\u003cmi\u003et\u003c/mi\u003e\u003cmi\u003en\u003c/mi\u003e\u003c/msub\u003e\u003cmo separator=\"true\"\u003e,\u003c/mo\u003e\u003cmsub\u003e\u003cmi\u003et\u003c/mi\u003e\u003cmn\u003e1\u003c/mn\u003e\u003c/msub\u003e\u003cmi mathvariant=\"normal\"\u003e.\u003c/mi\u003e\u003cmi mathvariant=\"normal\"\u003e.\u003c/mi\u003e\u003cmi mathvariant=\"normal\"\u003e.\u003c/mi\u003e\u003cmsub\u003e\u003cmi\u003et\u003c/mi\u003e\u003cmi\u003en\u003c/mi\u003e\u003c/msub\u003e\u003cmo stretchy=\"false\"\u003e)\u003c/mo\u003e\u003cmo\u003e=\u003c/mo\u003e\u003cmsub\u003e\u003cmi\u003eD\u003c/mi\u003e\u003cmrow\u003e\u003cmi\u003ep\u003c/mi\u003e\u003cmi\u003er\u003c/mi\u003e\u003cmi\u003ee\u003c/mi\u003e\u003cmi\u003ed\u003c/mi\u003e\u003c/mrow\u003e\u003c/msub\u003e\u003c/mrow\u003e\u003cannotation encoding=\"application/x-tex\"\u003eD(t_1 ... t_n, t_1 ... t_n) = D_{pred}\u003c/annotation\u003e\u003c/semantics\u003e\u003c/math\u003e\u003c/span\u003e\u003cspan class=\"katex-html\" aria-hidden=\"true\"\u003e\u003cspan class=\"base\"\u003e\u003cspan class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"\u003e\u003c/span\u003e\u003cspan class=\"mord mathnormal\" style=\"margin-right:0.02778em;\"\u003eD\u003c/span\u003e\u003cspan class=\"mopen\"\u003e(\u003c/span\u003e\u003cspan class=\"mord\"\u003e\u003cspan class=\"mord mathnormal\"\u003et\u003c/span\u003e\u003cspan class=\"msupsub\"\u003e\u003cspan class=\"vlist-t vlist-t2\"\u003e\u003cspan class=\"vlist-r\"\u003e\u003cspan class=\"vlist\" style=\"height:0.3011em;\"\u003e\u003cspan style=\"top:-2.55em;margin-left:0em;margin-right:0.05em;\"\u003e\u003cspan class=\"pstrut\" style=\"height:2.7em;\"\u003e\u003c/span\u003e\u003cspan class=\"sizing reset-size6 size3 mtight\"\u003e\u003cspan class=\"mord mtight\"\u003e1\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"vlist-s\"\u003e​\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"vlist-r\"\u003e\u003cspan class=\"vlist\" style=\"height:0.15em;\"\u003e\u003cspan\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"mord\"\u003e...\u003c/span\u003e\u003cspan class=\"mord\"\u003e\u003cspan class=\"mord mathnormal\"\u003et\u003c/span\u003e\u003cspan class=\"msupsub\"\u003e\u003cspan class=\"vlist-t vlist-t2\"\u003e\u003cspan class=\"vlist-r\"\u003e\u003cspan class=\"vlist\" style=\"height:0.1514em;\"\u003e\u003cspan style=\"top:-2.55em;margin-left:0em;margin-right:0.05em;\"\u003e\u003cspan class=\"pstrut\" style=\"height:2.7em;\"\u003e\u003c/span\u003e\u003cspan class=\"sizing reset-size6 size3 mtight\"\u003e\u003cspan class=\"mord mathnormal mtight\"\u003en\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"vlist-s\"\u003e​\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"vlist-r\"\u003e\u003cspan class=\"vlist\" style=\"height:0.15em;\"\u003e\u003cspan\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"mpunct\"\u003e,\u003c/span\u003e\u003cspan class=\"mspace\" style=\"margin-right:0.1667em;\"\u003e\u003c/span\u003e\u003cspan class=\"mord\"\u003e\u003cspan class=\"mord mathnormal\"\u003et\u003c/span\u003e\u003cspan class=\"msupsub\"\u003e\u003cspan class=\"vlist-t vlist-t2\"\u003e\u003cspan class=\"vlist-r\"\u003e\u003cspan class=\"vlist\" style=\"height:0.3011em;\"\u003e\u003cspan style=\"top:-2.55em;margin-left:0em;margin-right:0.05em;\"\u003e\u003cspan class=\"pstrut\" style=\"height:2.7em;\"\u003e\u003c/span\u003e\u003cspan class=\"sizing reset-size6 size3 mtight\"\u003e\u003cspan class=\"mord mtight\"\u003e1\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"vlist-s\"\u003e​\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"vlist-r\"\u003e\u003cspan class=\"vlist\" style=\"height:0.15em;\"\u003e\u003cspan\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"mord\"\u003e...\u003c/span\u003e\u003cspan class=\"mord\"\u003e\u003cspan class=\"mord mathnormal\"\u003et\u003c/span\u003e\u003cspan class=\"msupsub\"\u003e\u003cspan class=\"vlist-t vlist-t2\"\u003e\u003cspan class=\"vlist-r\"\u003e\u003cspan class=\"vlist\" style=\"height:0.1514em;\"\u003e\u003cspan style=\"top:-2.55em;margin-left:0em;margin-right:0.05em;\"\u003e\u003cspan class=\"pstrut\" style=\"height:2.7em;\"\u003e\u003c/span\u003e\u003cspan class=\"sizing reset-size6 size3 mtight\"\u003e\u003cspan class=\"mord mathnormal mtight\"\u003en\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"vlist-s\"\u003e​\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"vlist-r\"\u003e\u003cspan class=\"vlist\" style=\"height:0.15em;\"\u003e\u003cspan\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"mclose\"\u003e)\u003c/span\u003e\u003cspan class=\"mspace\" style=\"margin-right:0.2778em;\"\u003e\u003c/span\u003e\u003cspan class=\"mrel\"\u003e=\u003c/span\u003e\u003cspan class=\"mspace\" style=\"margin-right:0.2778em;\"\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"base\"\u003e\u003cspan class=\"strut\" style=\"height:0.9694em;vertical-align:-0.2861em;\"\u003e\u003c/span\u003e\u003cspan class=\"mord\"\u003e\u003cspan class=\"mord mathnormal\" style=\"margin-right:0.02778em;\"\u003eD\u003c/span\u003e\u003cspan class=\"msupsub\"\u003e\u003cspan class=\"vlist-t vlist-t2\"\u003e\u003cspan class=\"vlist-r\"\u003e\u003cspan class=\"vlist\" style=\"height:0.3361em;\"\u003e\u003cspan style=\"top:-2.55em;margin-left:-0.0278em;margin-right:0.05em;\"\u003e\u003cspan class=\"pstrut\" style=\"height:2.7em;\"\u003e\u003c/span\u003e\u003cspan class=\"sizing reset-size6 size3 mtight\"\u003e\u003cspan class=\"mord mtight\"\u003e\u003cspan class=\"mord mathnormal mtight\"\u003ep\u003c/span\u003e\u003cspan class=\"mord mathnormal mtight\"\u003ere\u003c/span\u003e\u003cspan class=\"mord mathnormal mtight\"\u003ed\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"vlist-s\"\u003e​\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"vlist-r\"\u003e\u003cspan class=\"vlist\" style=\"height:0.2861em;\"\u003e\u003cspan\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e","enumerator":"3","key":"ExtWbIJ2Yf"},{"type":"math","value":"C_{pred} = f_{cov}(D_{pred})","position":{"start":{"line":26,"column":1},"end":{"line":26,"column":1}},"html":"\u003cspan class=\"katex-display\"\u003e\u003cspan class=\"katex\"\u003e\u003cspan class=\"katex-mathml\"\u003e\u003cmath xmlns=\"http://www.w3.org/1998/Math/MathML\" display=\"block\"\u003e\u003csemantics\u003e\u003cmrow\u003e\u003cmsub\u003e\u003cmi\u003eC\u003c/mi\u003e\u003cmrow\u003e\u003cmi\u003ep\u003c/mi\u003e\u003cmi\u003er\u003c/mi\u003e\u003cmi\u003ee\u003c/mi\u003e\u003cmi\u003ed\u003c/mi\u003e\u003c/mrow\u003e\u003c/msub\u003e\u003cmo\u003e=\u003c/mo\u003e\u003cmsub\u003e\u003cmi\u003ef\u003c/mi\u003e\u003cmrow\u003e\u003cmi\u003ec\u003c/mi\u003e\u003cmi\u003eo\u003c/mi\u003e\u003cmi\u003ev\u003c/mi\u003e\u003c/mrow\u003e\u003c/msub\u003e\u003cmo stretchy=\"false\"\u003e(\u003c/mo\u003e\u003cmsub\u003e\u003cmi\u003eD\u003c/mi\u003e\u003cmrow\u003e\u003cmi\u003ep\u003c/mi\u003e\u003cmi\u003er\u003c/mi\u003e\u003cmi\u003ee\u003c/mi\u003e\u003cmi\u003ed\u003c/mi\u003e\u003c/mrow\u003e\u003c/msub\u003e\u003cmo stretchy=\"false\"\u003e)\u003c/mo\u003e\u003c/mrow\u003e\u003cannotation encoding=\"application/x-tex\"\u003eC_{pred} = f_{cov}(D_{pred})\u003c/annotation\u003e\u003c/semantics\u003e\u003c/math\u003e\u003c/span\u003e\u003cspan class=\"katex-html\" aria-hidden=\"true\"\u003e\u003cspan class=\"base\"\u003e\u003cspan class=\"strut\" style=\"height:0.9694em;vertical-align:-0.2861em;\"\u003e\u003c/span\u003e\u003cspan class=\"mord\"\u003e\u003cspan class=\"mord mathnormal\" style=\"margin-right:0.07153em;\"\u003eC\u003c/span\u003e\u003cspan class=\"msupsub\"\u003e\u003cspan class=\"vlist-t vlist-t2\"\u003e\u003cspan class=\"vlist-r\"\u003e\u003cspan class=\"vlist\" style=\"height:0.3361em;\"\u003e\u003cspan style=\"top:-2.55em;margin-left:-0.0715em;margin-right:0.05em;\"\u003e\u003cspan class=\"pstrut\" style=\"height:2.7em;\"\u003e\u003c/span\u003e\u003cspan class=\"sizing reset-size6 size3 mtight\"\u003e\u003cspan class=\"mord mtight\"\u003e\u003cspan class=\"mord mathnormal mtight\"\u003ep\u003c/span\u003e\u003cspan class=\"mord mathnormal mtight\"\u003ere\u003c/span\u003e\u003cspan class=\"mord mathnormal mtight\"\u003ed\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"vlist-s\"\u003e​\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"vlist-r\"\u003e\u003cspan class=\"vlist\" style=\"height:0.2861em;\"\u003e\u003cspan\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"mspace\" style=\"margin-right:0.2778em;\"\u003e\u003c/span\u003e\u003cspan class=\"mrel\"\u003e=\u003c/span\u003e\u003cspan class=\"mspace\" style=\"margin-right:0.2778em;\"\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"base\"\u003e\u003cspan class=\"strut\" style=\"height:1.0361em;vertical-align:-0.2861em;\"\u003e\u003c/span\u003e\u003cspan class=\"mord\"\u003e\u003cspan class=\"mord mathnormal\" style=\"margin-right:0.10764em;\"\u003ef\u003c/span\u003e\u003cspan class=\"msupsub\"\u003e\u003cspan class=\"vlist-t vlist-t2\"\u003e\u003cspan class=\"vlist-r\"\u003e\u003cspan class=\"vlist\" style=\"height:0.1514em;\"\u003e\u003cspan style=\"top:-2.55em;margin-left:-0.1076em;margin-right:0.05em;\"\u003e\u003cspan class=\"pstrut\" style=\"height:2.7em;\"\u003e\u003c/span\u003e\u003cspan class=\"sizing reset-size6 size3 mtight\"\u003e\u003cspan class=\"mord mtight\"\u003e\u003cspan class=\"mord mathnormal mtight\"\u003eco\u003c/span\u003e\u003cspan class=\"mord mathnormal mtight\" style=\"margin-right:0.03588em;\"\u003ev\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"vlist-s\"\u003e​\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"vlist-r\"\u003e\u003cspan class=\"vlist\" style=\"height:0.15em;\"\u003e\u003cspan\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"mopen\"\u003e(\u003c/span\u003e\u003cspan class=\"mord\"\u003e\u003cspan class=\"mord mathnormal\" style=\"margin-right:0.02778em;\"\u003eD\u003c/span\u003e\u003cspan class=\"msupsub\"\u003e\u003cspan class=\"vlist-t vlist-t2\"\u003e\u003cspan class=\"vlist-r\"\u003e\u003cspan class=\"vlist\" style=\"height:0.3361em;\"\u003e\u003cspan style=\"top:-2.55em;margin-left:-0.0278em;margin-right:0.05em;\"\u003e\u003cspan class=\"pstrut\" style=\"height:2.7em;\"\u003e\u003c/span\u003e\u003cspan class=\"sizing reset-size6 size3 mtight\"\u003e\u003cspan class=\"mord mtight\"\u003e\u003cspan class=\"mord mathnormal mtight\"\u003ep\u003c/span\u003e\u003cspan class=\"mord mathnormal mtight\"\u003ere\u003c/span\u003e\u003cspan class=\"mord mathnormal mtight\"\u003ed\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"vlist-s\"\u003e​\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"vlist-r\"\u003e\u003cspan class=\"vlist\" style=\"height:0.2861em;\"\u003e\u003cspan\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"mclose\"\u003e)\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e","enumerator":"4","key":"B9t2dSfEPL"},{"type":"code","lang":"","value":"Dist(t1…tn, t1…tn) = Dpred  \t\t# square distance matrix\nCpred = CovF(Dpred)                     # target covarience, i.e., target-to-target cov","position":{"start":{"line":28,"column":1},"end":{"line":29,"column":1}},"key":"QRrgV5DsbS"},{"type":"paragraph","position":{"start":{"line":31,"column":1},"end":{"line":31,"column":1}},"children":[{"type":"text","value":"Note that for above, we don’t actually know p1…pn ","position":{"start":{"line":31,"column":1},"end":{"line":31,"column":1}},"key":"mmt2MP8l9h"},{"type":"emphasis","position":{"start":{"line":31,"column":1},"end":{"line":31,"column":1}},"children":[{"type":"text","value":"but we do know the locations","position":{"start":{"line":31,"column":1},"end":{"line":31,"column":1}},"key":"vzf0uOq9uw"}],"key":"HmpfWUpO9l"},{"type":"text","value":" of p1…pn, and hence we can calculate their distances, and given that our covariance function is a function of distances, we can ","position":{"start":{"line":31,"column":1},"end":{"line":31,"column":1}},"key":"AoherKjsQN"},{"type":"strong","position":{"start":{"line":31,"column":1},"end":{"line":31,"column":1}},"children":[{"type":"text","value":"model","position":{"start":{"line":31,"column":1},"end":{"line":31,"column":1}},"key":"t5K8ytFiTa"}],"key":"E1e3wNmpnh"},{"type":"text","value":" the covariance of the predictions p1…pn as a function of distance.","position":{"start":{"line":31,"column":1},"end":{"line":31,"column":1}},"key":"vL6qm12z1z"}],"key":"jsFjFmkAmz"},{"type":"paragraph","position":{"start":{"line":33,"column":1},"end":{"line":33,"column":1}},"children":[{"type":"text","value":"As mentioned above, kriging is equivalent to spatial least squares regression. Hence, we can retrieve our best estimate at locations p1…pn though least square regression—see below for useful equivalencies:","position":{"start":{"line":33,"column":1},"end":{"line":33,"column":1}},"key":"Hb6dEqM2X5"}],"key":"Gnb59W7OdL"},{"type":"code","lang":"","value":"Lstsq( s1…sn, t1…tn) == Lstsq( Cobs, Cobs_pred) == kriging_wieghts","position":{"start":{"line":35,"column":1},"end":{"line":35,"column":1}},"key":"qcCWLEC7DY"},{"type":"paragraph","position":{"start":{"line":37,"column":1},"end":{"line":37,"column":1}},"children":[{"type":"text","value":"…where ","position":{"start":{"line":37,"column":1},"end":{"line":37,"column":1}},"key":"NhNvwD2klA"},{"type":"inlineCode","value":"Cobs_pred","position":{"start":{"line":37,"column":1},"end":{"line":37,"column":1}},"key":"ith9WM3uM0"},{"type":"text","value":" is the covariance between our observations and predictions, i.e., our target-to-source ","position":{"start":{"line":37,"column":1},"end":{"line":37,"column":1}},"key":"h3AvtaGaAc"},{"type":"inlineCode","value":"cov","position":{"start":{"line":37,"column":1},"end":{"line":37,"column":1}},"key":"yXiR4Lo1hO"},{"type":"text","value":". Of course, we don’t know our predictions yet; all we have are our observations, and our observation covariances. However, we have defined a covariance function, ","position":{"start":{"line":37,"column":1},"end":{"line":37,"column":1}},"key":"HrKXthrXNT"},{"type":"emphasis","position":{"start":{"line":37,"column":1},"end":{"line":37,"column":1}},"children":[{"type":"strong","position":{"start":{"line":37,"column":1},"end":{"line":37,"column":1}},"children":[{"type":"text","value":"based","position":{"start":{"line":37,"column":1},"end":{"line":37,"column":1}},"key":"a3VBKYvbAS"}],"key":"yBhxAKhMaz"}],"key":"oY3eKEhaDH"},{"type":"text","value":" on our observation covariances, that provides covariance as a function of distance; hence above we defined our prediction to prediction covariance.","position":{"start":{"line":37,"column":1},"end":{"line":37,"column":1}},"key":"yKrcODFHxH"}],"key":"xe4ArQFjZU"},{"type":"paragraph","position":{"start":{"line":39,"column":1},"end":{"line":39,"column":1}},"children":[{"type":"strong","position":{"start":{"line":39,"column":1},"end":{"line":39,"column":1}},"children":[{"type":"text","value":"The kriging weights are used to weight a combination of our observations at each prediction location-- with the weights being determined by distance and the covariance structure. Our ‘mean’ prediction and target-to-target cov (and the steps above and below to retrieve them), happen at this call:","position":{"start":{"line":39,"column":1},"end":{"line":39,"column":1}},"key":"nXOFPaJQrV"}],"key":"e870zEI0jS"}],"key":"HJ1v9Y8pzk"},{"type":"code","lang":"python","value":"y_mean, y_cov = gp1.predict(target_c, return_cov=True)","position":{"start":{"line":41,"column":1},"end":{"line":43,"column":1}},"key":"kGJLdv8mrg"},{"type":"paragraph","position":{"start":{"line":45,"column":1},"end":{"line":45,"column":1}},"children":[{"type":"strong","position":{"start":{"line":45,"column":1},"end":{"line":45,"column":1}},"children":[{"type":"text","value":"(Note, this call is also implicitly calculating the source to target covariance!)","position":{"start":{"line":45,"column":1},"end":{"line":45,"column":1}},"key":"y4y2ub4q2E"}],"key":"uzAVnIrPJq"}],"key":"sSpxCaP8kw"},{"type":"paragraph","position":{"start":{"line":47,"column":1},"end":{"line":47,"column":1}},"children":[{"type":"text","value":"Using the same assumption that covariance can be specified as a function of distance, we can get an estimate of covariance between our observations and prediction locations:","position":{"start":{"line":47,"column":1},"end":{"line":47,"column":1}},"key":"MCdvHGsx7E"}],"key":"u2k6n88viu"},{"type":"code","lang":"","value":"Cobs_pred = CovF(Dist(s1…sn, t1…tn)","position":{"start":{"line":49,"column":1},"end":{"line":49,"column":1}},"key":"CIF3TTJ63w"},{"type":"paragraph","position":{"start":{"line":51,"column":1},"end":{"line":51,"column":1}},"children":[{"type":"text","value":"…now we obtain the kriging weights by:","position":{"start":{"line":51,"column":1},"end":{"line":51,"column":1}},"key":"eGRk7tIIbl"}],"key":"aqWxAIVQZw"},{"type":"code","lang":"","value":"kriging_wieghts = dot(inv(Cobs), Cobs_pred)","position":{"start":{"line":53,"column":1},"end":{"line":53,"column":1}},"key":"iWcmPSc0xL"},{"type":"paragraph","position":{"start":{"line":55,"column":1},"end":{"line":55,"column":1}},"children":[{"type":"text","value":"Above we see the key computational constraint for kriging; we need to be able to invert an N by N observation covariance matrix.","position":{"start":{"line":55,"column":1},"end":{"line":55,"column":1}},"key":"jNO7zUmAVM"}],"key":"q7NtBeHosV"},{"type":"paragraph","position":{"start":{"line":57,"column":1},"end":{"line":57,"column":1}},"children":[{"type":"text","value":"Given that the regression/kriging weights are identical for both the observations and their covariances, we now have enough information to make a kriging/Lstsq’s prediction of t1…tn:","position":{"start":{"line":57,"column":1},"end":{"line":57,"column":1}},"key":"jLCkGeTVBm"}],"key":"TzgM1woWtm"},{"type":"code","lang":"","value":"t1…tn =  dot(kriging_wieghts.T, s1…sn)","position":{"start":{"line":59,"column":1},"end":{"line":59,"column":1}},"key":"WYXbutex7O"},{"type":"paragraph","position":{"start":{"line":61,"column":1},"end":{"line":61,"column":1}},"children":[{"type":"text","value":"We can calculate partial correlation/covariance, which is equivalent to the covariance of the residual error from kriging/regression. We get conditional covariance with:","position":{"start":{"line":61,"column":1},"end":{"line":61,"column":1}},"key":"g5DPu3GSmy"}],"key":"wdqtZGWzhm"},{"type":"code","lang":"","value":"Cpred – dot(dot(Cobs_pred.T, inv(Cobs)), Cobs_pred)","position":{"start":{"line":63,"column":1},"end":{"line":63,"column":1}},"key":"M90ig2E0ED"},{"type":"paragraph","position":{"start":{"line":65,"column":1},"end":{"line":65,"column":1}},"children":[{"type":"text","value":"The above gives the estimation error covariance, and allows for simulation, i.e., ","position":{"start":{"line":65,"column":1},"end":{"line":65,"column":1}},"key":"aNOhhzDACW"},{"type":"emphasis","position":{"start":{"line":65,"column":1},"end":{"line":65,"column":1}},"children":[{"type":"text","value":"prediction","position":{"start":{"line":65,"column":1},"end":{"line":65,"column":1}},"key":"AYXVhO9Ijb"}],"key":"GIRrkZ12mI"},{"type":"text","value":". Specifically, we can preform simulation via Cholesky decomposition* using the derived mean target predictions, and the target-to-target covariance:","position":{"start":{"line":65,"column":1},"end":{"line":65,"column":1}},"key":"XXK5ZVh0OY"}],"key":"iVaFHL38GE"},{"type":"paragraph","position":{"start":{"line":67,"column":1},"end":{"line":67,"column":1}},"children":[{"type":"text","value":"(from ","position":{"start":{"line":67,"column":1},"end":{"line":67,"column":1}},"key":"WUafe1iRfj"},{"type":"link","url":"https://github.com/scikit-learn/scikit-learn/blob/main/sklearn/gaussian_process/_gpr.py","position":{"start":{"line":67,"column":1},"end":{"line":67,"column":1}},"children":[{"type":"text","value":"sklearn gaussian process module","position":{"start":{"line":67,"column":1},"end":{"line":67,"column":1}},"key":"EOzrwAQ9dL"}],"urlSource":"https://github.com/scikit-learn/scikit-learn/blob/main/sklearn/gaussian_process/_gpr.py","data":{"kind":"file","org":"scikit-learn","repo":"scikit-learn","reference":"main","file":"sklearn/gaussian_process/_gpr.py","raw":"https://raw.githubusercontent.com/scikit-learn/scikit-learn/main/sklearn/gaussian_process/_gpr.py"},"internal":false,"protocol":"github","key":"dWyowaXIwx"},{"type":"text","value":"):","position":{"start":{"line":67,"column":1},"end":{"line":67,"column":1}},"key":"fT6c1gd1eT"}],"key":"GqxQTJSfSe"},{"type":"code","lang":"python","value":"    def sample_y(self, X, n_samples=1, random_state=0):\n        \"\"\"Draw samples from Gaussian process and evaluate at X.\n\n        Parameters\n        ----------\n        X : array-like of shape (n_samples_X, n_features) or list of object\n            Query points where the GP is evaluated.\n\n        n_samples : int, default=1\n            Number of samples drawn from the Gaussian process per query point.\n\n        random_state : int, RandomState instance or None, default=0\n            Determines random number generation to randomly draw samples.\n            Pass an int for reproducible results across multiple function\n            calls.\n            See :term:`Glossary \u003crandom_state\u003e`.\n\n        Returns\n        -------\n        y_samples : ndarray of shape (n_samples_X, n_samples), or \\\n            (n_samples_X, n_targets, n_samples)\n            Values of n_samples samples drawn from Gaussian process and\n            evaluated at query points.\n        \"\"\"\n        rng = check_random_state(random_state)\n\n        y_mean, y_cov = self.predict(X, return_cov=True)\n        if y_mean.ndim == 1:\n            y_samples = rng.multivariate_normal(y_mean, y_cov, n_samples).T\n        else:\n            y_samples = [\n                rng.multivariate_normal(\n                    y_mean[:, target], y_cov[..., target], n_samples\n                ).T[:, np.newaxis]\n                for target in range(y_mean.shape[1])\n            ]\n            y_samples = np.hstack(y_samples)\n        return y_samples","position":{"start":{"line":68,"column":1},"end":{"line":107,"column":1}},"key":"AToMjy1mga"},{"type":"paragraph","position":{"start":{"line":109,"column":1},"end":{"line":109,"column":1}},"children":[{"type":"text","value":"Several things are apparent for the kriging description above, that highlight both the strengths and weakness of the approach. First and foremost, ","position":{"start":{"line":109,"column":1},"end":{"line":109,"column":1}},"key":"ypYYlQtBWr"},{"type":"emphasis","position":{"start":{"line":109,"column":1},"end":{"line":109,"column":1}},"children":[{"type":"text","value":"the approach is completely dependent on specification of a proper covariance function","position":{"start":{"line":109,"column":1},"end":{"line":109,"column":1}},"key":"RSWGmAfH22"}],"key":"VrWi9prbcq"},{"type":"text","value":". ","position":{"start":{"line":109,"column":1},"end":{"line":109,"column":1}},"key":"RrQiidCbBu"},{"type":"strong","position":{"start":{"line":109,"column":1},"end":{"line":109,"column":1}},"children":[{"type":"text","value":"The covariance function must be invertible; that is it must be positive definite (Genton, 2002)","position":{"start":{"line":109,"column":1},"end":{"line":109,"column":1}},"key":"Nzv6CHXehL"}],"key":"ckNJY4alnw"},{"type":"text","value":", and the machine that runs the computation must be capable of inverting a N by N matrix. In practice, the N by N inversion can be relaxed if only the ‘best’ prediction is desired (since it can be derived via lstsq calculation); ","position":{"start":{"line":109,"column":1},"end":{"line":109,"column":1}},"key":"H5n9bMiaPv"},{"type":"emphasis","position":{"start":{"line":109,"column":1},"end":{"line":109,"column":1}},"children":[{"type":"text","value":"however, simulation and error estimation requires inversion of an N by N matrix.","position":{"start":{"line":109,"column":1},"end":{"line":109,"column":1}},"key":"mWvZNyK0OR"}],"key":"ax29jWyc6H"},{"type":"text","value":" ","position":{"start":{"line":109,"column":1},"end":{"line":109,"column":1}},"key":"g7vg54nPn3"},{"type":"strong","position":{"start":{"line":109,"column":1},"end":{"line":109,"column":1}},"children":[{"type":"text","value":"In practice, empirical covariance almost always provides a non-invertible (not positive definite) gram matrix (","position":{"start":{"line":109,"column":1},"end":{"line":109,"column":1}},"key":"kwSvUNk2Eh"},{"type":"cite","identifier":"10.1080/00401706.1993.10485354","label":"Handcock_1993","kind":"narrative","position":{"start":{"line":109,"column":761},"end":{"line":109,"column":792}},"children":[{"type":"text","value":"Handcock \u0026 Stein (1993)","key":"eHAFkSnA3o"}],"enumerator":"11","key":"fhU8GRPb2K"},{"type":"text","value":"); further, a model of covariance is needed to estimate source to target and target to target covariance—so estimation of a covariance function, either via a variogram or by other methods, is always required for geostatistical interpolation and simulation.","position":{"start":{"line":109,"column":1},"end":{"line":109,"column":1}},"key":"bZk2ZDb92D"}],"key":"sZcXe7uUg7"},{"type":"text","value":" The error estimation that kriging gives per prediction is error estimation on the assumption that modeled covariance structure is true! Kriging has been characterized as the Best Unbiased Linear Predictor (BULP)… which it is, for a given covariance function. Swapping covariance functions gives different and competing BLUPs, which then need to be evaluated via inter-model comparison (","position":{"start":{"line":109,"column":1},"end":{"line":109,"column":1}},"key":"l0k3zh7dgh"},{"type":"cite","url":"https://doi.org/10.1162/neco.1992.4.3.415","position":{"start":{"line":109,"column":1},"end":{"line":109,"column":1}},"children":[{"type":"text","value":"MacKay (1992)","key":"KvOqFPv1oU"}],"kind":"narrative","label":"MacKay_1992","identifier":"https://doi.org/10.1162/neco.1992.4.3.415","enumerator":"12","key":"JPNuQ9GJXg"},{"type":"text","value":"). In short, the kriging error and uncertainty estimation is not the absolute error estimate for the surface, and probability estimation of a prediction must be obtained with other models to give realistic confidence bounds.","position":{"start":{"line":109,"column":1},"end":{"line":109,"column":1}},"key":"EoIdlJSphn"}],"key":"XPCtrzCr65"},{"type":"paragraph","position":{"start":{"line":111,"column":1},"end":{"line":111,"column":1}},"children":[{"type":"text","value":"*Traditional kriging involves estimation of a variogram, however, the variogram is simply a way of producing a covariance function that produces a positive definite gram matrix of covariances (Genton, 2002). Since we know that our covariance function produces a positive definite gram matrix of covariances, we use cholesky because ","position":{"start":{"line":111,"column":1},"end":{"line":111,"column":1}},"key":"wXxJ5kWrjU"},{"type":"link","url":"https://numpy.org/doc/2.2/reference/random/generated/numpy.random.Generator.multivariate_normal.html#numpy.random.Generator.multivariate_normal","position":{"start":{"line":111,"column":1},"end":{"line":111,"column":1}},"children":[{"type":"text","value":"it is faster than SVD or eigen decomposition","position":{"start":{"line":111,"column":1},"end":{"line":111,"column":1}},"key":"H7wNPdfVI8"}],"urlSource":"https://numpy.org/doc/2.2/reference/random/generated/numpy.random.Generator.multivariate_normal.html#numpy.random.Generator.multivariate_normal","key":"hth1KOWzMt"},{"type":"text","value":".","position":{"start":{"line":111,"column":1},"end":{"line":111,"column":1}},"key":"nScvx8Zw1v"}],"key":"mooOsd5Hvx"}],"key":"rjctTY6jpy"},{"type":"block","kind":"notebook-content","children":[{"type":"heading","depth":3,"position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"Why Prediction?","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"HGPCfMxuo2"}],"identifier":"why-prediction","label":"Why Prediction?","html_id":"why-prediction","implicit":true,"key":"SkMDTbbrAI"},{"type":"paragraph","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"children":[{"type":"text","value":"Slope is an important variable for glaciologists, but it also doesn’t vary much on the icesheet-- it goes from about 2 degrees at the edge where it’s ‘steep’, before gradually dropping down to 1 in the interior and eventually 0 at the drainage boundary. However, things change when the surface is crevassed; cracks present a range of surface heights and angles, and generally those retrievals are ","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"key":"hBFFMWkUNQ"},{"type":"strong","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"children":[{"type":"text","value":"not","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"key":"Rp0643HWkE"}],"key":"oRGKBtW6Hv"},{"type":"text","value":" flat.","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"key":"Lf9kgp4JiH"}],"key":"vEX0Hsvc3v"},{"type":"paragraph","position":{"start":{"line":5,"column":1},"end":{"line":5,"column":1}},"children":[{"type":"text","value":"So if we are looking for crevasses, and we know that the ‘background’ slope of the ice sheet is 2 degrees of slope or lower, it would be nice to know when that slope is exceeded. Unfortunately, our mean prediction of surface slope is smoothing the variation in slope retrievals-- if we have a distribution of slope values, the best prediction will trend towards the mean, resulting in surface that suppresses variation we know is present.","position":{"start":{"line":5,"column":1},"end":{"line":5,"column":1}},"key":"kd3UcGRxnd"}],"key":"LIUWKctxuD"},{"type":"paragraph","position":{"start":{"line":7,"column":1},"end":{"line":7,"column":1}},"children":[{"type":"text","value":"What we can do though, is simulate possible surfaces, and count how often we exceed 2 degrees of slope for a given location:","position":{"start":{"line":7,"column":1},"end":{"line":7,"column":1}},"key":"wT2xr1fGeW"}],"key":"WivXOJFuPN"}],"key":"g9iqpd3OjM"},{"type":"block","kind":"notebook-code","children":[{"type":"code","lang":"python","executable":true,"value":"%%time\nrealizations = rng.multivariate_normal(y_mean, y_cov, size=100, method='cholesky')","key":"mFFUTugzjF"},{"type":"output","id":"Q0dE4tCUj1r-3NSfi-eXa","data":[{"name":"stdout","output_type":"stream","text":"CPU times: user 8.21 s, sys: 313 ms, total: 8.52 s\nWall time: 1.12 s\n"}],"key":"jP6V7VhbUm"}],"key":"yHtB9fXLCi"},{"type":"block","kind":"notebook-code","children":[{"type":"code","lang":"python","executable":true,"value":"results1 = np.ones(len(kcoords)) *np.nan\nresults1[Zidx] =  realizations[5]\nshow_res1 = results1.reshape((x1.shape))\nplt.imshow(np.flipud(show_res1), vmin=2)\nplt.colorbar()\nplt.show()","key":"VwU5GtJMRn"},{"type":"output","id":"0a5qZ8XNe_dajSuq9_Oi1","data":[{"output_type":"display_data","metadata":{},"data":{"image/png":{"content_type":"image/png","hash":"16054cd9d3452404ea4c0d28a5ebc991","path":"/build/16054cd9d3452404ea4c0d28a5ebc991.png"},"text/plain":{"content":"\u003cFigure size 640x480 with 2 Axes\u003e","content_type":"text/plain"}}}],"key":"kolWbaaoAc"}],"key":"wgD4MUWeUf"},{"type":"block","kind":"notebook-code","children":[{"type":"code","lang":"python","executable":true,"value":"results1 = np.ones(len(kcoords)) *np.nan\nresults1[Zidx] =  realizations[9]\nshow_res1 = results1.reshape((x1.shape))\nplt.imshow(np.flipud(show_res1), vmin=2)\nplt.colorbar()\nplt.show()","key":"Hnk5r4jl9d"},{"type":"output","id":"6K8j64ofh3Rhr6mSsZF61","data":[{"output_type":"display_data","metadata":{},"data":{"image/png":{"content_type":"image/png","hash":"5613a94aefe71a55d1b42b8e85bc75d9","path":"/build/5613a94aefe71a55d1b42b8e85bc75d9.png"},"text/plain":{"content":"\u003cFigure size 640x480 with 2 Axes\u003e","content_type":"text/plain"}}}],"key":"fAwnhNYJCE"}],"key":"oav8SejSai"},{"type":"block","kind":"notebook-code","children":[{"type":"code","lang":"python","executable":true,"value":"occurance = np.zeros(5600, dtype=np.int64)\nfor i in realizations:\n    occurance += i \u003e 3","key":"cWVwRZj3Gu"},{"type":"output","id":"NT3O1UCicG9ovN8s0hMO3","data":[],"key":"JOk7RVn2C3"}],"key":"iPkwY8kV6S"},{"type":"block","kind":"notebook-code","children":[{"type":"code","lang":"python","executable":true,"value":"","key":"ouqFNsnWKZ"},{"type":"output","id":"UL87g3u8NYv9yNKai7Ywk","data":[],"key":"gLz2V7fym9"}],"key":"fVulMGzWbH"},{"type":"block","kind":"notebook-code","children":[{"type":"code","lang":"python","executable":true,"value":"results1 = np.ones(len(kcoords)) *np.nan\nresults1[Zidx] =  occurance\nshow_res1 = results1.reshape((x1.shape))\nplt.imshow(np.flipud(show_res1)) #, norm=mpl.colors.LogNorm())\nticks = np.array([0,20,40,60,80])\nyticks = np.array([100,80,60,40,20])\nplt.xticks(ticks[1:],(ticks[0:-1]*5))\nplt.yticks(yticks,(ticks*5))\nplt.colorbar()\nplt.show()","key":"liNZKDeV92"},{"type":"output","id":"TwfosROyLIwX0XEtNG6p6","data":[{"output_type":"display_data","metadata":{},"data":{"image/png":{"content_type":"image/png","hash":"bd2f9c7b57e429a89e58d05f8c66d1c8","path":"/build/bd2f9c7b57e429a89e58d05f8c66d1c8.png"},"text/plain":{"content":"\u003cFigure size 640x480 with 2 Axes\u003e","content_type":"text/plain"}}}],"key":"qiOcEIbWmN"}],"key":"XcIDQWOgTa"},{"type":"block","kind":"notebook-content","children":[{"type":"heading","depth":3,"position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"Covarience Kernels","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"frPo6RZLk0"}],"identifier":"covarience-kernels","label":"Covarience Kernels","html_id":"covarience-kernels","implicit":true,"key":"xkBP0nDI9V"},{"type":"paragraph","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"children":[{"type":"text","value":"Observe the following GP kernels (i.e., covarience models), fitted to the same data; note that every model consistently ","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"key":"BNJbD0gaK1"},{"type":"emphasis","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"children":[{"type":"text","value":"predicts","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"key":"Hu7N20jHHN"}],"key":"Usm3gvgM6T"},{"type":"text","value":" an additional drop ","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"key":"Av6T7kDvQZ"},{"type":"emphasis","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"children":[{"type":"text","value":"beyond the observations","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"key":"IhIixjJIpj"}],"key":"CGhI6kyHum"},{"type":"text","value":" between x=4 and x=5; interpolation using most estimators cannot exceed the min/max of the observation space!","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"key":"j3JatFHgn8"}],"key":"dDhYCAEBWq"},{"type":"paragraph","position":{"start":{"line":5,"column":1},"end":{"line":6,"column":1}},"children":[{"type":"image","url":"/build/640cbbfcbbe6456d9de17be99a0b8710.png","alt":"gp1.png","position":{"start":{"line":5,"column":1},"end":{"line":5,"column":1}},"key":"LGBEUiKb04","urlSource":"https://scikit-learn.org/stable/_images/sphx_glr_plot_gpr_prior_posterior_001.png","urlOptimized":"/build/640cbbfcbbe6456d9de17be99a0b8710.webp"},{"type":"text","value":"\n","position":{"start":{"line":5,"column":1},"end":{"line":5,"column":1}},"key":"RQcAPWDiFg"},{"type":"image","url":"/build/02c12096c474beb07b01aa952e6d7321.png","alt":"gp1.png","position":{"start":{"line":5,"column":1},"end":{"line":5,"column":1}},"key":"mmD3egw8lA","urlSource":"https://scikit-learn.org/stable/_images/sphx_glr_plot_gpr_prior_posterior_002.png","urlOptimized":"/build/02c12096c474beb07b01aa952e6d7321.webp"}],"key":"eU5cOIwW2u"},{"type":"paragraph","position":{"start":{"line":8,"column":1},"end":{"line":8,"column":1}},"children":[{"type":"emphasis","position":{"start":{"line":8,"column":1},"end":{"line":8,"column":1}},"children":[{"type":"text","value":"Note that the next kernel is modeling period functions (applicable to basin and range features)","position":{"start":{"line":8,"column":1},"end":{"line":8,"column":1}},"key":"xpw6xY4FcR"}],"key":"s5mwFu3GTd"}],"key":"pW1pGRT7Zh"},{"type":"paragraph","position":{"start":{"line":10,"column":1},"end":{"line":11,"column":1}},"children":[{"type":"image","url":"/build/d5647b7711a1f652476f0e28745cc0ab.png","alt":"gp1.png","position":{"start":{"line":10,"column":1},"end":{"line":10,"column":1}},"key":"bI5pScoror","urlSource":"https://scikit-learn.org/stable/_images/sphx_glr_plot_gpr_prior_posterior_003.png","urlOptimized":"/build/d5647b7711a1f652476f0e28745cc0ab.webp"},{"type":"text","value":"\n","position":{"start":{"line":10,"column":1},"end":{"line":10,"column":1}},"key":"PXrYA6QnCq"},{"type":"image","url":"/build/3a9cdfda5457eba4bcbf6bf31a4c9441.png","alt":"gp1.png","position":{"start":{"line":10,"column":1},"end":{"line":10,"column":1}},"key":"HEYuwWm2z8","urlSource":"https://scikit-learn.org/stable/_images/sphx_glr_plot_gpr_prior_posterior_005.png","urlOptimized":"/build/3a9cdfda5457eba4bcbf6bf31a4c9441.webp"}],"key":"s90NHR3LPA"},{"type":"paragraph","position":{"start":{"line":13,"column":1},"end":{"line":13,"column":1}},"children":[{"type":"text","value":"Note that one major benefit to the GP kernel formulation is that ","position":{"start":{"line":13,"column":1},"end":{"line":13,"column":1}},"key":"o9RZMJtdPy"},{"type":"link","url":"https://towardsdatascience.com/gaussian-process-kernels-96bafb4dd63e/","position":{"start":{"line":13,"column":1},"end":{"line":13,"column":1}},"children":[{"type":"text","value":"kernels can be ","position":{"start":{"line":13,"column":1},"end":{"line":13,"column":1}},"key":"NkUBMwSlFz"},{"type":"emphasis","position":{"start":{"line":13,"column":1},"end":{"line":13,"column":1}},"children":[{"type":"text","value":"combined","position":{"start":{"line":13,"column":1},"end":{"line":13,"column":1}},"key":"Q8gbItGasS"}],"key":"W2CJr0BgHy"}],"urlSource":"https://towardsdatascience.com/gaussian-process-kernels-96bafb4dd63e/","key":"pt9aXhiFjd"},{"type":"text","value":". This approach models kernels to account for the non-stationarity of the processes within the kernel formulation, rather than seperating out a","position":{"start":{"line":13,"column":1},"end":{"line":13,"column":1}},"key":"Yj82Ocdm9S"}],"key":"w8nSpIhw9O"}],"key":"Z2fnGFouBL"}],"key":"R23mRmoOtn"},"references":{"cite":{"order":["Williams_1998","Rasmussen_2005","Matheron_1973","Journel_1977","genton","https://doi.org/10.48550/arxiv.1302.4245","Cressie_1999","Mat_rn_1986","https://doi.org/10.48550/arxiv.1503.01057","Cressie_1990","Handcock_1993","MacKay_1992"],"data":{"Williams_1998":{"label":"Williams_1998","enumerator":"1","doi":"10.1007/978-94-011-5014-9_23","html":"Williams, C. K. I. (1998). Prediction with Gaussian Processes: From Linear Regression to Linear Prediction and Beyond. In \u003ci\u003eLearning in Graphical Models\u003c/i\u003e (pp. 599–621). Springer Netherlands. \u003ca target=\"_blank\" rel=\"noreferrer\" href=\"https://doi.org/10.1007/978-94-011-5014-9_23\"\u003e10.1007/978-94-011-5014-9_23\u003c/a\u003e","url":"https://doi.org/10.1007/978-94-011-5014-9_23"},"Rasmussen_2005":{"label":"Rasmussen_2005","enumerator":"2","doi":"10.7551/mitpress/3206.001.0001","html":"Rasmussen, C. E., \u0026 Williams, C. K. I. (2005). \u003ci\u003eGaussian Processes for Machine Learning\u003c/i\u003e. The MIT Press. \u003ca target=\"_blank\" rel=\"noreferrer\" href=\"https://doi.org/10.7551/mitpress/3206.001.0001\"\u003e10.7551/mitpress/3206.001.0001\u003c/a\u003e","url":"https://doi.org/10.7551/mitpress/3206.001.0001"},"Matheron_1973":{"label":"Matheron_1973","enumerator":"3","doi":"10.2307/1425829","html":"Matheron, G. (1973). The intrinsic random functions and their applications. \u003ci\u003eAdvances in Applied Probability\u003c/i\u003e, \u003ci\u003e5\u003c/i\u003e(3), 439–468. \u003ca target=\"_blank\" rel=\"noreferrer\" href=\"https://doi.org/10.2307/1425829\"\u003e10.2307/1425829\u003c/a\u003e","url":"https://doi.org/10.2307/1425829"},"Journel_1977":{"label":"Journel_1977","enumerator":"4","doi":"10.1007/bf02067214","html":"Journel, A. G. (1977). Kriging in terms of projections. \u003ci\u003eMathematical Geology\u003c/i\u003e, \u003ci\u003e9\u003c/i\u003e(6), 563–586. \u003ca target=\"_blank\" rel=\"noreferrer\" href=\"https://doi.org/10.1007/bf02067214\"\u003e10.1007/bf02067214\u003c/a\u003e","url":"https://doi.org/10.1007/bf02067214"},"genton":{"label":"genton","enumerator":"5","doi":"10.5555/944790.944815","html":"Genton, M. G. (2002). Classes of kernels for machine learning: a statistics perspective. \u003ci\u003eJ. Mach. Learn. Res.\u003c/i\u003e, \u003ci\u003e2\u003c/i\u003e, 299–312. \u003ca target=\"_blank\" rel=\"noreferrer\" href=\"https://doi.org/10.5555/944790.944815\"\u003e10.5555/944790.944815\u003c/a\u003e","url":"https://doi.org/10.5555/944790.944815"},"https://doi.org/10.48550/arxiv.1302.4245":{"label":"https://doi.org/10.48550/arxiv.1302.4245","enumerator":"6","doi":"10.48550/ARXIV.1302.4245","html":"Wilson, A. G., \u0026 Adams, R. P. (2013). \u003ci\u003eGaussian Process Kernels for Pattern Discovery and Extrapolation\u003c/i\u003e. \u003ca target=\"_blank\" rel=\"noreferrer\" href=\"https://doi.org/10.48550/ARXIV.1302.4245\"\u003e10.48550/ARXIV.1302.4245\u003c/a\u003e","url":"https://doi.org/10.48550/ARXIV.1302.4245"},"Cressie_1999":{"label":"Cressie_1999","enumerator":"7","doi":"10.1080/01621459.1999.10473885","html":"Cressie, N., \u0026 Huang, H.-C. (1999). Classes of Nonseparable, Spatio-Temporal Stationary Covariance Functions. \u003ci\u003eJournal of the American Statistical Association\u003c/i\u003e, \u003ci\u003e94\u003c/i\u003e(448), 1330–1339. \u003ca target=\"_blank\" rel=\"noreferrer\" href=\"https://doi.org/10.1080/01621459.1999.10473885\"\u003e10.1080/01621459.1999.10473885\u003c/a\u003e","url":"https://doi.org/10.1080/01621459.1999.10473885"},"Mat_rn_1986":{"label":"Mat_rn_1986","enumerator":"8","doi":"10.1007/978-1-4615-7892-5","html":"Matérn, B. (1986). Spatial Variation. In \u003ci\u003eLecture Notes in Statistics\u003c/i\u003e. Springer New York. \u003ca target=\"_blank\" rel=\"noreferrer\" href=\"https://doi.org/10.1007/978-1-4615-7892-5\"\u003e10.1007/978-1-4615-7892-5\u003c/a\u003e","url":"https://doi.org/10.1007/978-1-4615-7892-5"},"https://doi.org/10.48550/arxiv.1503.01057":{"label":"https://doi.org/10.48550/arxiv.1503.01057","enumerator":"9","doi":"10.48550/ARXIV.1503.01057","html":"Wilson, A. G., \u0026 Nickisch, H. (2015). \u003ci\u003eKernel Interpolation for Scalable Structured Gaussian Processes (KISS-GP)\u003c/i\u003e. arXiv. \u003ca target=\"_blank\" rel=\"noreferrer\" href=\"https://doi.org/10.48550/ARXIV.1503.01057\"\u003e10.48550/ARXIV.1503.01057\u003c/a\u003e","url":"https://doi.org/10.48550/ARXIV.1503.01057"},"Cressie_1990":{"label":"Cressie_1990","enumerator":"10","doi":"10.1007/bf00889887","html":"Cressie, N. (1990). The origins of kriging. \u003ci\u003eMathematical Geology\u003c/i\u003e, \u003ci\u003e22\u003c/i\u003e(3), 239–252. \u003ca target=\"_blank\" rel=\"noreferrer\" href=\"https://doi.org/10.1007/bf00889887\"\u003e10.1007/bf00889887\u003c/a\u003e","url":"https://doi.org/10.1007/bf00889887"},"Handcock_1993":{"label":"Handcock_1993","enumerator":"11","doi":"10.1080/00401706.1993.10485354","html":"Handcock, M. S., \u0026 Stein, M. L. (1993). A Bayesian Analysis of Kriging. \u003ci\u003eTechnometrics\u003c/i\u003e, \u003ci\u003e35\u003c/i\u003e(4), 403–410. \u003ca target=\"_blank\" rel=\"noreferrer\" href=\"https://doi.org/10.1080/00401706.1993.10485354\"\u003e10.1080/00401706.1993.10485354\u003c/a\u003e","url":"https://doi.org/10.1080/00401706.1993.10485354"},"MacKay_1992":{"label":"MacKay_1992","enumerator":"12","doi":"10.1162/neco.1992.4.3.415","html":"MacKay, D. J. C. (1992). Bayesian Interpolation. \u003ci\u003eNeural Computation\u003c/i\u003e, \u003ci\u003e4\u003c/i\u003e(3), 415–447. \u003ca target=\"_blank\" rel=\"noreferrer\" href=\"https://doi.org/10.1162/neco.1992.4.3.415\"\u003e10.1162/neco.1992.4.3.415\u003c/a\u003e","url":"https://doi.org/10.1162/neco.1992.4.3.415"}}}},"footer":{"navigation":{"prev":{"title":"Coding \u0026 Writing Sample","url":"/gaussianprocesses","group":"Coding Sample"}}},"domain":"http://localhost:3001"},"project":{"title":"Coding Sample","thumbnail":"/build/c46244155f82f0a2188b900fb12670c3.svg","exports":[],"bibliography":[],"index":"readme","pages":[{"slug":"gaussianprocesses","title":"Coding \u0026 Writing Sample","description":"","date":"2025-05-07","thumbnail":"/build/b77199e99a54e59b2e3c037c2cc90f21.svg","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":1},{"title":"Tmp","level":1},{"slug":"gaussianprocesses-copy1","title":"Context for this coding \u0026 writing sample","description":"","date":"","thumbnail":"/build/b77199e99a54e59b2e3c037c2cc90f21.svg","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2}]}}},"actionData":null,"errors":null},"future":{"unstable_dev":false,"unstable_postcss":false,"unstable_tailwind":false,"v2_errorBoundary":true,"v2_headers":true,"v2_meta":true,"v2_normalizeFormMethod":true,"v2_routeConvention":true}};</script><script type="module" async="">import "/build/manifest-B4831781.js";
import * as route0 from "/build/root-QGLRP2PL.js";
import * as route1 from "/build/routes/$-7JYT5576.js";
window.__remixRouteModules = {"root":route0,"routes/$":route1};

import("/build/entry.client-UNPC4GT3.js");</script></body></html>